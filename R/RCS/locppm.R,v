head	1.183;
access;
symbols;
locks
	adrian:1.183; strict;
comment	@# @;


1.183
date	2016.10.11.10.55.06;	author adrian;	state Exp;
branches;
next	1.182;

1.182
date	2016.10.11.10.26.06;	author adrian;	state Exp;
branches;
next	1.181;

1.181
date	2016.10.01.05.14.37;	author adrian;	state Exp;
branches;
next	1.180;

1.180
date	2016.09.25.06.40.39;	author adrian;	state Exp;
branches;
next	1.179;

1.179
date	2016.09.23.09.52.48;	author adrian;	state Exp;
branches;
next	1.178;

1.178
date	2016.09.22.03.22.01;	author adrian;	state Exp;
branches;
next	1.177;

1.177
date	2016.09.10.06.10.50;	author adrian;	state Exp;
branches;
next	1.176;

1.176
date	2016.09.08.01.33.26;	author adrian;	state Exp;
branches;
next	1.175;

1.175
date	2016.09.05.08.18.19;	author adrian;	state Exp;
branches;
next	1.174;

1.174
date	2016.09.05.08.09.41;	author adrian;	state Exp;
branches;
next	1.173;

1.173
date	2016.09.03.10.49.39;	author adrian;	state Exp;
branches;
next	1.172;

1.172
date	2016.08.31.10.20.00;	author adrian;	state Exp;
branches;
next	1.171;

1.171
date	2016.08.31.09.09.05;	author adrian;	state Exp;
branches;
next	1.170;

1.170
date	2016.08.20.09.03.13;	author adrian;	state Exp;
branches;
next	1.169;

1.169
date	2016.08.20.08.25.47;	author adrian;	state Exp;
branches;
next	1.168;

1.168
date	2016.08.20.08.12.53;	author adrian;	state Exp;
branches;
next	1.167;

1.167
date	2016.08.20.07.34.24;	author adrian;	state Exp;
branches;
next	1.166;

1.166
date	2016.08.20.06.47.48;	author adrian;	state Exp;
branches;
next	1.165;

1.165
date	2016.08.17.10.12.09;	author adrian;	state Exp;
branches;
next	1.164;

1.164
date	2016.08.17.10.10.37;	author adrian;	state Exp;
branches;
next	1.163;

1.163
date	2014.07.02.04.53.00;	author adrian;	state Exp;
branches;
next	1.162;

1.162
date	2014.07.01.01.16.56;	author adrian;	state Exp;
branches;
next	1.161;

1.161
date	2014.07.01.00.53.39;	author adrian;	state Exp;
branches;
next	1.160;

1.160
date	2014.07.01.00.51.33;	author adrian;	state Exp;
branches;
next	1.159;

1.159
date	2014.06.28.09.47.34;	author adrian;	state Exp;
branches;
next	1.158;

1.158
date	2014.06.28.09.14.02;	author adrian;	state Exp;
branches;
next	1.157;

1.157
date	2013.12.19.08.38.35;	author adrian;	state Exp;
branches;
next	1.156;

1.156
date	2013.11.29.01.52.17;	author adrian;	state Exp;
branches;
next	1.155;

1.155
date	2013.11.28.14.49.40;	author adrian;	state Exp;
branches;
next	1.154;

1.154
date	2013.11.28.13.00.44;	author adrian;	state Exp;
branches;
next	1.153;

1.153
date	2013.11.28.10.54.38;	author adrian;	state Exp;
branches;
next	1.152;

1.152
date	2013.11.28.10.44.15;	author adrian;	state Exp;
branches;
next	1.151;

1.151
date	2013.11.28.10.17.21;	author adrian;	state Exp;
branches;
next	1.150;

1.150
date	2013.11.28.05.06.51;	author adrian;	state Exp;
branches;
next	1.149;

1.149
date	2013.11.28.05.06.17;	author adrian;	state Exp;
branches;
next	1.148;

1.148
date	2013.11.28.02.15.05;	author adrian;	state Exp;
branches;
next	1.147;

1.147
date	2013.11.28.02.06.36;	author adrian;	state Exp;
branches;
next	1.146;

1.146
date	2013.11.28.02.05.12;	author adrian;	state Exp;
branches;
next	1.145;

1.145
date	2013.11.27.13.01.17;	author adrian;	state Exp;
branches;
next	1.144;

1.144
date	2013.09.25.07.42.51;	author adrian;	state Exp;
branches;
next	1.143;

1.143
date	2013.09.25.06.57.35;	author adrian;	state Exp;
branches;
next	1.142;

1.142
date	2013.09.25.05.20.37;	author adrian;	state Exp;
branches;
next	1.141;

1.141
date	2013.09.25.04.11.39;	author adrian;	state Exp;
branches;
next	1.140;

1.140
date	2013.09.25.04.06.04;	author adrian;	state Exp;
branches;
next	1.139;

1.139
date	2013.09.25.02.47.31;	author adrian;	state Exp;
branches;
next	1.138;

1.138
date	2013.09.04.11.53.33;	author adrian;	state Exp;
branches;
next	1.137;

1.137
date	2013.08.31.02.27.51;	author adrian;	state Exp;
branches;
next	1.136;

1.136
date	2013.07.28.09.16.42;	author adrian;	state Exp;
branches;
next	1.135;

1.135
date	2013.07.27.09.56.12;	author adrian;	state Exp;
branches;
next	1.134;

1.134
date	2013.07.27.08.42.17;	author adrian;	state Exp;
branches;
next	1.133;

1.133
date	2013.07.26.02.24.29;	author adrian;	state Exp;
branches;
next	1.132;

1.132
date	2013.07.25.07.54.37;	author adrian;	state Exp;
branches;
next	1.131;

1.131
date	2013.07.25.07.53.28;	author adrian;	state Exp;
branches;
next	1.130;

1.130
date	2013.07.23.10.49.38;	author adrian;	state Exp;
branches;
next	1.129;

1.129
date	2013.07.23.08.11.54;	author adrian;	state Exp;
branches;
next	1.128;

1.128
date	2013.07.23.07.35.04;	author adrian;	state Exp;
branches;
next	1.127;

1.127
date	2013.07.23.06.17.22;	author adrian;	state Exp;
branches;
next	1.126;

1.126
date	2013.07.23.05.41.26;	author adrian;	state Exp;
branches;
next	1.125;

1.125
date	2013.07.23.04.36.43;	author adrian;	state Exp;
branches;
next	1.124;

1.124
date	2013.07.23.02.54.40;	author adrian;	state Exp;
branches;
next	1.123;

1.123
date	2013.07.23.01.26.22;	author adrian;	state Exp;
branches;
next	1.122;

1.122
date	2013.07.23.01.13.44;	author adrian;	state Exp;
branches;
next	1.121;

1.121
date	2013.07.23.01.11.49;	author adrian;	state Exp;
branches;
next	1.120;

1.120
date	2013.07.23.01.10.40;	author adrian;	state Exp;
branches;
next	1.119;

1.119
date	2013.07.22.08.15.10;	author adrian;	state Exp;
branches;
next	1.118;

1.118
date	2013.07.22.08.03.35;	author adrian;	state Exp;
branches;
next	1.117;

1.117
date	2013.07.20.03.41.43;	author adrian;	state Exp;
branches;
next	1.116;

1.116
date	2013.07.19.09.31.29;	author adrian;	state Exp;
branches;
next	1.115;

1.115
date	2013.07.19.08.56.50;	author adrian;	state Exp;
branches;
next	1.114;

1.114
date	2013.07.19.05.25.51;	author adrian;	state Exp;
branches;
next	1.113;

1.113
date	2013.07.18.06.37.19;	author adrian;	state Exp;
branches;
next	1.112;

1.112
date	2013.07.18.06.35.10;	author adrian;	state Exp;
branches;
next	1.111;

1.111
date	2013.07.18.01.23.21;	author adrian;	state Exp;
branches;
next	1.110;

1.110
date	2013.07.16.10.24.16;	author adrian;	state Exp;
branches;
next	1.109;

1.109
date	2013.07.16.06.47.30;	author adrian;	state Exp;
branches;
next	1.108;

1.108
date	2013.07.16.06.43.40;	author adrian;	state Exp;
branches;
next	1.107;

1.107
date	2013.07.07.09.35.49;	author adrian;	state Exp;
branches;
next	1.106;

1.106
date	2013.07.06.09.12.09;	author adrian;	state Exp;
branches;
next	1.105;

1.105
date	2013.07.06.01.37.10;	author adrian;	state Exp;
branches;
next	1.104;

1.104
date	2013.07.05.10.49.02;	author adrian;	state Exp;
branches;
next	1.103;

1.103
date	2013.07.05.10.34.52;	author adrian;	state Exp;
branches;
next	1.102;

1.102
date	2013.07.05.09.44.18;	author adrian;	state Exp;
branches;
next	1.101;

1.101
date	2013.07.05.09.15.28;	author adrian;	state Exp;
branches;
next	1.100;

1.100
date	2013.07.04.07.06.26;	author adrian;	state Exp;
branches;
next	1.99;

1.99
date	2013.07.04.06.46.44;	author adrian;	state Exp;
branches;
next	1.98;

1.98
date	2013.07.04.06.21.53;	author adrian;	state Exp;
branches;
next	1.97;

1.97
date	2013.07.04.06.17.38;	author adrian;	state Exp;
branches;
next	1.96;

1.96
date	2013.07.03.10.17.15;	author adrian;	state Exp;
branches;
next	1.95;

1.95
date	2013.07.03.09.33.17;	author adrian;	state Exp;
branches;
next	1.94;

1.94
date	2013.07.03.02.58.51;	author adrian;	state Exp;
branches;
next	1.93;

1.93
date	2013.07.03.02.21.44;	author adrian;	state Exp;
branches;
next	1.92;

1.92
date	2013.07.03.02.18.28;	author adrian;	state Exp;
branches;
next	1.91;

1.91
date	2013.07.03.02.15.17;	author adrian;	state Exp;
branches;
next	1.90;

1.90
date	2013.07.02.10.57.46;	author adrian;	state Exp;
branches;
next	1.89;

1.89
date	2013.07.02.10.45.53;	author adrian;	state Exp;
branches;
next	1.88;

1.88
date	2013.07.02.09.46.22;	author adrian;	state Exp;
branches;
next	1.87;

1.87
date	2013.07.02.09.44.31;	author adrian;	state Exp;
branches;
next	1.86;

1.86
date	2013.07.02.09.38.27;	author adrian;	state Exp;
branches;
next	1.85;

1.85
date	2013.07.02.08.03.43;	author adrian;	state Exp;
branches;
next	1.84;

1.84
date	2013.07.02.07.47.55;	author adrian;	state Exp;
branches;
next	1.83;

1.83
date	2013.07.02.07.22.27;	author adrian;	state Exp;
branches;
next	1.82;

1.82
date	2013.07.02.06.11.11;	author adrian;	state Exp;
branches;
next	1.81;

1.81
date	2013.07.02.06.02.23;	author adrian;	state Exp;
branches;
next	1.80;

1.80
date	2013.07.02.06.01.18;	author adrian;	state Exp;
branches;
next	1.79;

1.79
date	2013.07.02.04.32.14;	author adrian;	state Exp;
branches;
next	1.78;

1.78
date	2013.07.01.09.13.38;	author adrian;	state Exp;
branches;
next	1.77;

1.77
date	2013.07.01.08.51.15;	author adrian;	state Exp;
branches;
next	1.76;

1.76
date	2013.07.01.08.49.47;	author adrian;	state Exp;
branches;
next	1.75;

1.75
date	2013.07.01.08.47.16;	author adrian;	state Exp;
branches;
next	1.74;

1.74
date	2013.07.01.08.25.22;	author adrian;	state Exp;
branches;
next	1.73;

1.73
date	2013.07.01.08.21.13;	author adrian;	state Exp;
branches;
next	1.72;

1.72
date	2013.06.30.07.00.46;	author adrian;	state Exp;
branches;
next	1.71;

1.71
date	2013.06.30.06.53.57;	author adrian;	state Exp;
branches;
next	1.70;

1.70
date	2013.06.30.03.21.55;	author adrian;	state Exp;
branches;
next	1.69;

1.69
date	2013.06.17.08.03.27;	author adrian;	state Exp;
branches;
next	1.68;

1.68
date	2013.04.22.09.30.34;	author adrian;	state Exp;
branches;
next	1.67;

1.67
date	2013.04.22.07.39.15;	author adrian;	state Exp;
branches;
next	1.66;

1.66
date	2013.04.20.10.46.51;	author adrian;	state Exp;
branches;
next	1.65;

1.65
date	2013.04.19.09.04.12;	author adrian;	state Exp;
branches;
next	1.64;

1.64
date	2013.04.19.08.52.36;	author adrian;	state Exp;
branches;
next	1.63;

1.63
date	2013.04.19.08.33.56;	author adrian;	state Exp;
branches;
next	1.62;

1.62
date	2013.04.19.07.26.31;	author adrian;	state Exp;
branches;
next	1.61;

1.61
date	2013.04.19.07.16.02;	author adrian;	state Exp;
branches;
next	1.60;

1.60
date	2013.04.19.07.14.36;	author adrian;	state Exp;
branches;
next	1.59;

1.59
date	2013.04.19.07.04.50;	author adrian;	state Exp;
branches;
next	1.58;

1.58
date	2013.04.19.06.58.04;	author adrian;	state Exp;
branches;
next	1.57;

1.57
date	2013.04.15.09.00.12;	author adrian;	state Exp;
branches;
next	1.56;

1.56
date	2013.04.12.07.05.30;	author adrian;	state Exp;
branches;
next	1.55;

1.55
date	2013.04.12.06.57.34;	author adrian;	state Exp;
branches;
next	1.54;

1.54
date	2013.04.11.06.42.57;	author adrian;	state Exp;
branches;
next	1.53;

1.53
date	2012.12.14.02.48.24;	author adrian;	state Exp;
branches;
next	1.52;

1.52
date	2012.12.14.02.44.19;	author adrian;	state Exp;
branches;
next	1.51;

1.51
date	2012.12.13.02.49.34;	author adrian;	state Exp;
branches;
next	1.50;

1.50
date	2012.12.13.02.33.33;	author adrian;	state Exp;
branches;
next	1.49;

1.49
date	2012.12.12.05.12.23;	author adrian;	state Exp;
branches;
next	1.48;

1.48
date	2012.12.12.04.46.00;	author adrian;	state Exp;
branches;
next	1.47;

1.47
date	2012.12.12.04.42.57;	author adrian;	state Exp;
branches;
next	1.46;

1.46
date	2012.12.12.03.21.28;	author adrian;	state Exp;
branches;
next	1.45;

1.45
date	2012.12.12.03.15.02;	author adrian;	state Exp;
branches;
next	1.44;

1.44
date	2012.12.12.01.52.31;	author adrian;	state Exp;
branches;
next	1.43;

1.43
date	2012.12.12.01.49.33;	author adrian;	state Exp;
branches;
next	1.42;

1.42
date	2012.12.12.01.48.06;	author adrian;	state Exp;
branches;
next	1.41;

1.41
date	2012.12.10.08.54.20;	author adrian;	state Exp;
branches;
next	1.40;

1.40
date	2012.12.09.10.17.07;	author adrian;	state Exp;
branches;
next	1.39;

1.39
date	2012.12.08.02.59.53;	author adrian;	state Exp;
branches;
next	1.38;

1.38
date	2012.12.07.10.56.23;	author adrian;	state Exp;
branches;
next	1.37;

1.37
date	2012.12.07.10.53.54;	author adrian;	state Exp;
branches;
next	1.36;

1.36
date	2012.12.07.10.16.21;	author adrian;	state Exp;
branches;
next	1.35;

1.35
date	2012.12.07.09.36.43;	author adrian;	state Exp;
branches;
next	1.34;

1.34
date	2012.12.07.09.30.53;	author adrian;	state Exp;
branches;
next	1.33;

1.33
date	2012.12.07.08.37.39;	author adrian;	state Exp;
branches;
next	1.32;

1.32
date	2012.12.07.05.05.19;	author adrian;	state Exp;
branches;
next	1.31;

1.31
date	2012.12.03.06.13.55;	author adrian;	state Exp;
branches;
next	1.30;

1.30
date	2012.11.29.05.30.06;	author adrian;	state Exp;
branches;
next	1.29;

1.29
date	2012.11.29.05.25.15;	author adrian;	state Exp;
branches;
next	1.28;

1.28
date	2012.11.23.04.54.46;	author adrian;	state Exp;
branches;
next	1.27;

1.27
date	2012.11.23.04.28.09;	author adrian;	state Exp;
branches;
next	1.26;

1.26
date	2012.11.15.07.04.22;	author adrian;	state Exp;
branches;
next	1.25;

1.25
date	2012.11.15.04.05.10;	author adrian;	state Exp;
branches;
next	1.24;

1.24
date	2012.11.15.02.40.54;	author adrian;	state Exp;
branches;
next	1.23;

1.23
date	2012.11.14.11.11.03;	author adrian;	state Exp;
branches;
next	1.22;

1.22
date	2012.11.14.10.49.10;	author adrian;	state Exp;
branches;
next	1.21;

1.21
date	2012.11.14.07.57.39;	author adrian;	state Exp;
branches;
next	1.20;

1.20
date	2012.11.12.07.11.07;	author adrian;	state Exp;
branches;
next	1.19;

1.19
date	2012.10.29.10.23.35;	author adrian;	state Exp;
branches;
next	1.18;

1.18
date	2012.10.29.01.00.25;	author adrian;	state Exp;
branches;
next	1.17;

1.17
date	2012.10.26.07.53.47;	author adrian;	state Exp;
branches;
next	1.16;

1.16
date	2012.10.10.06.07.11;	author adrian;	state Exp;
branches;
next	1.15;

1.15
date	2012.10.10.04.48.26;	author adrian;	state Exp;
branches;
next	1.14;

1.14
date	2012.10.10.02.55.33;	author adrian;	state Exp;
branches;
next	1.13;

1.13
date	2012.10.03.11.01.30;	author adrian;	state Exp;
branches;
next	1.12;

1.12
date	2012.10.03.10.55.01;	author adrian;	state Exp;
branches;
next	1.11;

1.11
date	2012.09.12.02.10.12;	author adrian;	state Exp;
branches;
next	1.10;

1.10
date	2012.09.04.07.16.07;	author adrian;	state Exp;
branches;
next	1.9;

1.9
date	2012.09.04.06.07.25;	author adrian;	state Exp;
branches;
next	1.8;

1.8
date	2012.09.03.06.19.46;	author adrian;	state Exp;
branches;
next	1.7;

1.7
date	2012.08.29.02.11.44;	author adrian;	state Exp;
branches;
next	1.6;

1.6
date	2012.08.28.09.53.10;	author adrian;	state Exp;
branches;
next	1.5;

1.5
date	2012.08.27.01.48.23;	author adrian;	state Exp;
branches;
next	1.4;

1.4
date	2012.08.27.01.39.39;	author adrian;	state Exp;
branches;
next	1.3;

1.3
date	2012.08.27.01.30.22;	author adrian;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.16.10.17.15;	author adrian;	state Exp;
branches;
next	1.1;

1.1
date	2012.08.16.09.55.05;	author adrian;	state Exp;
branches;
next	;


desc
@@


1.183
log
@retains all quadrature points!
@
text
@#
#  locppm.R
#
# Local (pseudo)likelihood for point processes
#
#  $Revision: 1.182 $ $Date: 2016/10/11 10:26:06 $
#

locppm <- function(..., sigma=NULL, f = 1/4,
                   vcalc=c("none", "t", "hessian", "hom", "lik", "full"),
                   locations=c("split", "fine", "coarse"),
                   ngrid=NULL, grideps=NULL,
                   verbose=TRUE,
                   use.fft=FALSE, fft.algorithm="closepairs") {

  starttime <- proc.time()

  missloc <- missing(locations)
  locations <- match.arg(locations)
  vcalc <- match.arg(vcalc)

  if(missloc) {
    # Default is locations = "split"
    # except in the following cases
    if(vcalc == "none") locations <- "fine"
    if(vcalc %in% c("hom", "lik"))  locations <- "coarse"
  }

  stopifnot(is.logical(use.fft))
  
  # fit homogeneous model
  if(verbose) cat("Fitting homogeneous model... ")
  parenv <- sys.parent()
  homfit <- eval(substitute(ppm(..., forcefit=TRUE)), envir=parenv)
  if(is.multitype(homfit))
    stop("Sorry, cannot handle marked point processes yet")
  if(verbose) cat("Done.\n")
  templatecall <- format(substitute(ppm(...)))

  ispois <- is.poisson(homfit)

  X <- data.ppm(homfit)
  Q <- quad.ppm(homfit)
  U <- union.quad(Q)
  wU <- w.quad(Q)

  # determine smoothing parameter
  if(is.null(sigma)) {
    sigma <- bw.frac(X, f=f)
    if(verbose)
      cat(paste("sigma = ", sigma, "\n"))
  }

  # default grid dimensions
  need.grid <- (locations %in% c("coarse", "split"))
  if(need.grid && is.null(ngrid) && is.null(grideps))
    ngrid <- 10
    
  # Selected calculations
  opt.none <- locppmOptions(FALSE)
  if(!use.fft) {
    opt.coef <- locppmOptions(cg=TRUE)
    opt.t    <- locppmOptions(tg=TRUE)
    opt.hess <- locppmOptions(Vg=TRUE, Tg=TRUE)
    opt.hom  <- locppmOptions(sh=TRUE, fh=TRUE, gh=TRUE, Xh=!ispois)
    opt.lik  <- locppmOptions(sh=TRUE, fh=TRUE, gh=TRUE, Xh=!ispois, Lg=TRUE)
    opt.full <- locppmOptions(v0=FALSE, other=TRUE, other1=FALSE)
  } else {
    # FFT calculations
    opt.coef <- locppmOptions(cg1=TRUE)
    opt.t    <- locppmOptions(tg1=TRUE)
    opt.hess <- locppmOptions(gg1=TRUE) 
    opt.hom  <- locppmOptions(sh1=TRUE, fh1=TRUE, gh1=TRUE) #, Xh1=!ispois)
    opt.lik  <- opt.hom
    opt.full <- locppmOptions(FALSE, other1=TRUE)
  }
  
  switch(vcalc,
         none = {
           # estimate coefficients only
           opt.fit  <- opt.coef
           opt.var  <- opt.none
         },
         t = {
           # estimate coefficients and calculate t-statistics
           opt.fit <- opt.coef
           opt.var <- opt.t
         },
         hessian = {
           # estimate coefficients and Poisson/Poincare variance only
           opt.fit <- opt.coef
           opt.var <- opt.hess & !opt.coef
         },
         full = {
           # full variance estimation
           opt.fit <- opt.coef
           opt.var <- opt.full & !opt.coef
         },
         hom = {
           # For use by 'homtest'.
           # Don't evaluate fitted coefficients.
           # Calculate variance of local score under homogeneous model
           opt.fit <- opt.none
           opt.var <- opt.hom
         },
         lik = {
           # For use by 'homtest'.
           # Calculate local likelihood ratio test statistic,
           # plus variance of local score under homogeneous model
           opt.fit <- opt.none
           opt.var <- opt.lik
         }
         )

  phase1time <- NULL
  
  # Execute
  switch(locations,
         fine = {
           # quadrature points
           opt <- opt.fit | opt.var
           lpe <- locppmEngine(homfit, sigma, U,
                               weights=wU, opt=opt,
                               scopename="quadrature points",
                               verbose=verbose,
                               fft.algorithm=fft.algorithm)
         },
         coarse = {
           # grid points
           opt <- opt.fit | opt.var
           coarse.to.fine <- gridproxy(U, dimyx=ngrid, eps=grideps)
           G <- U[coarse.to.fine]
           wG <- attr(coarse.to.fine, "weights")
           lpe <- locppmEngine(homfit, sigma, G, weights=wG, opt=opt,
                               scopename="grid points",
                               verbose=verbose, fft.algorithm=fft.algorithm)
         },
         split = {
           # fit on quadrature points, variance estimation on grid points
           lpe.fit <- locppmEngine(homfit, sigma, U, weights=wU, opt=opt.fit,
                                   scopename="quadrature points",
                                   verbose=verbose, fft.algorithm=fft.algorithm)
           # record time taken to complete first phase 
           phase1time <- proc.time() - starttime
           #
           coarse.to.fine <- gridproxy(U, dimyx=ngrid, eps=grideps)
           G <- U[coarse.to.fine]
           wG <- attr(coarse.to.fine, "weights")
           if(verbose) cat("Estimating variance..\n")
           lpe.var <- locppmEngine(homfit, sigma, G, weights=wG, opt=opt.var,
                                   scopename="grid points",
                                   scopeindex=coarse.to.fine,
                                   verbose=verbose, fft.algorithm=fft.algorithm)
           lpe <- resolve.defaults(lpe.fit, lpe.var,
                                   list(coarse.to.fine=coarse.to.fine),
                                   .MatchNull=FALSE)
         })
  # pack up
  result <- append(lpe,
                   list(homfit=homfit, ispois=ispois, sigma=sigma,
                        vcalc=vcalc, locations=locations,
                        ngrid=ngrid, grideps=grideps,
                        templatecall=templatecall,
                        phase1time=phase1time))
  class(result) <- c("locppm", class(result))
  result <- timed(result, starttime=starttime)
  return(result)
}

.locppmOptionTable <- local({
  x <-
    list(cg="coefficient estimates",
         vg="variance of local fit",
         tg="t statistics of local fit",
         Vg="Poincare variance (inverse negative Hessian) of local fit",
         Tg="Poincare approximation of t statistics of local fit",
         xg="leave-one-out coefficient estimates",
         vh="null variance of local fit under homogeneous model",
         fh="local Fisher information under homogeneous model",
         gh="gradient of local score evaluated at homogeneous model",
         sh="local score of homogeneous model",
         Xh="covariance of local and global scores under homogeneous model",
         v0="variance of local fit under reduced model", 
         cg1="Taylor approximation of local coefficient estimates",
         vg1="variance of Taylor approximate local coefficients",
         tg1="t statistics of Taylor approximate local fit",
         gg1="gradient (negative Hessian) of Taylor-approximate local fit",
         vh1="null variance of local fit under homogeneous model (by FFT)",
         fh1="local Fisher information under homogeneous model",
         sh1="local score of homogeneous model",
         gh1="gradient of local score evaluated at homogeneous model",
         Xh1="covariance of local and global scores under homogeneous model",
         #
         Lg="local likelihood ratio test statistic for homogeneity")
  
  not.implemented <- "Xh1"
  require.fastRC <- c("sh", "fh", "Xh")

  y <- names(x)
  z <- unname(unlist(x))

  y1 <- substr(y, 1, 1)
  y2 <- substr(y, 2, 2)

  calcmap <- c(c="coef",
               v="var",
               f="fish",
               s="score",
               g="grad",
               t="tstat",
               V="invgrad",
               T="tgrad",
               L="lrts",
               x="xcoef",
               X="cov")

  dimtype <- c(c="vector",
               v="matrix",
               f="matrix",
               s="vector",
               g="matrix",
               t="vector",
               V="matrix",
               T="vector",
               L="scalar",
               x="vector",
               X="matrix")

  data.frame(tags        = y,
             descrip     = z,
             calctype    = factor(y1),
             calcname    = unname(calcmap[y1]),
             dimtype     = unname(dimtype[y1]),
             modeltype   = factor(ifelse(y2 %in% c("h", "0"), y2, "l")),
             usefft      = (nchar(y) == 3),
             implemented = !(y %in% not.implemented),
             requirefast = y %in% require.fastRC,
             stringsAsFactors=FALSE, row.names=y)
})

locppmOptions <- function(other=FALSE, ..., other1=other) {
  if(!is.logical(other) || !is.logical(other1)) stop("Logical values expected")
  # initialise options
  LOT <- .locppmOptionTable
  opt <- ifelse(LOT$usefft, other1, other)
  names(opt) <- LOT$tags
  # set options given explicitly
  argh <- list(...)
  nama <- names(argh)
  hit <- (nama %in% names(opt))
  if(any(hit)) {
    newvalues <- unlist(argh[hit])
    if(!is.logical(newvalues))  stop("Logical values expected")
    opt[nama[hit]] <- newvalues
  }
  # warn about unrecognised options
  if(any(nbg <- !hit))
    warning(paste("Unrecognised",
                  ngettext(sum(nbg), "argument", "arguments"),
                  commasep(sQuote(nama[!hit]))))
  # return
  class(opt) <- c("locppmOptions", class(opt))
  return(opt)
}

print.locppmOptions <- function(x, ...) {
  cat("Options for locppm fit\n")
  y <- unlist(x)
  if(!any(y)) {
    cat("Selected options: None\n")
  } else {
    cat("Selected options: \n")
    explain <- .locppmOptionTable$descrip[y]
    nama <- names(explain)
    for(i in seq(along=explain))
      cat(paste0("\t$", nama[i], ": ", explain[[i]], "\n"))
  }
  return(invisible(NULL))
}

locppmEngine <- function(model, sigma, V, 
                         ...,
                         weights=NULL,
                         verbose=TRUE,
                         scopename="points",
                         scopeindex = NULL,
                         opt = locppmOptions(cg=TRUE, Tg=TRUE),
                         dropterm = NULL,
                         matrices = FALSE,
                         fastRCinloop = TRUE,
                         internals = NULL,
                         fft.algorithm = "density"
                         ) {
  # compute weighted version of point process model at each point of V
  stopifnot(inherits(model, "ppm"))
  stopifnot(is.ppp(V))
  # ensure 'opt' contains all required entries and resolve defaults
  nullopt <- locppmOptions(cg=TRUE, Tg=TRUE, v0=!is.null(dropterm))
  opt <- resolve.defaults(as.list(opt), as.list(nullopt))
  # get information about *available* options
  LOT <- .locppmOptionTable
  tags        <- LOT$tags
  usefft      <- LOT$usefft
  dimtype     <- LOT$dimtype 
  iscoef      <- (LOT$calctype == "c")
  implemented <- LOT$implemented
  requirefast <- LOT$requirefast
  modeltype   <- LOT$modeltype
  calctype    <- LOT$calctype
  calcname    <- LOT$calcname
  # Detect options that are not yet implemented:
  if(any(nbg <- unlist(opt[tags[!implemented]]))) {
    nama <- names(nbg)[nbg]
    nbad <- sum(nbg)
    warning(paste(ngettext(nbad, "Option", "Options"),
                  commasep(sQuote(nama)),
                  ngettext(nbad, "is", "are"),
                  "not yet implemented"))
  }
  if(!fastRCinloop && any(needfast <- unlist(opt[tags[requirefast]]))) {
    tagz <- names(needfast)[needfast]
    desired <- paste(LOT$descrip[tagz], collapse=" or ")
    warning(paste("Slow code (fastRCinloop=FALSE) does not compute",
                  paste0(desired, ";"), "using fast code instead"))
    fastRCinloop <- TRUE
  }
  # Decide on type(s) of calculation
  # Should we fit the local GLM at each location?
  need.localfit <- any(unlist(opt[tags[modeltype == "l" & !usefft]]))
  # Do we need some kind of iteration over locations?
  need.iteration <- any(unlist(opt[tags[!usefft]]))
  # Do we need to update/refit/change the original model in any way?
  need.update <- any(unlist(opt[tags[modeltype != "h"]]))
  #
  # ... setup ........................
  coef.hom <- coef(model)
  nama <- names(coef.hom)
  ncoef <- length(coef.hom)
  ncoef2 <- ncoef^2
  #
  nV <- npoints(V)
  Vx <- V$x
  Vy <- V$y
  # initialise results
  for(tn in tags) assign(tn, NULL)
  # i.e.   cg <- vg <- tg <- ... <- NULL
  if(any(unlist(opt[tags[dimtype == "scalar"]]))) {
    # create template storage for scalars
    sc.blank <- numeric(nV)
  }
  if(need.localfit || any(unlist(opt[tags[dimtype == "vector"]]))) {
    # create template storage for coefficients and t-statistics
    ct.blank <- matrix(NA_real_, nrow=nV, ncol=ncoef)
    colnames(ct.blank) <- nama
  }
  if(any(unlist(opt[tags[dimtype == "matrix"]]))) {
    # create template storage for variance matrices
    v.blank <-  matrix(NA_real_, nrow=nV, ncol=ncoef2)
    colnames(v.blank) <- as.vector(outer(nama, nama, paste, sep="."))
  }
  # actually assign storage
  if(need.localfit) cg <- ct.blank
  for(i in seq_along(tags)) {
    if(opt[[i]]) {
      blanki <- switch(dimtype[i],
                       matrix = v.blank,
                       vector = ct.blank,
                       scalar = sc.blank)
      assign(tags[i], blanki)
    }
  }

  # .....................................
  # start computin'
  # .....................................

  if(is.null(internals)) {
    # precompute internal data for Rubak-Coeurjolly estimates?
    # Yes if we have to compute Variance, Fisher info or t-statistic
    need.internals <-
      tags[calctype %in% c("v", "f", "t", "X") & ((!usefft & fastRCinloop) |
                                             (usefft  & !is.poisson(model)))]
    if(any(unlist(opt[need.internals]))) 
      internals <- getvcinternals(model, verbose=verbose)
  }
  
  env.here <- sys.frame(sys.nframe())
  m <- getglmfit(model)
  if(is.null(m)) stop("model has no glm fit")
  env.model <- environment(terms(m))
  env.update <- environment(formula(m))
  if(need.update) {
    # manipulate environments so that the update will work
    fmla     <- get("fmla",     envir=env.model)
    gcontrol <- get("gcontrol", envir=env.model)
    glmdata  <- get("glmdata", envir=env.model)
    assign("coef.hom", coef.hom, envir=env.update)
    # to pacify package checker
    .mpl.W <- glmdata$.mpl.W
    .mpl.Y <- glmdata$.mpl.Y
    if(opt$v0) {
      if(is.null(dropterm))
        stop("Argument dropterm is missing")
      # construct GLM formula representing null model
      dropfmla <- paste(". ~ . - ", dropterm)
      assign("dropfmla", dropfmla, envir=env.update)
      # evaluate null model
      m0 <- update(m, dropfmla, evaluate=FALSE)
      m0 <- try(eval(m0, enclos=env.model, envir=env.here), silent=TRUE)
      if(inherits(m0, "try-error"))
        stop("Internal error: evaluation of null model failed")
      coef.hom0 <- coef(m0)
      assign("coef.hom0", coef.hom0, envir=env.update)
      # determine injection of coefficients of null into alternative
      nullmap <- match(names(coef.hom0), nama)
      if(any(is.na(nullmap)))
        stop("Internal error: cannot match coefficients of null to alternative")
      zerocoef <- rep(0, ncoef)
      names(zerocoef) <- nama
    }
  }

  if(any(unlist(opt[tags[usefft]]))) {
    # FFT calculations
    if(verbose) 
      cat("Performing FFT calculations...")
    # calculations based on homogeneous intensity
    ffthom <- tags[usefft & (modeltype == "h" | iscoef)]
    # calculations based on Taylor approximation to locally fitted intensity
    fftapp <- tags[usefft & modeltype == "l" & !iscoef]
    if(any(unlist(opt[fftapp])))
      opt$cg1 <- TRUE
    # 
    if(any(opt.hom <- unlist(opt[ffthom]))) {
      # calculations using homogeneous intensity
      tags.do <- names(opt.hom[opt.hom])
      HF <- locppmFFT(model, sigma=sigma, ..., 
                      what=calcname[tags %in% tags.do],
                      internals=internals,
                      algorithm=fft.algorithm,
                      verbose=verbose)
      # Extract values at locations V
      if(opt$cg1) cg1 <- sample.imagelist(HF$coefficients, V)
      if(opt$vh1) vh1 <- sample.imagelist(HF$variance,     V)
      if(opt$fh1) fh1 <- sample.imagelist(HF$fisher,       V)
      if(opt$sh1) sh1 <- sample.imagelist(HF$score,        V)
      if(opt$gh1) gh1 <- sample.imagelist(HF$gradient,     V)
    } 
    if(any(opt.app <- unlist(opt[fftapp]))) {
      # calculations using Taylor approximation to locally fitted intensity
      tags.do <- names(opt.app[opt.app])
      # extract Taylor approximations to coefficients at each quadrature point
      coTay <- sample.imagelist(HF$coefficients, union.quad(quad.ppm(model)))
      # compute approximate fitted intensity
      lamT <- locppmPredict(model, coTay)
      # discard intensity values, computed for different model
      forbid <- c("lambda", "lamdel")
      internals.clean <- internals[!(names(internals) %in% forbid)]
      # plug into FFT calculation
      TF <- locppmFFT(model, sigma=sigma,
                      lambda=lamT, ...,
                      what=calcname[tags %in% tags.do],
                      internals=internals.clean, 
                      algorithm=fft.algorithm, verbose=verbose)
      # Extract values at locations V
      if(opt$vg1) vg1 <- sample.imagelist(TF$variance,   V)
      if(opt$tg1) tg1 <- sample.imagelist(TF$tstatistic, V)
      if(opt$gg1) gg1 <- sample.imagelist(TF$gradient,   V)
    } 
    if(verbose) cat("Done.\n")
  }

  if(need.iteration) {
    # ............. Compute estimates by local fitting .................
    
    # full pattern of quadrature points 
    U <- union.quad(quad.ppm(model))
    nU <- npoints(U)
    Ux <- U$x
    Uy <- U$y

    if(opt$Lg) {
      ## precompute values for likelihood ratio test
      lambda.hom <- fitted(m)
      log.lambda.hom <- log(ifelse(lambda.hom > 0, lambda.hom, 1))
    }

    if(verbose)
      cat(paste("Processing", nV, scopename, "...\n"))

    for(j in 1:nV) {
      if(verbose)
        progressreport(j, nV)
      localwt <- dnorm(Ux - Vx[j], sd=sigma) * dnorm(Uy - Vy[j], sd=sigma)
      if(need.localfit) {
        assign("localwt", localwt, envir=env.update)
        fitj <- update(m, weights = .mpl.W * localwt, start=coef.hom,
                       evaluate=FALSE)
        fitj <- try(eval(fitj, enclos=env.model, envir=env.here), silent=TRUE)
        if(!inherits(fitj, "try-error") && fitj$converged) {
          # fitted coefficients
          cg[j, ] <- coefj <- coef(fitj)
          # Poincare t-statistic for each parameter (using Hessian)
          if(opt$Tg)
            Tg[j,] <- coef(summary(fitj))[,3]
          # local likelihood ratio test statistic for test of homogeneity
          if(opt$Lg) {
            lambda.j <- fitted(fitj)
            log.lambda.j <- log(ifelse(lambda.j > 0, lambda.j, 1))
            locW <- .mpl.W * localwt
            logLhom <- sum(locW * (.mpl.Y * log.lambda.hom - lambda.hom))
            logLj   <- sum(locW * (.mpl.Y * log.lambda.j   - lambda.j))
            Lg[j] <- 2 * (logLj - logLhom)
          }
          # variance of local parameter estimates under local model
          # (for confidence intervals)
          if(opt$Vg) { # Poincare variance of local fit
            # Note that for a GLM with weights,
            # vcov.glm returns the inverse of the negative Hessian
            Vgj <- try(vcov(fitj, dispersion=1), silent=TRUE)
            if(!inherits(Vgj, "try-error") && !is.null(Vgj)) 
              Vg[j,] <- as.vector(Vgj)
          }
          if(opt$vg || opt$tg) {
            # Rubak-Coeurjolly type estimate of variance of local fit
            if(fastRCinloop) {
              vgj <- vcovlocEngine(internals, localwt,
                                   A1dummy=TRUE, new.coef=coefj)
            } else {
              vgj <- there.is.no.try(vcov(model,
                                          matwt=localwt, new.coef=coefj,
                                          A1dummy=TRUE, matrix.action="silent"),
                                     silent=TRUE)
            }
            if(!is.null(vgj)) {
              if(opt$vg) vg[j,] <- as.vector(vgj)
              if(opt$tg) tg[j,] <- coefj/sqrt(diag(vgj))
            }
          }
        }
        if(opt$xg) {
          ## leave-one-out estimates of coefficients
          kk <- if(is.null(scopeindex)) j else scopeindex[j]
          ## V[j] = U[kk]
          if(glmdata[kk, ".mpl.Y"] > 0) { #' U[kk] is a data point
            fakedata <- glmdata
            fakedata[kk, ".mpl.Y"] <- 0 # pretend there's no data point at U[kk]
            assign("fakedata", fakedata, envir=env.model)
            fut.j <- update(m, data=fakedata,
                            weights = .mpl.W * localwt, start=coef.hom,
                            evaluate=FALSE)
            fut.j <- try(eval(fut.j, enclos=env.model, envir=env.here),
                         silent=TRUE)
            if(!inherits(fut.j, "try-error") && fut.j$converged) 
              xg[j, ] <- coef(fut.j)
          } else xg[j,] <- cg[j,]
        }
      }
      # variance of local parameter estimates under homogeneous model
      # (for tests of homogeneity)
      if(any(unlist(opt[c("vh", "fh", "gh", "sh", "Xh")]))) {
        if(fastRCinloop) {
          vhj <- vcovlocEngine(internals, localwt, A1dummy=TRUE,
                               bananas=opt$Xh)
          if(opt$gh) ghj <- attr(vhj, "Grad")
          if(opt$fh) fhj <- attr(vhj, "Fish")
          if(opt$sh) shj <- attr(vhj, "Score")
          if(opt$Xh) Xhj <- attr(vhj, "Cov")
        } else if(!opt$gh) {
          vhj <- try(vcov(model, matwt=localwt, A1dummy=TRUE,
                          matrix.action="silent"),
                     silent=TRUE)
          if(inherits(vhj, "try-error")) vhj <- NULL
          shj <- fhj <- Xhj <- NULL
        } else {
          tmp <- try(vcov(model, matwt=localwt, A1dummy=TRUE,
                          matrix.action="silent",
                          what="all"),
                     silent=TRUE)
          if(inherits(tmp, "try-error")) vhj <- ghj <- shj <- NULL else {
            vhj <- tmp$varcov
            ghj <- tmp$internals$gradient
          }
          shj <- fhj <- Xhj <- NULL
        }
        if(opt$vh && !is.null(vhj) &&
           length(as.vector(vhj)) == ncoef2)
          vh[j,] <- as.vector(vhj)
        if(opt$gh && !is.null(ghj) &&
           length(as.vector(ghj)) == ncoef2)
          gh[j,] <- as.vector(ghj)
        if(opt$fh && !is.null(fhj) &&
           length(as.vector(fhj)) == ncoef2)
          fh[j,] <- as.vector(fhj)
        if(opt$sh && !is.null(shj) &&
           length(as.vector(shj)) == ncoef)
          sh[j,] <- as.vector(shj)
        if(opt$Xh && !is.null(Xhj) &&
           length(as.vector(Xhj)) == ncoef2)
          Xh[j,] <- as.vector(Xhj)
      }
      # variance of local parameter estimates under local NULL model
      # (for local test of H_0: beta_k = 0)
      if(opt$v0) {
          # fit null model
        fit0j <- update(m, dropfmla,
                        weights = .mpl.W * localwt, start=coef.hom0,
                        evaluate=FALSE)
        fit0j <- try(eval(fit0j, enclos=env.model, envir=env.here), silent=TRUE)
        if(!inherits(fit0j, "try-error")) {
          # extract coefficients of null model
          c0j <- coef(fit0j)
          # inject into alternative
          coef0j <- zerocoef
          coef0j[nullmap] <- c0j
          # compute null variance of local parameter estimates
          if(fastRCinloop) {
            v0j <- vcovlocEngine(internals, localwt,
                                 A1dummy=TRUE, new.coef=coef0j)
          } else {
            v0j <- try(vcov(model, matwt=localwt, new.coef=coef0j,
                            A1dummy=TRUE, matrix.action="silent"),
                       silent=TRUE)
          }
          if(!inherits(v0j, "try-error") && !is.null(v0j) &&
             length(as.vector(v0j)) == ncoef2)
            v0[j,] <- as.vector(v0j)
        }
      }
    }
    # ........ end of loop over V .................................
    if(verbose) cat("Done.\n")
  }

  # convert format and/or add attributes
  make.ssf <- !matrices
  add.scope <- !is.null(scopeindex)
  add.scopename <- !is.null(scopename)
  if(make.ssf || add.scope) {
    for(tn in tags) {
      if(!is.null(thing <- get(tn))) {
        if(make.ssf) {
          thing <- ssf(V, thing)
          if(!is.null(weights)) attr(thing, "weights") <- weights
        }
        if(add.scope)
          attr(thing, "scopeindex") <- scopeindex
        if(add.scopename)
          attr(thing, "scopename") <- scopename
        assign(tn, thing)
      }
    }
  }
        
  result <- mget(tags)
  return(result)
}

# Locally-weighted Rubak-Coeurjolly estimate of variance

vcovlocEngine <- function(internals, localwt=NULL,
                          ...,
                          A1dummy=FALSE, new.coef = NULL,
                          bananas=FALSE) {
  # 'internals' has previously been validated.
  # Components include
  #     'mom'       model matrix 
  #     'lambda'    fitted intensity of the homogeneous model
  #     'Z'         data/dummy indicator
  #     'wQ'        quadrature weight
  #     'ok'        indicator of the domain of the pseudolikelihood
  #     'areaW'     area of the domain of the pseudolikelihood
  #     'nX'        number of data points
  #     'ispois'    TRUE if model is Poisson
  #     'hom.coef'  fitted coefficients of homogeneous model
  with(internals, {
    okX <- ok[Z]
    ncoef <- length(hom.coef)
    # Conditional intensity using the locally-fitted coefficients 'new.coef'
    if(!is.null(new.coef)) 
      lambda <- as.vector(lambda * exp(mom %*% (new.coef - hom.coef)))
    # Matrix A1
    momL <- mom * localwt
    A1 <- with(internals,
               if(A1dummy) sumouter(momL[ok, , drop=FALSE],
                                    w=(lambda * wQ)[ok])
               else sumouter(momL[Z & ok, , drop=FALSE]))
    # Gradient (sensitivity) matrix
    Grad <- with(internals,
               if(A1dummy) sumouter(mom[ok, , drop=FALSE],
                                    w=(localwt* lambda * wQ)[ok])
               else sumouter(mom[Z & ok, , drop=FALSE],
                             w = localwt[Z & ok]))
    #
    # Matrices A2 and A3
    if(ispois) {
      A2 <- A3 <- B2 <- B3 <- matrix(0, ncoef, ncoef)
    } else {
      # Require components 'lamdel' and 'momdel'
      #   lamdel[i,j]   = lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)])
      #   momdel[ ,i,j] = h(X[i] | X[-j])      = h(X[i] | X[-c(i,j)])
      # adjust lamdel for new coefficient
      if(!is.null(new.coef))
        lamdel <- lamdel * exp(tensor::tensor(new.coef - hom.coef, momdel, 1, 1))
      #   pairweight[i,j] = lamdel[i,j]/lambda[i] - 1 
      pairweight <- lamdel / lambda[Z] - 1
      #   momdelL[ , i, j] = localwt[i] * momdel[ , i, j]
      locwtX <- localwt[Z]
      momdelL <- momdel * rep(locwtX, rep(ncoef, nX))
      # now compute sum_{i,j} for i != j
      # pairweight[i,j] * outer(momdelL[,i,j], momdelL[,j,i])
      # for data points that contributed to the pseudolikelihood
      pwXok <- pairweight[okX, okX]
      locwtXok <- locwtX[okX]
      A2 <- sumsymouter(momdelL[, okX, okX], w=pwXok)
      if(bananas)
        B2 <- sumsymouter( momdel[, okX, okX], w=locwtXok * pwXok)
      # locally-weighted model matrix for data only
      momLX <- momL[Z, , drop=FALSE]
      # deltamomL[ ,i,j] = momLX[j,] - momdelL[,j,i]
      deltamomL <- aperm(rep(t(momLX), nX) - momdelL, c(1, 3, 2))
      A3 <- sumsymouter(deltamomL[, okX, okX])
      if(bananas) {
        momX  <- mom[Z, , drop=FALSE]
        deltamom <- aperm(rep(t(momX), nX) - momdel, c(1, 3, 2))
        nXok <- sum(okX)
        locwtXokMat <- matrix(locwtXok, nXok, nXok)
        B3 <- sumsymouter(deltamom[, okX, okX], w=locwtXokMat)
      }
    }
    ## Finally calculate the Rubak-Coeurjolly estimate:
    Sigma <- A1 + A2 + A3
    U <- try(solve(Grad/areaW))
    if(inherits(U, "try-error")) return(NULL)
    mat <- U %*% (Sigma/areaW) %*% U / areaW
    # add information
    attr(mat, "Grad") <- Grad
    attr(mat, "Fish") <- Sigma
    attr(mat, "Score") <- colSums((Z - lambda * wQ) * momL)
    if(bananas) attr(mat, "Cov") <- Grad + B2 + B3
    return(mat)
  })
}

getvcinternals <- function(model, verbose=TRUE) {
  # Compute the internal data needed for Rubak-Coeurjolly variance estimate
  if(verbose) cat("Computing internal variance data ...")
  ispois <- is.poisson(model)
  internals <- vcov(model, what="internals", saveterms=TRUE)
  needed <- c( c("lambda", "mom", "Z", "ok"),
              if(ispois) NULL else c("lamdel", "momdel"))
  hit <- needed %in% names(internals)
  if(!all(hit))
    stop(paste(ngettext(sum(!hit), "component", "components"),
               commasep(sQuote(needed[!hit])),
               "missing from internals"))
  # add more info
  wQ <- w.quad(quad.ppm(model))
  nX <- npoints(data.ppm(model))
  W <- as.owin(model)
  internals <- append(internals,
                      list(wQ=wQ, nX=nX, ispois=ispois, hom.coef=coef(model)))
  if(is.null(internals$areaW)) {
    internals$areaW <- if(model$correction == "border")
      eroded.areas(W, model$rbord) else area.owin(W)
  }
  if(verbose) cat("Done.\n")
  return(internals)
}

# ............. methods for locppm ................................

plot.locppm <- function(x, ...,
                        what="cg",
                        which=NULL) {
  xname <- deparse(substitute(x))
  if(!missing(what)) {
    what <- match.arg(what, row.names(.locppmOptionTable))
  } else {
    what <- FirstExtantEntry(x, c("cg", "cg1"), "Please specify argument what")
  }
  Z <- x[[what]]
  if(is.null(Z))
    stop(paste("Component", sQuote(what), "is unavailable"))
  if(!is.null(which))
    Z <- Z[, which]
  do.call("plot", resolve.defaults(list(x=Z),
                                   list(...),
                                   list(main=xname)))
}

print.locppm <- function(x, ...) {
  homfit <- as.ppm(x)
  splat("Local",
        if(is.poisson(homfit)) "likelihood" else "pseudolikelihood",
        "fit")
  splat("Template model:")
  splat(x$templatecall, "\n\n", indent=5)
  #' quadrature info
  qux <- quad.ppm(homfit)
  rez <- summary(qux)$resolution
  if(!is.null(rez)) {
    ndum <- npoints(qux$dummy)
    splat(ndum, "dummy points with spacing", format(rez))
  } else print(qux)
  #'
  splat("\nSmoothing parameter sigma: ",
        format(signif(x$sigma, 4) %unit% unitname(qux)),
        "\n")
  # Identify which values have been computed
  LOT <- .locppmOptionTable
  possible <- row.names(LOT)
  present <- possible %in% names(x)
  present[present] <- !unlist(lapply(x[possible[present]], is.null))
  if(any(present)) {
    tags    <- LOT$tags[present]
    explain <- LOT$descrip[present]
    scopes  <- unlist(lapply(lapply(x[tags], attributes),
                             getElement, name="scopename"))
    if(any(nbg <- !nzchar(scopes)))
      scopes[nbg] <- "unspecified locations"
    for(sc in unique(scopes)) {
      splat("Values computed at", sc)
      for(i in which(scopes == sc)) 
        splat(paste0(tags[i], ": ", explain[[i]]), indent=5)
    }
  }
  if(!is.null(ng <- x$ngrid))
    splat("Coarse grid:", paste(ensure2vector(ng), collapse=" x "))
  if(!is.null(ep <- x$grideps)) {
    uh <- unitname(x$homfit)
    splat("Coarse grid: spacing", format(ep %unit% uh))
  }
  if(!is.null(p1t <- x$phase1time))
    splat("Time taken for first phase:", codetime(p1t))
  return(invisible(NULL))
}

contour.locppm <- function(x, ...,
                           what="cg",
                           which=NULL) {
  xname <- deparse(substitute(x))
  if(!missing(what)) {
    what <- match.arg(what, row.names(.locppmOptionTable))
  } else {
    what <- FirstExtantEntry(x, c("cg", "cg1"), "Please specify argument what")
  }
  Z <- x[[what]]
  if(is.null(Z))
    stop(paste("Component", sQuote(what), "is unavailable"))
  W <- rescue.rectangle(as.owin(Z))
  if(!is.null(which))
    Z <- Z[, which]
  Z <- Smooth(Z, ...)
  do.call("contour", resolve.defaults(list(x=Z),
                                      list(...),
                                      list(main=xname)))
  invisible(NULL)
}

Smooth.locppm <- function(X, ..., what="cg") {
  stopifnot(inherits(X, "locppm"))
  if(!missing(what)) {
    what <- match.arg(what, row.names(.locppmOptionTable))
  } else {
    what <- FirstExtantEntry(X, c("cg", "cg1"), "Please specify argument what")
  }
  Y <- X[[what]]
  if(is.null(Y)) return(NULL)
  A <- as.ppp(Y)
  ok <- attr(Y, "ok")
  A <- A[ok]
  sigma0 <- if(any(c("sigma", "varcov") %in% names(list(...))))
            NULL else 1.4 * max(nndist(A))
  out <- do.call("Smooth.ppp",
                 resolve.defaults(list(X = A),
                                  list(...),
                                  list(sigma=sigma0)))
  return(out)
}

coef.locppm <- function(object, ...,
                        which=c("local", "homogeneous")) {
  which <- match.arg(which)
  result <- with(object,
                 switch(which,
                        homogeneous = coef(homfit),
                        local       = {
                          if(!is.null(cg)) cg else cg1
                        }))
  return(result)
}

confint.locppm <- function (object, parm, level = 0.95, ...,
                            which=c("local", "homogeneous")) 
{
  stopifnot(inherits(object, "locppm"))
  which <- match.arg(which)
  ispois <- is.poisson(object)
  cf <- coef(object$homfit)
  pnames <- names(cf)
  if (missing(parm)) 
    parm <- pnames
  else if (is.numeric(parm)) 
    parm <- pnames[parm]
  if(which == "homogeneous")
    return(confint(object$homfit, parm, level, ...))
  nparm <- length(parm)
  a <- (1 - level)/2
  a <- c(a, 1 - a)
  pct <- paste(format(100 * a, trim = TRUE,
                      scientific = FALSE, digits = 3), 
               "%")
  fac <- qnorm(a)
  # local var-cov matrices
  v <- object$vg
  if(is.null(v)) {
    v <- object$Vg
    if(is.null(v))
      stop("Fitted model does not contain variances")
    else
      warning("Using Poincare variance (Hessian matrix)")
  }
  vindex <- attr(v, "scopeindex")
  v <- marks(v)
  # extract standard deviations
  diagindex <- diag(matrix(1:(nparm^2), nparm, nparm))
  sd <- sqrt(v[, diagindex, drop=FALSE])
  # create space for result
  ci <- matrix(NA_real_, nrow=nrow(v), ncol = 2 * nparm)
  colnames(ci) <- as.vector(t(outer(parm, pct, paste)))
  # extract coefficients at same locations
  coefs <- object$cg
  cindex <- attr(coefs, "scopeindex")
  if(!identical(cindex, vindex)) {
    # v is computed on a coarser set of points
    coarse.to.fine <- object$coarse.to.fine
    coefs <- coefs[coarse.to.fine, ]
  }
  co <- marks(coefs)
  P  <- unmark(coefs)
  if(nrow(co) != nrow(v))
    stop("Internal error: mismatch in arrays")
  # calculate confidence intervals
  for(i in seq_len(nrow(v))) 
    ci[i,] <- rep(co[i,], rep(2, nparm)) +
              rep(sd[i, ],   rep(2, nparm)) * rep(fac, nparm)
  # pack up
  ssf(P, ci)
}

as.ppm.locppm <- function(object) {
  return(object$homfit)
}

as.interact.locppm <- function(object) {
  as.interact(as.ppm(object))
}

fitted.locppm <- function(object, ...,
                          type=c("cif", "trend", "intensity"),
                          new.coef=NULL) {
  trap.extra.arguments(...)
  type <- match.arg(type)
  lam <- predict(object, type=type, new.coef=new.coef)
  return(marks(lam))
}

predict.locppm <- function(object, ...,
                           type=c("cif", "trend", "intensity"),
                           locations=NULL, new.coef=NULL) {
  # minimal implementation
  trap.extra.arguments(...)
  type <- match.arg(type)
  # Extract homogeneous/template model
  homfit <- as.ppm(object)
  # Fitted local coefficients (could be NULL)
  coefs <- coef(object, what="local")
  # Prediction locations
  if(is.null(locations)) {
    # Use locations of fitted local coefficients
    if(is.null(coefs)) stop("Unable to determine locations for prediction")
    locations <- unmark(coefs)
  } else stopifnot(is.ppp(locations))
  # Local coefficients
  if(is.null(new.coef)) {
     # Extract local coefficients 
    if(is.null(coefs)) stop("Object does not include any fitted coefficients")
    coefmat <- marks(coefs)
  } else {
    # New values for local coefficients
    p <- length(coef(as.ppm(object)))
    nloc <- npoints(locations)
    if(is.matrix(new.coef)) {
      if(ncol(new.coef) != p)
        stop("Incorrect number of columns in new.coef")
      if(nrow(new.coef) != nloc)
        stop("Incorrect number of rows in new.coef")
      coefmat <- new.coef
    } else {
      if(length(new.coef) == p) {
        # replicate
        coefmat <- matrix(new.coef, nloc, p, byrow=TRUE)
      } else stop("Incorrect length in new.coef")
    }
  }
  # Check that local coefficients were computed at the quadrature points
  if(is.null(new.coef) &&
     identical(attr(coefs, "scopename"), "quadrature points")) {
    precomputed <- NULL # use defaults
  } else {
    mom <- sample.imagelist(model.images(homfit), locations)
    precomputed <- list(hom.coef = coef(homfit),
                        mom = mom)
    switch(type,
           cif = {
             precomputed$lambda <- predict(homfit, locations=locations)
           },
           trend = ,
           intensity = {
             precomputed$trend <- predict(homfit, locations=locations,
                                          type="trend")
           })
  }
  # compute
  values <- locppmPredict(homfit, coefmat, type=type, precomputed=precomputed)
  return(ssf(locations, values))
}

locppmPredict <- function(homfit, coefs,
                          type = c("cif", "trend", "intensity"),
                          precomputed=NULL, details=FALSE,
                          index = NULL) {
  stopifnot(is.ppm(homfit))
  stopifnot(is.matrix(coefs))
  type <- match.arg(type)
  # Start by computing fitted conditional intensity of homogeneous model
  # This ensures correct handling of offsets etc
  coef0   <- precomputed$hom.coef %orifnull%  coef(homfit)
  mom     <- precomputed$mom      %orifnull%  model.matrix(homfit)
  switch(type,
         cif = {
           result0 <- precomputed$lambda %orifnull% fitted(homfit)
         },
         trend = ,
         intensity = {
           result0 <- precomputed$trend %orifnull% fitted(homfit, type="trend")
         })
  if(!is.null(index)) {
    ## restrict to subset of quadrature points U[index]
    result0 <- result0[index] 
    mom     <- mom[index,,drop=FALSE]
  }
  # compute change in linear predictor
  d.coef <- coefs - matrix(coef0, nrow(coefs), ncol(coefs), byrow=TRUE)
  if(type != "cif") {
    # ignore interaction terms
    Vnames <- homfit$internal$Vnames
    d.coef[, Vnames] <- 0
  }
  # adjust fitted conditional intensities according to changed coefficients
  d.eta <- rowSums(mom * d.coef)
  result <- result0 * exp(d.eta)
  #
  if(type == "intensity")
    stop("Poisson-saddlepoint approximation is not yet implemented")
  #
  ans <- result
  if(details)
    attr(ans, "d.eta") <- d.eta
  return(ans)
}


is.poisson.locppm <- function(x) { is.poisson(x$homfit) }


# local 't' statistic for one coefficient in model
ttestmap <- function(object, term, ...,
                     method = c("exact", "hessian", "taylor"),
                     grid = FALSE,
                     ngrid=NULL, grideps=NULL,
                     verbose=TRUE) {
  starttime <- proc.time()
  method <- match.arg(method)
  stopifnot(inherits(object, "locppm"))
  homfit <- object$homfit
  coef.hom <- coef(homfit)
  nama <- names(coef.hom)
  # validate 'term'
  stopifnot(is.character(term))
  gfit <- getglmfit(homfit)
  tlab <- attr(terms(gfit), "term.labels")
  tpos <- match(term, tlab)
  if(is.na(tpos))
    stop(paste(sQuote(term), "is not a term in the model formula"))
  ass <- attr(model.matrix(gfit), "assign")
  relevant <- which(ass == tpos)
  if(length(relevant) == 0)
    stop("Internal error: cannot match the term to its canonical coefficients")
  if(length(relevant) > 1 && method == "exact")
    stop(paste("For Gibbs models, the exact method is not yet implemented",
               "for multidimensional parameters;",
               "the term", sQuote(term),
               "corresponds to", length(relevant), "parameters",
               commasep(sQuote(nama[relevant]))))
  parm <- nama[relevant]
  iparm <- relevant
  #
  # Which t statistic?
  tname <- switch(method,
                  exact   = "tg",
                  hessian = "Tg",
                  taylor  = "tg1")
  # Is it already available?
  if(!grid && !is.null(tvalues <- object[[tname]])) {
    result <- tvalues[,parm]
    result <- timed(result, starttime=starttime)
    return(result)
  }
  # Further computation required
  coefs <- coef(object)
  sigma <- object$sigma
  P <- unmark(coefs)
  wP <- attr(coefs, "weights")
  # determine points for evaluation
  if(!grid) {
    # use all quadrature points
    Puse <- P
    wPuse <- wP
    scopename <- "quadrature points"
    coarse.to.fine <- seq_len(npoints(P))
  } else {
    # use an approximate grid
    if(is.null(ngrid) && is.null(grideps) && object$locations == "split") {
      # use existing 'grid'
      coarse.to.fine <- object$coarse.to.fine
    } else {
      # generate new 'grid'
      coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=grideps, weights=wP)
    }
    Puse <- P[coarse.to.fine]
    wPuse <- attr(coarse.to.fine, "weights")
    scopename <- "grid points"
  }
  # Compute
  opt <- switch(method,
                exact   = locppmOptions(tg  = TRUE),
                taylor  = locppmOptions(tg1 = TRUE),
                hessian = locppmOptions(Tg = TRUE))
  z <- locppmEngine(homfit, sigma, Puse, weights=wPuse, 
                    opt=opt, scopename=scopename,
                    verbose=verbose)
  tvalues <- z[[tname]]
  result <- tvalues[,parm]
  result <- timed(result, starttime=starttime)
  return(result)
}

# (signed square root of) local score test statistic
# for test of homogeneity.

homteststat <- function(object, ..., verbose=FALSE) {
  # 'object' can be either a locppm or a homtestmap
  if(inherits(object, "locppm")) {
    Tv <- homtestmap(object, ..., verbose=verbose)
  } else if(inherits(object, "homtestmap")) {
    Tv <- update(object, ...)
  } else stop("Unrecognised format for object")
  starttime <- proc.time()
  Sv <- if(ncol(marks(Tv)) > 1) sqmag(Tv) else Tv
  S <- integral(Sv)/area(Window(Sv))
  timetaken <- proc.time() - starttime + attr(Tv, "timetaken")
  S <- timed(S, timetaken=timetaken)
  attr(S, "nsample") <- npoints(Sv)
  return(S)
}

update.homtestmap <-
  function(object, ...,
           what=NULL, test=NULL, ladjust=NULL,
           calibrate=NULL, saveall=FALSE, poolmoments=NULL) {
  starttime <- proc.time()
  trap.extra.arguments(...)
  stopifnot(inherits(object, "homtestmap"))
  ## arguments default to their current values in the object
  info <- attr(object, "info")
  oldwhat <- info$what %orifnull% "components"
  oldtest <- info$test %orifnull% "score"
  oldcalibrate <- info$calibrate %orifnull% "Satterthwaite"
  oldladjust   <- info$ladjust   %orifnull% "none"
  oldpoolmoments <- !identical(info$poolable, FALSE)
  if(is.null(what)) what <- oldwhat 
  if(is.null(test)) test <- oldtest 
  if(is.null(calibrate)) calibrate <- oldcalibrate
  if(is.null(ladjust)) ladjust <- oldladjust 
  if(is.null(poolmoments)) poolmoments <- oldpoolmoments
  what <- match.arg(what, c("components", "statistic", "pvalue"))
  test <- match.arg(test, c("score", "taylor", "likelihood"))
  calibrate <- match.arg(calibrate, c("chisq", "Satterthwaite", "firstmoment"))
  ladjust <- match.arg(ladjust, c("none", "moment", "PSS"))
  poolmoments <- as.logical(poolmoments)
  #' interpret arguments
  do.test <- (what %in% c("statistic", "pvalue"))
  likely <- test %in% c("likelihood", "taylor")
  adjusting <- (do.test && likely && ladjust != "none")
  newinfo <- replace(info,
                     c("what", "test", "calibrate", "ladjust",
                       "poolmoments", "adjusting"),
                     list(what, test, calibrate, ladjust,
                          poolmoments, adjusting))
  # is complete data available?
  if(!is.null(localdata <- attr(object, "localdata"))) {
    # yes - compute whatever is required
    resultvalues <- HomTestMapEngine(localdata, newinfo)
    P <- unmark(object)
    result <- ssf(P, resultvalues)
    class(result) <- c("homtestmap", class(result))
    attr(result, "info") <- newinfo
    if(saveall) attr(result, "localdata") <- localdata
    result <- timed(result, starttime=starttime)
    return(result)
  }
  # check compatibility
  sameladjust    <- (ladjust == oldladjust) 
  samecalibrate <- (calibrate == oldcalibrate) &&
                   (poolmoments == oldpoolmoments || calibrate == "chisq")
  sametestname <- (test == oldtest)
  sametestdetails <- switch(test,
                            score = TRUE,
                            taylor = samecalibrate,
                            likelihood = sameladjust && samecalibrate)
  sametest <- sametestname && sametestdetails

  ## 
  if(!sametest)
    stop("Cannot convert between different tests: no saved data")

  ##
  if(what == oldwhat) return(object)
  
  if(oldwhat == "components" && what == "statistic" && test != "likelihood") {
    result <- sqmag(object)
    class(result) <- c("homtestmap", class(result))
    attr(result, "info") <- newinfo
    result <- timed(result, starttime=starttime)
    return(result)
  }

  if(what == "pvalue" && test == "score" && calibrate == "chisq") {
    switch(oldwhat,
           pvalue = return(object),
           statistic = {
             stat <- marks(object)
           },
           components = {
             stat <- marks(sqmag(object))
           })
    ncoef <- info$p 
    pvals <- pchisq(stat, df=ncoef, lower.tail=FALSE)
    result <- ssf(unmark(object), pvals)
    result <- timed(result, starttime=starttime)
    return(result)
  }
  
  stop("Cannot recover information: no saved data")
}

homtestmap <-  function(object, ...,
                        what = c("components", "statistic", "pvalue"),
                        test = c("score", "taylor", "likelihood"),
                        ladjust = c("none", "moment", "PSS"),
                        calibrate = c("chisq", "Satterthwaite", "firstmoment"),
                        simple = !is.null(theta0), 
                        theta0 = NULL, 
                        poolmoments = NULL,
                        sigma = NULL, 
                        saveall = FALSE, 
                        use.fft = TRUE, 
                        verbose = TRUE) {
  starttime <- proc.time()
  test <- match.arg(test)
  what <- match.arg(what)
  ladjust <- match.arg(ladjust)
  told.use.fft <- !missing(use.fft) && use.fft
  stopifnot(inherits(object, "locppm"))
  if(is.null(poolmoments)) poolmoments <- is.stationary(as.ppm(object))
  trap.extra.arguments(...)
  #' interpret arguments
  do.test <- (what %in% c("statistic", "pvalue"))
  likely <- test %in% c("likelihood", "taylor")
  adjusting <- do.test && likely && (ladjust != "none")
  #' calibration i.e. reference distribution for p-value
  miss.cal <- missing(calibrate)
  should.cal.chisq <- adjusting || (do.test && (test == "score"))
  should.cal.other <- do.test && (test != "score") && (ladjust == "none")
  if(miss.cal && should.cal.chisq) {
    #' score test statistic &
    #' adjusted composite likelihood ratio test statistic
    #' should be referred to chi-squared 
    calibrate <- "chisq"
  } else if(miss.cal && should.cal.other) {
    calibrate <- "Satterthwaite"
  } else {
    calibrate <- match.arg(calibrate)
    if(calibrate != "chisq" && should.cal.chisq) {
      statname <- if(test == "score") "Score test statistic" else
                  "Adjusted composite likelihood ratio test statistic" 
      warning(paste(statname, "should be referred to",
                    "the chi-squared distribution",
                    "by setting calibrate='chisq'"),
              call.=FALSE)
    }
    if(calibrate == "chisq" && should.cal.other) {
      warning(paste("Unadjusted likelihood-type statistic should be calibrated",
                    "by setting calibrate='firstmoment' or 'Satterthwaite'"),
              call.=FALSE)
    }
  }
  ispois <- is.poisson(object)
  if(test == "likelihood" && use.fft) {
    if(told.use.fft)
      stop("Cannot use FFT code for test='likelihood'")
    use.fft <- FALSE
  }
  # Determine whether variance calculation under H0 is required
  calc.pvals <- (what == "pvalue")
  calc.var <- calc.pvals || (test != "taylor")
  # Determine whether to assume a simple or composite null hypothesis
  nulltype <- if(simple) "simple" else "composite"
  if(calc.var && nulltype == "simple" && verbose)
    message("Note: calculation ignores the effect of estimating theta")
  if(!is.null(theta0) && use.fft) {
    use.fft <- FALSE
    if(told.use.fft) 
      stop("Cannot use FFT code when theta0 is given")
  }
  homfit <- object$homfit
  hom.coef <- coef(homfit)
  p <- ncoef <- length(hom.coef)
  if(is.null(sigma))
    sigma <- object$sigma

  vec.names <- names(hom.coef)
  mat.names <- as.vector(outer(vec.names, vec.names,
                               function(a,b){paste(a,b,sep=".")}))
  
  # determine what values are required
  # U = score, H = hessian, F = local Fisher info, L = local LRTS
  # X = cross-covariance 
  # taylor approximation to likelihood ratio requires H
  # adjusted composite likelihood ratio requires F, H
  # variance calculation for simple null requires F
  # variance calculation for composite null requires F, H and (if Gibbs) X
  # p-value for exact likelihood ratio requires F, H and (if Gibbs) X
  needed <- c(U = TRUE,
              F = saveall || calc.var,
              H = saveall || calc.pvals ||
                  (calc.var && nulltype == "composite") ||
                  (test=="taylor") || adjusting,
              L = saveall || (test == "likelihood"),
              X = !ispois && (calc.pvals ||
                              (calc.var && (nulltype == "composite"))))

  # try to use FFT results
  if(use.fft) {
    # check that required data are available
    ftable = c(U="sh1", F="fh1", H="gh1", L="NA", X="Xh1")
    missed <- unlist(lapply(object[ftable[needed]], is.null))
    if(any(missed)) {
      use.fft <- FALSE
      if(told.use.fft) {
        want.tags <- ftable[needed[missed]]
        want.desc <- with(.locppmOptionTable, descrip[tags %in% want.tags])
        gripe <- paste("Cannot use FFT code; object does not contain",
                       paste0(commasep(want.desc), ";"),
                       "refit the model with vcalc='hom' or 'lik'")
        warning(gripe, call.=FALSE)
      }
    }
  }
  # otherwise try to use data in object
  if(!use.fft) {
    ftable <- c(U="sh", F="fh", H="gh", L="Lg", X="Xh")
    missed <- unlist(lapply(object[ftable[needed]], is.null))
    names(missed) <- names(needed)[needed]
    if(needed["L"] && missed["L"])
      stop(paste("Cannot perform test='likelihood':",
                 "object does not contain",
                 "local likelihood ratio test statistic;",
                 "refit the model with vcalc='lik'"))
    use.object <- !any(missed) && is.null(theta0)
  }

  # OK, all parameters are decided
  resultinfo <- list(test=test, what=what, use.fft=use.fft, p=p,
                     sigma=sigma,
                     poolmoments=poolmoments,
                     poolable=is.stationary(as.ppm(object)),
                     calibrate=calibrate,
                     ladjust=ladjust,
                     nulltype = nulltype,
                     adjusting = adjusting,
                     saveall=saveall)

  # ................ START COMPUTING .......................................
  # .........  Compute the local score and other required matrices .........
  Fmat <- Hmat <- Umat <- VUmat <- Lvec <- Xmat <- NULL
  if(use.fft) {
    # use FFT results
    sh1 <- object$sh1
    Umat <- marks(sh1)
    P <- unmark(sh1)
    nP <- npoints(P)
    wP <- attr(sh1, "weights")
    if(needed["F"]) Fmat <- marks(object$fh1)
    if(needed["H"]) Hmat <- marks(object$gh1)
    if(needed["X"]) Xmat <- marks(object$Xh1)
  } else if(use.object) {
    # use values in object
    sh <- object$sh
    Umat <- marks(sh)
    P <- unmark(sh)
    nP <- npoints(P)
    wP <- attr(sh, "weights")
    if(needed["F"]) Fmat <- marks(object$fh)
    if(needed["H"]) Hmat <- marks(object$gh)
    if(needed["L"]) Lvec <- marks(object$Lg)
    if(needed["X"]) Xmat <- marks(object$Xh)
  } else {
    # compute directly (slower...)
    internals <- getvcinternals(homfit, verbose=verbose)
    # extract quadrature points used to fit model
    Q    <- quad.ppm(homfit, drop=TRUE)
    w    <- w.quad(Q)
    Z    <- is.data(Q)
    U    <- union.quad(Q)
    nU   <- npoints(U)
    wU <- w.quad(Q)
    Ux <- U$x
    Uy <- U$y
    ok <- getglmsubset(homfit)
    suf <- model.matrix(homfit)[ok, , drop=FALSE]
    # fitted intensity of homogeneous model
    lam <- fitted(homfit, drop=TRUE, new.coef=theta0)
    # increments of residual measure of homogeneous fit
    homresid <- Z - lam * w
    #
    if(ispois) {
      # use all quadrature points
      P <- U
      wP <- wU
      scopename <- "quadrature points"
      coarse.to.fine <- seq_len(nU)
    } else {
      # use coarse grid
      # find components inside the object which are 'ssf'
      izsf <- unlist(lapply(object, inherits, what="ssf"))
      sfs <- object[izsf]
      # count number of points in each ssf object
      nps <- unlist(lapply(sfs, npoints))
      # select smallest number of points
      ibest <- which.min(nps)
      bestname <- names(sfs)[ibest]
      best <- object[[bestname]]
      P <- unmark(best)
      wP <- attr(best, "weights")
      scopename <- attr(best, "scopename") %orifnull% "grid points"
      coarse.to.fine <- object$coarse.to.fine
    }
    nP <- npoints(P)
    Px <- P$x
    Py <- P$y
    # create space
    ncoef <- length(hom.coef)
    Umat <- matrix(, nrow=nP, ncol=ncoef, dimnames=list(NULL, vec.names))
    if(needed["F"]) Fmat <- matrix(, nrow=nP, ncol=ncoef^2,
                                dimnames=list(NULL, mat.names))
    if(needed["H"]) Hmat <- matrix(, nrow=nP, ncol=ncoef^2,
                                dimnames=list(NULL, mat.names))
    if(needed["X"]) Xmat <- matrix(, nrow=nP, ncol=ncoef^2,
                                   dimnames=list(NULL, mat.names))
    #
    if(verbose)
      splat("Processing", nP, scopename)
    for(k in 1:nP) {
      if(verbose) 
        progressreport(k, nP)
      localwt <- dnorm(Ux - Px[k], sd=sigma) * dnorm(Uy - Py[k], sd=sigma)
      if(ispois) {
        # local score at P[k] for homogeneous model
        locscore <- matrix(localwt * homresid, nrow=1) %*% suf
        Umat[k,] <- locscore
        if(needed["F"] || needed["H"]) {
          # local Fisher information at P[k] for homogeneous model
          if(needed["F"]) {
            locfish <- sumouter(localwt * suf, w * lam)
            Fmat[k,] <- as.vector(locfish)
          }
          # local Hessian at P[k] for homogeneous model
          if(needed["H"]) {
            locHess <- sumouter(suf, w * lam * localwt)
            Hmat[k,] <- as.vector(locHess)
          }
        }
      } else {
        vcl <- vcovlocEngine(internals, localwt, A1dummy=TRUE, new.coef=theta0)
        Umat[k,] <- as.vector(attr(vcl, "Score"))
        if(needed["F"]) Fmat[k,] <- as.vector(attr(vcl, "Fish"))
        if(needed["H"]) Hmat[k,] <- as.vector(attr(vcl, "Grad"))
        if(needed["X"]) Xmat[k,] <- as.vector(attr(vcl, "Cov"))
      }
    }
    if(verbose) splat("\t Done.")
  }

  #' ...... Local variance calculation ...........................
  
  if(saveall || calc.var) {
    ## compute variance of local score at global estimate of theta
    switch(nulltype,
           simple = {
             ## theta is fixed.
             ## variance of local score
             VUmat <- Fmat
           },
           composite = {
             ## theta has been estimated.
             ## Calculate variance of
             ##    {local score evaluated at global estimate of theta}
             ##     allowing for estimation of theta 
             ##     assuming template model is true.
             usepois <- ispois || is.null(Xmat)
             if(!ispois && usepois)
               warning("cross-covariance term not calculated!")
             ## Variance of estimate for *template* model
             ##    var0 = H^{-1} I H^{-1}
             ## where I = information, H = gradient
             ## (H = G if poisson)
             if(usepois) {
               homV <- vcov(homfit)
             } else {
               a <- vcov(homfit, what="all")
               homV <- a$varcov
               homH <- a$internals$hessian %orifnull% a$internals$A1
             }
             ## Make it a flat matrix stack
             homVmat <- as.flat.matrix(homV, nP)
             ## Cross-covariance term(s)
             ## C(s) = H(s) var0 H(s)
             Cmat <- quadform2.flat.matrices(homVmat, Hmat,
                                             c(p,p), c(p,p))
             if(ispois || is.null(Xmat)) {
               VUmat <- Fmat - Cmat
             } else {
               ## D(d) = H(s) H^{-1} cov(local score, global score)
               invhomHmat <- as.flat.matrix(solve(homH), nP)
               Dmat <- multiply3.flat.matrices(Hmat, invhomHmat, Xmat,
                                               c(p,p), c(p,p), c(p,p))
               tDmat <- transpose.flat.matrix(Dmat, c(p,p))
               VUmat <- Fmat + Cmat - Dmat - tDmat
               ## 
               if(spatstat.options('developer')) {
                 ei <- eigenvalues.flat.matrix(VUmat, p)
                 bad <- apply(ei < 0, 1, any)
                 if(any(bad))
                   warning(paste0(signif(100 * mean(bad), 3),
                                  "% of matrices are not positive definite\n"))
               }
             }
           })
  }
  
  # ....   Assemble 'sufficient statistics' ...............
  
  localdata <- list(Fmat   = Fmat,
                    Hmat   = Hmat,
                    Umat   = Umat,
                    VUmat  = VUmat,
                    Lvec   = Lvec,
                    Xmat   = Xmat,
                    ncoef  = ncoef,
                    p      = p,
                    nP     = nP,
                    wts    = wP,
                    hom.coef = hom.coef)

  # ....  Compute the desired map (p-value, test statistic etc) .....

  resultvalues <- HomTestMapEngine(localdata, resultinfo)

  # ....  Wrap up ............................................

  result <- ssf(P, resultvalues)
  class(result) <- c("homtestmap", class(result))
  attr(result, "weights") <- wP
  #
  attr(result, "info") <- resultinfo
  if(saveall) attr(result, "localdata") <- localdata
  # 
  result <- timed(result, starttime=starttime)
  return(result)
}

print.homtestmap <- function(x, ...) {
  with(attr(x, "info"), {
    splat("Homogeneity test map (class 'homtestmap')")
    switch(test,
           score = {
             testname <- "Score Test"
             shortstat <- paste(testname, "Statistic")
           },
           taylor = {
             testname <- paste("Taylor approximation to",
                               "Composite Likelihood Ratio Test")
             shortstat <- "Approximate CLRTS"
             if(adjusting) {
               testname <- paste("Adjusted", testname)
               shortstat <- paste("Adjusted", shortstat)
             }
           },
           likelihood = {
             testname <- "Composite Likelihood Ratio Test"
             shortstat <- "CLRTS"
             if(adjusting) {
               testname <- paste("Adjusted", testname)
               shortstat <- paste("Adjusted", shortstat)
             }
           })
    statname <- paste(testname, "Statistic")
    vname <-
      switch(what,
             components = {
               issqrt <- (test != "likelihood")
               isvector <- issqrt && (p > 1) 
               paste0(if(isvector) "Vector components of " else "",
                      if(issqrt) "signed square root of " else "",
                      paste(testname, "Statistic"))
             },
             statistic = paste(testname, "Statistic"),
             pvalue    = paste("p-values for", testname))
    splat("\nFunction values:", vname)
    if(adjusting)
      switch(ladjust,
             moment = splat(shortstat, "adjusted by first moment matching"),
             PSS = splat(shortstat, "adjusted by Pace-Salvan-Sartori"),
             none = {})
    if(what == "pvalue")
      splat(
        "The p-values were obtained by referring the",
        shortstat, "to the",
        switch(calibrate,
               chisq = paste("chi-squared distribution with", p, "d.f."),
               Satterthwaite =
               "gamma distribution (Satterthwaite approx.)",
               firstmoment =
               "rescaled chi-squared distribution (first moment approx.)")
        )
  })
  cat("\n")
  NextMethod("print")
}


HomTestMapEngine <- function(x, info) {
  #' some of these may be NULL 
  Lvec  <- x$Lvec  # local pseudolikelihood
  Umat  <- x$Umat  # local pseudoscore
  VUmat <- x$VUmat # null variance of local pseudoscore
  Hmat  <- x$Hmat  # Hessian of local log pseudolikelihood
  p     <- x$p     # dimension of parameter
  wts   <- x$wts   # weights associated with sample locations
  hom.coef <- x$hom.coef # global estimate of theta under H0
  ncoef <- length(hom.coef)
  #'
  if(spatstat.options('developer')) {
    splat("homtestmap info:")
    print(unlist(info))
  }
  with(info, {
    ## .....  Now calculate test statistic .....................................
    switch(what,
           components = {
             ## compute components of 'square root' of local test statistic
             switch(test,
                    score = {
                      ## score test statistic
                      ## inverse square root of variance of local score
                      ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
                      ## premultiply local score
                      rootstat <- multiply2.flat.matrices(ISVmat, Umat,
                                                          c(p, p), c(p, 1))
                      colnames(rootstat) <- names(hom.coef)
                    },
                    taylor = {
                      ## Taylor approximation to local likelihood ratio test
                      ## inverse square root of variance of local Hessian
                      InvsqHmat <- handle.flat.matrix(Hmat, c(p, p), invsqrtmat)
                      ## premultiply local score
                      rootstat <- multiply2.flat.matrices(InvsqHmat, Umat,
                                                          c(p, p), c(p, 1))
                      colnames(rootstat) <- names(hom.coef)
                    },
                    likelihood = {
                      rootstat <- Lvec
                    })
           },
           pvalue = ,
           statistic = {
             ## compute local test statistic
             switch(test,
                    score = {
                      ## score test statistic
                      IVmat <- invert.flat.matrix(VUmat, p)
                      stat <- quadform2.flat.matrices(IVmat, Umat,
                                                      c(p,p), c(1,p))
                    },
                    taylor = {
                      ## Taylor approx of local likelihood ratio test statistic
                      IHmat <- invert.flat.matrix(Hmat, p)
                      stat <- quadform2.flat.matrices(IHmat, Umat,
                                                      c(p,p), c(1,p))
                    },
                    likelihood = {
                      stat <- Lvec
                    })
           })
    ## .....  Adjustment of (approximate) CLRTS .......................
    if(adjusting) {
      switch(ladjust,
             moment = {
               ## first moment matching adjustment
               GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                               c(p,p), c(p,p))
               E <- trace.flat.matrix(GinVmat, p)
               stat <- (ncoef/E) * stat
             },
             PSS = {
               ## Pace-Salvan-Sartori adjustment
               IVmat <- invert.flat.matrix(VUmat, p)
               scorestat <- quadform2.flat.matrices(IVmat, Umat,
                                                    c(p,p), c(1,p))
               IHmat <- invert.flat.matrix(Hmat, p)
               taylorstat <- quadform2.flat.matrices(IHmat, Umat,
                                                     c(p,p), c(1,p))
               stat <- (scorestat/taylorstat) * stat
             },
             none = { }
             )
    }
    ## .....  Null moments for calibration ...................................
    if(calibrate != "chisq" && test %in% c("likelihood", "taylor")) {
      if(poolmoments) {
        Hpool <- average.flat.matrix(Hmat, c(p, p), wts)
        VUpool <- average.flat.matrix(VUmat, c(p, p), wts)
        GinVpool <- solve(Hpool, VUpool)
        E <- sum(diag(GinVpool))
        if(calibrate == "Satterthwaite")
          V <- 2 * sum(diag(GinVpool %*% GinVpool))
      } else {
        GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                        c(p,p), c(p,p))
        E <- trace.flat.matrix(GinVmat, p)
        if(calibrate == "Satterthwaite") {
          GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat,
                                              c(p,p), c(p,p))
          V <- 2 * trace.flat.matrix(GinV2mat, p)
        }
      }
    }
    ## .....  Local p-values ...................................
    if(what == "pvalue") {
      switch(calibrate,
             chisq = {
               pvals <- pchisq(stat, df=ncoef, lower.tail=FALSE)
             },
             Satterthwaite = {
               shape <- E^2/V
               scale <- V/E
               pvals <- pgamma(stat, shape=shape, scale=scale,
                               lower.tail=FALSE)
             },
             firstmoment = {
               shape <- ncoef/2  ## i.e. chi^2, df=ncoef
               scale <- 2 * E/ncoef  ## rescaled so mean =  E
               pvals <- pgamma(stat, shape=shape, scale=scale,
                               lower.tail=FALSE)
             })
    }
    ## .....  Finally assemble the result ...................................
    resultvalues <- switch(what,
                           components = rootstat,
                           statistic  = stat,
                           pvalue     = pvals)
    return(resultvalues)
  })
}


sqmag <- function(x) {
  stopifnot(inherits(x, "ssf"))
  val <- marks(x)
  y <- matrix(rowSums(val^2), ncol=1)
  z <- ssf(unmark(x), y)
  attr(z, "weights") <- attr(x, "weights")
  return(z)
}


homtest <- function(X, ...,
                    nsim=19,
                    test = c("residuals", "score", "taylor", "likelihood"),
                    locations = c("coarse", "fine", "split"),
                    ladjust = NULL,
                    use.fft = NULL,
                    simul = NULL,
                    verbose = TRUE,
                    Xname=NULL) {
  starttime <- proc.time()
  if(is.null(Xname))
    Xname <- short.deparse(substitute(X))
  test <- match.arg(test)
  locations <- match.arg(locations)
  if(is.null(use.fft))
    use.fft <- (locations == "fine") && (test != "likelihood")
  stopifnot(is.ppp(X))
  argh <- list(...)
  # Text string representing the locppm call
  cl <- sys.call()
  if(!is.null(clnames <- names(cl))) {
    discard <- clnames %in% c("nsim", "test", "simul",
                              "verbose", "Xname", "ladjust", "calibrate")
    cl <- cl[!discard]
  }
  cl[[1]] <- as.name("locppm")
  cl <- format(cl)
  testname <- c("Monte Carlo test of homogeneity for", cl)
  testbase <- paste("based on", nsim, "simulations")
  #'
  ladjust <- if(is.null(ladjust)) "PSS" else
             match.arg(ladjust, c("none", "moment", "PSS"))
  ladjname <- if(ladjust == "none") "" else paste0(ladjust, "-adjusted ")
  #' 
  switch(test,
         likelihood = {
           methodname <- paste0("using ", ladjname,
                                "composite likelihood ratio test statistic")
           calcname <- if(use.fft) "computed by FFT" else "computed directly"
           doit <- function(Y, argh, locations, use.fft, ladjust) { 
             fit <- do.call(locppm,
                            c(list(Y),
                              argh,
                              list(vcalc="lik",
                                   locations=locations,
                                   use.fft=use.fft,
                                   verbose=FALSE)))
             h <- homteststat(fit, test="likelihood", ladjust=ladjust,
                              use.fft=use.fft, verbose=FALSE)
             return(h)
           }
         },
         taylor = {
           methodname <- paste0("using ", ladjname, "Taylor approximation to ",
                                "composite likelihood ratio test statistic")
           calcname <- if(use.fft) "computed by FFT" else "computed directly"
           doit <- function(Y, argh, locations, use.fft, ladjust) { 
             fit <- do.call(locppm,
                            c(list(Y),
                              argh,
                              list(vcalc="hom",
                                   locations=locations,
                                   use.fft=use.fft,
                                   verbose=FALSE)))
             h <- homteststat(fit, test="taylor", ladjust=ladjust,
                              use.fft=use.fft, verbose=FALSE)
             return(h)
           }
         },
         score = {
           methodname <- "using score test statistic"
           calcname <- if(use.fft) "computed by FFT" else "computed directly"
           doit <- function(Y, argh, locations, use.fft, ladjust) { 
             fit <- do.call(locppm,
                            c(list(Y),
                              argh,
                              list(vcalc="hom",
                                   locations=locations,
                                   use.fft=use.fft,
                                   verbose=FALSE)))
             h <- homteststat(fit, test="score",
                              use.fft=use.fft, verbose=FALSE)
             return(h)
           }
         },
         residuals = {
           methodname <- "using score residuals"
           calcname <- "computed directly"
           doit <- function(Y, argh, locations, use.fft, ladjust) {
             fit <- do.call(ppm, append(list(Y), argh))
             res <- residuals(fit, "score")
             smr <- Smooth(res)
             if(is.im(smr)) smr <- list(smr)
             sqr <- lapply(smr, "^", e2=2)
             sumsqr <- Reduce("+", sqr)
             h <- mean(sumsqr)
             attr(h, "nsample") <- n.quad(quad.ppm(fit))
             return(h)
           }
         })

  if(verbose) cat("Computing observed value...")
  obs <- doit(X, argh, locations=locations, use.fft=use.fft, ladjust=ladjust)
  if(verbose) cat("Done.\n")
  # extract info
  nsample <- attr(obs, "nsample")
  if(!is.null(nsample))
    calcname <- paste(calcname, "on", nsample, "sample points")
  # save for use in return value
  obs <- as.numeric(obs)
  names(obs) <- "S"
  # fit 'homogeneous' model
  homfit <- ppm(X, ...)
  # generate the simulated patterns
  if(is.null(simul)) {
    Xsim <- simulate(homfit, nsim=nsim, progress=verbose)
  } else if(is.expression(simul)) {
    Xsim <- list()
    if(verbose) cat(paste("Generating", nsim,
                          "simulated realizations by evaluating expression..."))
    for(i in 1:nsim)
      Xsim[[i]] <- eval(simul)
    if(!all(unlist(lapply(Xsim, is.ppp))))
      stop("Evaluating the expression did not yield a point pattern")
  } else if(is.list(simul)) {
    Xsim <- simul
    if(!all(unlist(lapply(Xsim, is.ppp))))
      stop("Entries in the list should be point patterns")
  } else stop("Unrecognised format of argument simul")
  # evaluate the statistic
  sim <- numeric(nsim)
  if(verbose) cat("Computing test statistics...")
  for(i in 1:nsim) {
    if(verbose) progressreport(i, nsim)
    sim[i] <- doit(Xsim[[i]], argh, locations=locations,
                   use.fft=use.fft, ladjust=ladjust)
  }
  if(verbose) cat("Done.\n")
  pval <- (1 + sum(sim >= obs))/(nsim+1)
  result <- list(statistic = obs,
                 p.value = pval,
                 alternative = "inhomogeneous",
                 method = c(testname, methodname, calcname, testbase),
                 data.name = Xname,
                 simulated = sim)
  class(result) <- "htest"
  attr(result, "homfit") <- homfit
  result <- timed(result, starttime=starttime)
  return(result)
}
 
bw.locppm <- function(...,
                      method = c("fft", "exact", "taylor"), 
                      srange = NULL, ns=9, sigma = NULL,
                      additive = TRUE,
                      verbose=TRUE) {
  starttime <- proc.time()
  parenv <- sys.parent()

  method <- match.arg(method)
  additive <- additive && (method == "taylor")

  # fit homogeneous model
  if(verbose) cat("Fitting homogeneous model... ")  
  homfit <- eval(substitute(ppm(..., forcefit=TRUE)), envir=parenv)
  if(is.multitype(homfit))
    stop("Sorry, cannot handle marked point processes yet")
  p <- length(coef(homfit))
  ispois <- is.poisson(homfit)

  if(verbose) cat("Computing model properties... ")
  
  # extract quadrature info
  X <- data.ppm(homfit)
  Q <- quad.ppm(homfit)
  U <- union.quad(Q)
  wQ <- w.quad(Q)
  Z <- is.data(Q)
  nX <- npoints(X)
  nU <- npoints(U)
  Xindex <- seq_len(nU)[Z]
  xU <- U$x
  yU <- U$y
  
  # save internal structures for use in prediction
  gfit <- getglmfit(homfit)
  gdat <- getglmdata(homfit)

  mm <- model.matrix(homfit)
  mmX <- mm[Z, , drop=FALSE]

  lambda0  <- fitted(homfit)
  coef0    <- coef(homfit)
  coef0mat <- matrix(coef0, nU, length(coef0), byrow=TRUE)
  
  # determine values of smoothing parameter to be assessed
  if(!missing(sigma) && !is.null(sigma)) {
    stopifnot(is.numeric(sigma))
    ns <- length(sigma)
  } else {
    if(is.null(srange)) {
      srange <- range(bw.diggle(X) * c(1/2, 4),
                      bw.frac(X, f=1/3))
    } else check.range(srange)
    sigma <- exp(seq(log(srange[1]), log(srange[2]), length=ns))
  } 

  # specify fitting options and pre-compute relevant data
  switch(method,
         fft = {
           ## Taylor approximation coefficients and gradient
           ## on quadrature points
           opt.taylor <- locppmOptions(cg1=TRUE, gg1=TRUE)
           #' precompute some values
           internals <- list(lambda=lambda0,
                             hom.coef=coef0,
                             mom=mm)
         },
         exact = {
           ## fit on quadrature points
           opt.quad <- locppmOptions(cg=TRUE)
           ## leave-one-out calculation on data points
           opt.data <- locppmOptions(xg=TRUE)
           internals <- NULL
         },
         taylor = {
           ## fit on quadrature points
           opt.quad <- locppmOptions(cg=TRUE)
           ## leverage approximation on data points using Hessian
           opt.data <- locppmOptions(Vg=TRUE)
           ## precompute internal data for variance estimates
           internals <- getvcinternals(homfit, verbose=verbose)
         })

  if(!ispois && method != "exact") {
    # pre-compute data for leverage approximation
    if(verbose) cat("Leverage... ")
    internals$coef <- internals$hom.coef
    a <- ppmInfluence(homfit, what=c("increments"), precomputed=internals)
    # change in canonical statistic for X[i] when X[j] is deleted
    ddS <- a$increm$ddS[ Z, Z, , drop=FALSE]
    # change in integral increment at U[i] when X[j] is deleted
    ddSincrements <- wQ * a$increm$ddSintegrand[ , Z, , drop=FALSE]
  }
  if(verbose) cat("Done.\n")

  ## allocate storage
  datasum <- dof <- intlam <- numeric(ns)

  ## fit using each value of sigma
  if(verbose) {
    cat(paste("Assessing", ns, "values of sigma... "))
    pstate <- list()
  }
  for(k in 1:ns) {
    sigk <- sigma[k]
    kernel0 <- 1/(2 * pi * sigk^2)
    switch(method,
           fft = {
             #' fit and Hessian approximated on quadrature points
             lpe <- locppmEngine(homfit, sigk, U, opt=opt.taylor,
                                 scopename="quadrature points",
                                 verbose=FALSE, internals=internals)
             #' fitted [conditional] intensity at each quadrature point
             lambda <- locppmPredict(homfit, marks(lpe$cg1),
                                     precomputed=internals, details=TRUE)
             d.eta <- attr(lambda, "d.eta")
             #' Hessian at data points
             hQ <- lpe[[ "gg1" ]]
             hX <- marks(hQ)[Z,,drop=FALSE]
             #' invert the Hessians
             vX <- invert.flat.matrix(hX, p)
           },
           exact = {
             #' fit on quadrature points
             lpe.quad <- locppmEngine(homfit, sigk, U, opt=opt.quad,
                                      scopename="quadrature points",
                                      verbose=FALSE, internals=internals)
             ## compute fitted conditional intensity at each quadrature point
             lambda <- locppmPredict(homfit, marks(lpe.quad$cg), 
                                     precomputed=internals, details=TRUE)
             #' leave-one-out fit on data points
             lpe.data <- locppmEngine(homfit, sigk, X, opt=opt.data,
                                      scopename="data points",
                                      scopeindex=Xindex,
                                      verbose=FALSE, internals=internals)
             ## leave-one-out estimates at data points
             lambdaXminus <- locppmPredict(homfit, marks(lpe.data$xg),
                                           index=Xindex,
                                           precomputed=internals, details=TRUE)
           },
           taylor = {
             #' fit on quadrature points
             lpe.quad <- locppmEngine(homfit, sigk, U, opt=opt.quad,
                                      scopename="quadrature points",
                                      verbose=FALSE, internals=internals)
             ## compute fitted conditional intensity at each quadrature point
             lambda <- locppmPredict(homfit, marks(lpe.quad$cg), 
                                     precomputed=internals, details=TRUE)
             d.eta <- attr(lambda, "d.eta")
             ## leverage approximation on data points
             lpe.data <- locppmEngine(homfit, sigk, X, opt=opt.data,
                                      scopename="data points",
                                      scopeindex=Xindex,
                                      verbose=FALSE, internals=internals)
             ## leverage approximation uses inverse Hessian at data points
             vX <- lpe.data[[ "Vg" ]]
             vX <- marks(vX)
           })
    
    # compute terms in cross-validation criterion
    datasum[k] <- sum(log(lambda[Z])) 
    intlam[k] <- if(anyNA(lambda)) Inf else sum(lambda * wQ)
    #'
    if(method == "exact") {
      dof[k] <- datasum[k] - sum(log(lambdaXminus))
    } else {
      ## compute 'leverage' approximation 
      if(ispois) {
        ##    log(lambda(x_i)) - log(lambda_{-i}(x_i))
        ##    ~ kernel(0) Z(x_i) V(x_i) Z(x_i)^T
        leve <- kernel0 * quadform2.flat.matrices(vX, mmX, c(p, p), c(1, p))
      } else {
        ##    log(lambda(x_i)) - log(lambda_{-i}(x_i))
        ##    ~ kernel(0) Z(x_i) V(x_i) Y(x_i)^T
        ## compute Y(x_i)
        dScore <- kernel0 * mmX
        lrat <- exp(d.eta) # adjustment factor for lambda
        seqX <- 1:nX
        for(j in seqX) {
          weiU <-
            dnorm(xU, mean=xU[j], sd=sigk) * dnorm(yU, mean=yU[j], sd=sigk)
          weiX <- weiU[seqX]
          A <- apply(weiX * ddS[, j, , drop=FALSE], c(2,3), sum)
          B <- apply(weiU * lrat * ddSincrements[ , j, , drop=FALSE],
                     c(2,3), sum)
          dScore[j,] <- dScore[j,] + A + B
        }
        leve <- bilinear3.flat.matrices(mmX, vX, dScore, c(1,p), c(p,p), c(1,p))
      }
      dof[k] <- if(!additive) sum(leve) else
                if(all(leve < 1)) -sum(log(1-leve)) else Inf
    }
    #' end of loop
    if(verbose) pstate <- progressreport(k, ns, state=pstate)
  }

  # cross-validation criterion
  gcv <- datasum - dof - intlam
  result <- bw.optim(gcv, sigma, iopt=which.max(gcv), cvname="cv",
                     dof=dof, intlam=intlam, datasum=datasum)
  attr(result, "method") <- method
  attr(result, "resolution") <- summary(quad.ppm(homfit))[["resolution"]]
  timed(result, starttime=starttime)
}

@


1.182
log
@predict method now handles 'type'
@
text
@d6 1
a6 1
#  $Revision: 1.181 $ $Date: 2016/10/01 05:14:37 $
d43 1
a43 1
  Q <- quad.ppm(homfit, drop=TRUE)
@


1.181
log
@added code for covariance estimation
@
text
@d6 1
a6 1
#  $Revision: 1.180 $ $Date: 2016/09/25 06:40:39 $
d65 2
a66 2
    opt.hom  <- locppmOptions(sh=TRUE, fh=TRUE, gh=TRUE)
    opt.lik  <- locppmOptions(sh=TRUE, fh=TRUE, gh=TRUE, Lg=TRUE)
d73 1
a73 1
    opt.hom  <- locppmOptions(sh1=TRUE, fh1=TRUE, gh1=TRUE)
d182 1
d192 1
d196 2
a197 1
  not.implemented <- character(0)
d214 2
a215 1
               x="xcoef")
d226 2
a227 1
               x="vector")
d237 1
d307 1
d320 3
a322 3
  if(!fastRCinloop && (opt$sh || opt$fh)) {
    desired <- LOT$descrip[c("sh","fh")[c(opt$sh, opt$fh)]]
    desired <- paste(desired, collapse=" or ")
d381 1
a381 1
      tags[calctype %in% c("v", "f", "t") & ((!usefft & fastRCinloop) |
d561 1
a561 1
      if(any(unlist(opt[c("vh", "fh", "gh", "sh")]))) {
d563 2
a564 1
          vhj <- vcovlocEngine(internals, localwt, A1dummy=TRUE)
d568 1
d574 1
a574 1
          shj <- fhj <- NULL
d584 1
a584 1
          shj <- fhj <- NULL
d598 3
d616 1
a616 1
          # compute null variance of score
d663 2
a664 1
                          A1dummy=FALSE, new.coef = NULL) {
d716 2
a717 1
      B2 <- sumsymouter( momdel[, okX, okX], w=locwtXok * pwXok)
d723 7
a729 3
      momX  <- mom[Z, , drop=FALSE]
      deltamom <- aperm(rep(t(momX), nX) - momdel, c(1, 3, 2))
      B3 <- sumsymouter(deltamom[, okX, okX], w=locwtXok * (pwXok != 0))
a737 1
    attr(mat, "Cov") <- Grad + B2 + B3
d740 1
d960 3
a962 1
fitted.locppm <- function(object, ..., new.coef=NULL) {
d964 2
a965 1
  lam <- predict(object, new.coef=new.coef)
d969 3
a971 1
predict.locppm <- function(object, ..., locations=NULL, new.coef=NULL) {
d974 1
d1010 1
a1010 1
    precomputed <- NULL
a1011 1
    lambda0 <- predict(homfit, locations=locations)
d1013 11
a1023 3
    precomputed <- list(lambda   = lambda0,
                        hom.coef = coef(homfit),
                        mom      = mom)
d1026 1
a1026 1
  values <- locppmPredict(homfit, coefmat, precomputed=precomputed)
d1030 3
a1032 1
locppmPredict <- function(homfit, coefs, precomputed=NULL, details=FALSE,
d1036 1
a1038 1
  lambda0 <- precomputed$lambda   %orifnull%  fitted(homfit)
d1041 8
d1051 1
a1051 1
    lambda0 <- lambda0[index]
d1056 6
d1063 6
a1068 2
  # adjust fitted intensities according to changed coefficients
  ans <- lambda0 * exp(d.eta)
d1350 1
d1354 2
a1355 2
  # variance calculation for composite null requires F, H
  # p-value for exact likelihood ratio requires F, H
d1361 3
a1363 1
              L = saveall || (test == "likelihood"))
d1368 1
a1368 1
    ftable = c(U="sh1", F="fh1", H="gh1", L="XX")
d1384 1
a1384 1
    ftable <- c(U="sh", F="fh", H="gh", L="Lg")
d1408 1
a1408 1
  Fmat <- Hmat <- Umat <- VUmat <- Lvec <- NULL
d1418 1
d1429 1
d1481 2
d1511 1
d1533 14
a1546 2
             ## Inverse Fisher information of template model
             invI0 <- vcov(homfit)
d1548 4
a1551 5
             invI0mat <- matrix(as.vector(invI0), ncol=p^2, nrow=nP,
                                byrow=TRUE)
             ## Cross-covariance term
             ## C = H_v I^{-1} H_v
             Cmat <- quadform2.flat.matrices(invI0mat, Hmat,
d1553 18
a1570 2
             ## put it together
             VUmat <- Fmat - Cmat
d1581 1
@


1.180
log
@fiddling with bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.179 $ $Date: 2016/09/23 09:52:48 $
d177 1
d210 2
a211 1
               L="lrts")
d221 2
a222 1
               L="scalar")
d480 1
a480 1
    
d523 4
a526 4
              vgj <- try(vcov(model,
                              matwt=localwt, new.coef=coefj,
                              A1dummy=TRUE, matrix.action="silent"),
                         silent=TRUE)
d528 1
a528 1
            if(!inherits(vgj, "try-error") && !is.null(vgj)) {
d534 17
d679 1
a679 1
               else sumouter(momL[Z & ok, , drop=FALSE],
d684 1
a684 1
      A2 <- A3 <- matrix(0, ncoef, ncoef)
d694 3
a696 2
      #   momdelL[ , i, j] = localwt[i] * momdel[ , i, j] 
      momdelL <- momdel * rep(localwt[Z], rep(ncoef, nX))
d700 4
a703 1
      A2 <- sumsymouter(momdelL[, okX, okX], w=pairweight[okX, okX])
d707 1
a707 2
      deltamomL <- aperm(rep(t(momLX), nX) - momdelL,
                         c(1, 3, 2))
d709 3
d720 1
d785 2
a786 1
    splat("Quadrature point spacing:", format(rez))
d999 2
a1000 1
locppmPredict <- function(homfit, coefs, precomputed=NULL, details=FALSE) {
d1008 5
d1124 1
d1741 1
a1741 1
  # Text name of the homogeneous model
d1744 1
a1744 1
    discard <- clnames %in% c("nsim", "test", "locations", "simul",
d1816 2
a1817 2
             sqr <- lapply(smr, function(x) { eval.im(x^2)})
             sumsqr <- Reduce(function(x,y) eval.im(x+y), sqr)
d1819 1
d1826 7
d1834 1
a1834 1
  if(verbose) cat("Done.\n")
d1875 1
a1875 1
                      use.fft=TRUE,
d1877 1
a1877 1
                      additive = !use.fft, 
d1882 3
d1931 27
a1957 15
  if(!use.fft) {
    # fit on quadrature points, inverse gradient on data points
    opt.quad <- locppmOptions(cg=TRUE)
    opt.data <- locppmOptions(Vg=TRUE)
    # precompute internal data for variance estimates
    internals <- getvcinternals(homfit, verbose=verbose) 
  } else {
    # Taylor approximation coefficients and gradient on quadrature points
    opt.taylor <- locppmOptions(cg1=TRUE, gg1=TRUE)
    # precompute some values
    internals <- list(lambda=lambda0,
                      hom.coef=coef0,
                      mom=mm)
  }
  if(!ispois) {
d1968 5
a1972 3
  
  # fit using each value of sigma
  datasum <- dofadd <- dofmul <- intlam <- numeric(ns)
d1980 52
a2031 31
    if(!use.fft) {
      # fit on quadrature points, variance estimation on data points
      lpe.quad <- locppmEngine(homfit, sigk, U, opt=opt.quad,
                               scopename="quadrature points",
                               verbose=FALSE, internals=internals)
      lpe.data <- locppmEngine(homfit, sigk, X, opt=opt.data,
                               scopename="data points",
                               scopeindex=Xindex,
                               verbose=FALSE, internals=internals)
      # compute fitted conditional intensity at each quadrature point
      lambda <- locppmPredict(homfit, marks(lpe.quad$cg),
                                   precomputed=internals, details=TRUE)
      d.eta <- attr(lambda, "d.eta")
      # inverse Hessian at data points
      vX <- lpe.data[[ "Vg" ]]
      vX <- marks(vX)
    } else {
      # fit and Hessian approximated on quadrature points
      lpe <- locppmEngine(homfit, sigk, U, opt=opt.taylor,
                          scopename="quadrature points",
                          verbose=FALSE, internals=internals)
      # fitted [conditional] intensity at each quadrature point
      lambda <- locppmPredict(homfit, marks(lpe$cg1),
                                   precomputed=internals, details=TRUE)
      d.eta <- attr(lambda, "d.eta")
      # Hessian at data points
      hQ <- lpe[[ "gg1" ]]
      hX <- marks(hQ)[Z,,drop=FALSE]
      # invert the Hessians
      vX <- invert.flat.matrix(hX, p)
    }
d2033 6
a2038 5
    # compute 'leverage' approximation 
    if(ispois) {
      #    log(lambda(x_i)) - log(lambda_{-i}(x_i))
      #    ~ kernel(0) Z(x_i) V(x_i) Z(x_i)^T
      leve <- kernel0 * quadform2.flat.matrices(vX, mmX, c(p, p), c(1, p))
d2040 22
a2061 11
      #    log(lambda(x_i)) - log(lambda_{-i}(x_i))
      #    ~ kernel(0) Z(x_i) V(x_i) Y(x_i)^T
      # compute Y(x_i)
      dScore <- kernel0 * mmX
      lrat <- exp(d.eta) # adjustment factor for lambda
      for(j in 1:nX) {
        weiU <- dnorm(xU, mean=xU[j], sd=sigk) * dnorm(yU, mean=yU[j], sd=sigk)
        weiX <- weiU[1:nX]
        A <- apply(weiX * ddS[, j, , drop=FALSE], c(2,3), sum)
        B <- apply(weiU * lrat * ddSincrements[ , j, , drop=FALSE], c(2,3), sum)
        dScore[j,] <- dScore[j,] + A + B
d2063 2
a2064 1
      leve <- bilinear3.flat.matrices(mmX, vX, dScore, c(1,p), c(p,p), c(1,p))
d2066 1
a2066 6
    # compute terms in cross-validation criterion
    dofmul[k] <- sum(leve)
    dofadd[k] <- if(all(leve < 1)) -sum(log(1-leve)) else Inf
    intlam[k] <- if(anyNA(lambda)) Inf else sum(lambda * wQ)
    datasum[k] <- sum(log(lambda[Z])) 
    #
d2069 1
a2069 2
  #
  dof <- if(additive) dofadd else dofmul
a2071 1
  # 
d2073 2
a2074 3
                     dof=dof, intlam=intlam, datasum=datasum,
                     dofadd=dofadd, dofmul=dofmul)
  attr(result, "additive") <- additive
@


1.179
log
@more tweaks for the sake of cross-checking in the paper
@
text
@d6 1
a6 1
#  $Revision: 1.178 $ $Date: 2016/09/22 03:22:01 $
d1834 1
d1912 5
a1916 2
  if(verbose) cat(paste("Assessing", ns, "values of sigma... "))
  gcv <- dof <- intlam <- numeric(ns)
a1917 1
    if(verbose) progressreport(k, ns)
d1972 7
a1978 5
    
    # compute cross-validation criterion
    dof[k]    <- dof.k    <- sum(leve) 
    intlam[k] <- intlam.k <- sum(lambda * wQ, na.rm=TRUE)
    gcv[k] <- sum(log(lambda[Z])) - intlam.k - dof.k
d1980 5
d1986 3
a1988 1
                     dof=dof, intlam=intlam)
@


1.178
log
@tweaked printout
@
text
@d6 1
a6 1
#  $Revision: 1.177 $ $Date: 2016/09/10 06:10:50 $
d748 4
a751 1
  splat("Local (pseudo)likelihood fit")
d753 11
a763 3
  splat(x$templatecall, "\n", indent=5)
  print(quad.ppm(as.ppm(x)))
  splat("Smoothing parameter sigma: ", signif(x$sigma, 4), "\n")
d786 1
a786 1
    splat("Coarse grid: spacing", ep %unit% uh)
d1826 1
d1977 1
@


1.177
log
@now uses 'quadrature' weights to take averages etc
@
text
@d6 1
a6 1
#  $Revision: 1.176 $ $Date: 2016/09/08 01:33:26 $
d748 5
a752 4
  cat("Local (pseudo)likelihood fit\n")
  cat("Template model:\n")
  cat(paste("\t", x$templatecall, "\n\n"))
  cat(paste("Smoothing parameter sigma: ", x$sigma, "\n\n"))
d766 1
a766 1
      cat(paste0("Values computed at ", sc, ":\n"))
d768 1
a768 1
        cat(paste0("\t$", tags[i], ": ", explain[[i]], "\n"))
d772 1
a772 3
    cat(paste("Coarse grid: ",
              paste(ensure2vector(ng), collapse=" x "),
              "\n"))
d774 2
a775 5
    us <- summary(unitname(x$homfit))
    cat(paste("Coarse grid: spacing",
              paste(ep, collapse=" x "),
              us$plural, us$explain, 
              "\n"))
d778 1
a778 1
    cat(paste("Time taken for first phase:", codetime(p1t), "\n"))
d1381 1
a1381 1
      cat(paste("Processing", nP, scopename, "\n"))
d1409 1
a1409 1
    if(verbose) cat("\t Done.\n")
d1474 1
a1474 1
    cat("Homogeneity test map (class 'homtestmap')\n")
d1509 1
a1509 1
    cat(paste("\nFunction values:", vname, "\n"))
d1512 2
a1513 4
             moment = cat(paste(shortstat,
               "adjusted by first moment matching\n")),
             PSS = cat(paste(shortstat,
               "adjusted by Pace-Salvan-Sartori\n")),
d1516 1
a1516 1
      cat(paste(
d1524 2
a1525 2
               "rescaled chi-squared distribution (first moment approx.)"),
        "\n"))
d1544 1
a1544 1
    cat("homtestmap info:\n")
@


1.176
log
@homtestmap now handles composite null in Gibbs case
homtestmap arguments rearranged
@
text
@d6 1
a6 1
#  $Revision: 1.175 $ $Date: 2016/09/05 08:18:19 $
d43 3
a45 1
  U <- union.quad(quad.ppm(homfit, drop=TRUE))
d122 2
a123 1
           lpe <- locppmEngine(homfit, sigma, U, opt=opt,
d133 2
a134 1
           lpe <- locppmEngine(homfit, sigma, G, opt=opt,
d140 1
a140 1
           lpe.fit <- locppmEngine(homfit, sigma, U, opt=opt.fit,
d148 1
d150 1
a150 1
           lpe.var <- locppmEngine(homfit, sigma, G, opt=opt.var,
d274 1
d610 1
a610 1
        if(make.ssf)
d612 2
d1033 1
d1038 1
d1048 1
a1048 1
      coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=grideps)
d1051 1
d1059 1
a1059 1
  z <- locppmEngine(homfit, sigma, Puse,
d1080 1
a1080 1
  S <- mean(marks(Sv))
d1319 1
d1328 1
d1341 1
d1354 1
d1369 1
d1456 1
d1467 1
d1545 1
d1627 2
a1628 2
        Hpool <- matrix(colMeans(Hmat, na.rm=TRUE), p, p)
        VUpool <- matrix(colMeans(VUmat, na.rm=TRUE), p, p)
d1677 3
a1679 1
  ssf(unmark(x), y)
@


1.175
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.174 $ $Date: 2016/09/05 08:09:41 $
d1166 8
a1173 4
                        test=c("score", "taylor", "likelihood"),
                        ladjust=c("none", "moment", "PSS"),
                        calibrate=c("chisq", "Satterthwaite", "firstmoment"),
                        what=c("components", "statistic", "pvalue"),
d1175 2
a1176 3
                        theta0=NULL, sigma=NULL, 
                        use.fft=TRUE, verbose=TRUE, simple=FALSE,
                        poolmoments=NULL) {
d1226 2
a1227 4
  # Composite case is currently implemented only for Poisson
  told.simple <- simple || !is.null(theta0)
  nulltype <- if(told.simple || !ispois) "simple" else "composite"
  if(calc.var && nulltype == "simple" && !told.simple && verbose)
d1501 1
a1501 1
               "adjusted by Pace-Salvan-Sartori\n"),
d1666 1
d1684 1
a1684 1
                              "verbose", "Xname")
d1691 5
a1695 1
  #
d1698 2
a1699 1
           methodname <- "using likelihood ratio test statistic"
d1701 1
a1701 1
           doit <- function(Y, argh, locations, use.fft) { 
d1709 1
a1709 1
             h <- homteststat(fit, test="likelihood",
d1715 2
a1716 1
           methodname <- "using approximate likelihood ratio test statistic"
d1718 1
a1718 1
           doit <- function(Y, argh, locations, use.fft) { 
d1726 1
a1726 1
             h <- homteststat(fit, test="taylor",
d1734 1
a1734 1
           doit <- function(Y, argh, locations, use.fft) { 
d1750 1
a1750 1
           doit <- function(Y, argh, locations, use.fft) {
d1763 1
a1763 1
  obs <- doit(X, argh, locations=locations, use.fft=use.fft)
d1788 2
a1789 1
    sim[i] <- doit(Xsim[[i]], argh, locations=locations, use.fft=use.fft)
@


1.174
log
@tweaked argument handling in homtestmap
@
text
@d6 1
a6 1
#  $Revision: 1.173 $ $Date: 2016/09/03 10:49:39 $
d1254 1
a1254 1
                  (test=="taylor") || adjustingCLRTS,
d1295 1
a1295 1
                     adjustingCLRTS = adjustingCLRTS,
d1469 4
d1477 1
a1477 1
             if(adjustingCLRTS) {
d1495 1
a1495 1
    if(adjustingCLRTS)
d1497 4
a1500 2
             moment = cat("CLRTS adjustment: first moment matching\n"),
             PSS = cat("CLRTS adjustment: Pace-Salvan-Sartori\n"),
d1581 2
a1582 2
    ## .....  Adjustment of CLRTS ...................................
    if(adjustingCLRTS) {
@


1.173
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.172 $ $Date: 2016/08/31 10:20:00 $
d1099 1
d1101 2
a1102 1
  adjustingCLRTS <- (do.test && test == "likelihood" && ladjust != "none")
d1105 1
a1105 1
                       "poolmoments", "adjustingCLRTS"),
d1107 1
a1107 1
                          poolmoments, adjustingCLRTS))
d1178 5
d1184 3
a1186 1
  adjustingCLRTS <- (do.test && test == "likelihood" && ladjust != "none")
d1188 2
a1189 2
  should.cal.chisq <- adjustingCLRTS || (do.test && (test == "score"))
  should.cal.other <- (do.test && (test == "taylor"))
d1208 1
a1208 1
      warning(paste("Taylor approximation should be calibrated",
a1212 2
  trap.extra.arguments(...)
  stopifnot(inherits(object, "locppm"))
a1213 2
  told.use.fft <- !missing(use.fft) && use.fft
  if(is.null(poolmoments)) poolmoments <- is.stationary(as.ppm(object))
@


1.172
log
@fixed scoping bug in homtest
@
text
@d6 1
a6 1
#  $Revision: 1.171 $ $Date: 2016/08/31 09:09:05 $
d1178 4
a1181 2
  calibrate.chisq <- adjustingCLRTS || (do.test && (test == "score"))
  if(missing(calibrate) && calibrate.chisq) {
d1186 2
d1190 1
a1190 1
    if(calibrate != "chisq" && calibrate.chisq) {
d1198 5
d1239 1
a1239 1
  # U = score, H = hessian, F = local Fisher info
@


1.171
log
@extended cases handled by update method
@
text
@d6 1
a6 1
#  $Revision: 1.170 $ $Date: 2016/08/20 09:03:13 $
d1657 1
d1674 8
a1681 6
           doit <- function(Y, ..., locations, use.fft) { 
             fit <- locppm(Y, ...,
                           vcalc="lik",
                           locations=locations,
                           use.fft=use.fft,
                           verbose=FALSE)
d1690 8
a1697 6
           doit <- function(Y, ..., locations, use.fft) { 
             fit <- locppm(Y, ...,
                           vcalc="hom",
                           locations=locations,
                           use.fft=use.fft,
                           verbose=FALSE)
d1706 8
a1713 6
           doit <- function(Y, ..., locations, use.fft) { 
             fit <- locppm(Y, ...,
                           vcalc="hom",
                           locations=locations,
                           use.fft=use.fft,
                           verbose=FALSE)
d1722 2
a1723 2
           doit <- function(Y, ..., locations, use.fft) {
             fit <- ppm(Y, ...)
d1735 1
a1735 1
  obs <- doit(X, ..., locations=locations, use.fft=use.fft)
d1760 1
a1760 1
    sim[i] <- doit(Xsim[[i]], ..., locations=locations, use.fft=use.fft)
@


1.170
log
@more tweaks of print method
@
text
@d6 1
a6 1
#  $Revision: 1.169 $ $Date: 2016/08/20 08:25:47 $
d1144 16
@


1.169
log
@tweaked print method
@
text
@d6 1
a6 1
#  $Revision: 1.168 $ $Date: 2016/08/20 08:12:53 $
d1101 5
a1108 5
    newinfo <-
      replace(info, c("what", "test", "calibrate", "ladjust",
                      "poolmoments", "adjustingCLRTS"),
                    list(what, test, calibrate, ladjust,
                      poolmoments, adjustingCLRTS))
d1137 1
a1137 3
    resultvalues <- sqmag(object)
    P <- unmark(object)
    result <- ssf(P, resultvalues)
d1139 1
a1139 1
    attr(result, "info") <- info
d1270 1
a1270 1
  Fmat <- Hmat <- Umat <- Lvec <- NULL
d1430 7
a1436 4
    testname <- switch(test,
                       score = "Score Test",
                       taylor = {
                         paste("Taylor approximation to",
d1438 11
a1448 5
                       },
                       likelihood = {
                         paste0(if(adjustingCLRTS) "Adjusted " else "",
                                "Composite Likelihood Ratio Test")
                       })
d1451 7
a1457 3
             components = paste0(if(p > 1) "Vector components of" else "",
                                 paste("signed square root of",
                                       testname, "Statistic")),
d1460 6
a1465 2
    cat(paste("Function values:", vname, "\n"))
    if(adjustingCLRTS) cat(paste("Adjustment:", ladjust, "\n"))
d1469 1
a1469 1
        testname, "Statistic to the",
@


1.168
log
@added print method
@
text
@d6 1
a6 1
#  $Revision: 1.167 $ $Date: 2016/08/20 07:34:24 $
d1113 1
a1113 1
    attr(result, "info") <- info
d1453 2
a1454 1
        "The p-values were obtained by referring to",
d1456 1
a1456 1
               chisq = paste("chi-squared with", p, "d.f."),
@


1.167
log
@debuggered
@
text
@d6 1
a6 1
#  $Revision: 1.166 $ $Date: 2016/08/20 06:47:48 $
d1428 38
@


1.166
log
@reorganised 'homtestmap'
@
text
@d6 1
a6 1
#  $Revision: 1.165 $ $Date: 2016/08/17 10:12:09 $
d1099 2
d1104 6
a1109 1
    resultvalues <- HomTestMapEngine(localdata, info, what)
a1267 1
                     calc.var = calc.var,
d1415 1
a1415 1
  resultvalues <- HomTestMapEngine(localdata, resultinfo, what)
d1429 1
a1429 1
HomTestMapEngine <- function(x, info, what) {
d1438 5
a1442 1
  #' 
@


1.165
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.164 $ $Date: 2016/08/17 10:10:37 $
d1077 2
a1078 4
           what=c("components", "statistic", "pvalue", "all"),
           ladjust=c("none", "moment", "PSS"),
           calibrate=c("chisq", "Satterthwaite", "firstmoment"),
           poolmoments=NULL) {
a1079 3
  if(missing(what)) return(object)
  what <- match.arg(what)
  calibrate <- match.arg(calibrate)
d1081 2
d1085 55
a1139 77
  test    <- info$test %orifnull% "score"
  if(is.null(poolmoments)) poolmoments <- identical(info$poolable, TRUE)
  # transform the values?
  switch(what,
         all = {
           switch(oldwhat,
                  all = return(object),
                  components = {
                    if(test == "score") result <- object else
                    stop("Cannot resurrect all information")
                  },
                  statistic = ,
                  pvalue = stop("Cannot resurrect all information")
                  )
         },
         components = {
           switch(oldwhat,
                  all = { result <- object },
                  components = return(object),
                  statistic = ,
                  pvalue = stop("Cannot recover vector components")
                  )
         },
         statistic = {
           switch(oldwhat,
                  all = ,
                  components = { result <- sqmag(object) },
                  statistic = return(object),
                  pvalue = stop("Cannot recover statistic from p-values")
                  )
         },
         pvalue = {
           switch(oldwhat,
                  all =,
                  components = { stat <- sqmag(object) },
                  statistic  = { stat <- object },
                  pvalue = {
                    if(test == "score" ||
                       (identical(poolmoments, info$poolmoments) &&
                        identical(calibrate, info$calibrate)))
                      return(object)
                    stop("Cannot convert between different p-values")
                  })
           statvals <- as.vector(marks(stat))
           P <- unmark(stat)
           switch(calibrate,
                  chisq = {
                    p <- info$p
                    pvals <- pchisq(statvals, df=p, lower.tail=FALSE)
                  },
                  Satterthwaite = ,
                  firstmoment = {
                    nm <- attr(object, "nullmoments")
                    if(is.null(nm))
                      stop("Null moments unavailable: cannot compute p-values")
                    E <- with(nm, if(poolmoments) Epool else E)
                    V <- with(nm, if(poolmoments) Vpool else V)
                    switch(calibrate,
                           Satterthwaite = {
                             shape <- E^2/V
                             scale <- V/E
                           },
                           firstmoment = {
                             ncoef <- info$p
                             shape <- ncoef/2  ## i.e. chi^2, df=ncoef
                             scale <- 2 * E/ncoef  ## rescaled so mean =  E
                           })
                    pvals <- pgamma(statvals, shape=shape, scale=scale,
                                    lower.tail=FALSE)
                  })
           result <- ssf(P, pvals)
         })
  info$what <- what
  class(result) <- c("homtestmap", class(result))
  attr(result, "info") <- info
  result <- timed(result, starttime=starttime)
  return(result)
d1146 2
a1147 1
                        what=c("components", "statistic", "pvalue", "all"),
d1185 2
a1186 2
  calc.all <- what %in% c("pvalue", "all")
  calcvar <- calc.all || (test != "taylor")
d1191 1
a1191 1
  if(calcvar && nulltype == "simple" && !told.simple && verbose)
d1210 2
a1211 1
  # approximate likelihood ratio requires H
d1216 3
a1218 2
              F = calcvar,
              H = calc.all || (calcvar && nulltype == "composite") ||
d1220 2
a1221 2
              L = (test == "likelihood"))
  
d1258 5
a1262 1
                     ladjust=ladjust)
d1264 1
d1266 1
d1365 4
a1368 3
  # .....  Prepare to calculate test statistic .............................
  if(calcvar) {
    # compute variance of local score at global estimate of theta
d1371 2
a1372 2
             # theta is fixed.
             # variance of local score
d1376 6
a1381 6
             # theta has been estimated.
             # Calculate variance of
             #    {local score evaluated at global estimate of theta}
             #     allowing for estimation of theta 
             #     assuming template model is true.
             # Inverse Fisher information of template model
d1383 1
a1383 1
             # Make it a flat matrix stack
d1385 3
a1387 3
                              byrow=TRUE)
             # Cross-covariance term
             # C = H_v I^{-1} H_v
d1389 2
a1390 2
                                              c(p,p), c(p,p))
             # put it together
d1394 19
a1412 116
  # .....  Now calculate test statistic .....................................
  switch(what,
         all = ,
         components = {
           # compute components of 'square root' of local test statistic
           switch(test,
                  score = {
                    # score test statistic
                    # inverse square root of variance of local score
                    ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
                    # premultiply local score
                    rootstat <- multiply2.flat.matrices(ISVmat, Umat,
                                                        c(p, p), c(p, 1))
                    colnames(rootstat) <- names(hom.coef)
                  },
                  taylor = {
                    # Taylor approximation to local likelihood ratio test
                    # inverse square root of variance of local Hessian
                    InvsqHmat <- handle.flat.matrix(Hmat, c(p, p), invsqrtmat)
                    # premultiply local score
                    rootstat <- multiply2.flat.matrices(InvsqHmat, Umat,
                                                        c(p, p), c(p, 1))
                    colnames(rootstat) <- names(hom.coef)
                  },
                  likelihood = {
                    rootstat <- Lvec
                  })
         },
         pvalue = ,
         statistic = {
           # compute local test statistic
           switch(test,
                  score = {
                    # score test statistic
                    IVmat <- invert.flat.matrix(VUmat, p)
                    stat <- quadform2.flat.matrices(IVmat, Umat,
                                                    c(p,p), c(1,p))
                  },
                  taylor = {
                    # Taylor approx of local likelihood ratio test statistic
                    IHmat <- invert.flat.matrix(Hmat, p)
                    stat <- quadform2.flat.matrices(IHmat, Umat,
                                                    c(p,p), c(1,p))
                  },
                  likelihood = {
                    stat <- Lvec
                  })
         })
  # .....  Adjustment of CLRTS ...................................
  if(adjustingCLRTS) {
    switch(ladjust,
           moment = {
             # first moment matching adjustment
             GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                             c(p,p), c(p,p))
             E <- trace.flat.matrix(GinVmat, p)
             stat <- (ncoef/E) * stat
           },
           PSS = {
             # Pace-Salvan-Sartori adjustment
             IVmat <- invert.flat.matrix(VUmat, p)
             scorestat <- quadform2.flat.matrices(IVmat, Umat,
                                                  c(p,p), c(1,p))
             IHmat <- invert.flat.matrix(Hmat, p)
             taylorstat <- quadform2.flat.matrices(IHmat, Umat,
                                              c(p,p), c(1,p))
             stat <- (scorestat/taylorstat) * stat
           },
           none = { }
           )
  }
  # .....  Null moments for calibration ...................................
  if(calibrate != "chisq" && test %in% c("likelihood", "taylor")) {
    if(poolmoments) {
      Hpool <- matrix(colMeans(Hmat, na.rm=TRUE), p, p)
      VUpool <- matrix(colMeans(VUmat, na.rm=TRUE), p, p)
      GinVpool <- solve(Hpool, VUpool)
      E <- sum(diag(GinVpool))
      if(calibrate == "Satterthwaite")
        V <- 2 * sum(diag(GinVpool %*% GinVpool))
    } else {
      GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                      c(p,p), c(p,p))
      E <- trace.flat.matrix(GinVmat, p)
      if(calibrate == "Satterthwaite") {
        GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat,
                                            c(p,p), c(p,p))
        V <- 2 * trace.flat.matrix(GinV2mat, p)
      }
    }
  }
  # .....  Local p-values ...................................
  if(what == "pvalues") {
    switch(calibrate,
           chisq = {
             pvals <- pchisq(stat, df=ncoef, lower.tail=FALSE)
           },
           Satterthwaite = {
             shape <- E^2/V
             scale <- V/E
             pvals <- pgamma(stat, shape=shape, scale=scale,
                             lower.tail=FALSE)
           },
           firstmoment = {
             shape <- ncoef/2  ## i.e. chi^2, df=ncoef
             scale <- 2 * E/ncoef  ## rescaled so mean =  E
             pvals <- pgamma(stat, shape=shape, scale=scale,
                             lower.tail=FALSE)
           })
  }
  # .....  Finally assemble the result ...................................
  resultvalues <- switch(what,
                         all        = rootstat,
                         components = rootstat,
                         statistic  = stat,
                         pvalue     = pvals)
a1413 14
  #  ...............  add extra attributes .........................
  if(what == "all" && test == "likelihood") {
    # Compute and save null moments so that p-values can be computed
    GinVmat <- solve2.flat.matrices(Hmat, VUmat, c(p,p), c(p,p))
    GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat, c(p,p), c(p,p))
    E <- trace.flat.matrix(GinVmat, p)
    V <- 2 * trace.flat.matrix(GinV2mat, p)
    Hpool <- matrix(colMeans(Hmat, na.rm=TRUE), p, p)
    VUpool <- matrix(colMeans(VUmat, na.rm=TRUE), p, p)
    GinVpool <- solve(Hpool, VUpool)
    Epool <- sum(diag(GinVpool))
    Vpool <- 2 * sum(diag(GinVpool %*% GinVpool))
    attr(result, "nullmoments") <- list(E=E, V=V, Epool=Epool, Vpool=Vpool)
  }
d1415 1
d1417 2
d1423 130
d1559 1
@


1.164
log
@reorganised 'homtestmap' with new arguments 'ladjust' and 'calibrate'
@
text
@d6 1
a6 1
#  $Revision: 1.163 $ $Date: 2014/07/02 04:53:00 $
d1521 1
a1521 1
                         all        = rootstat
@


1.163
log
@fixed BUG in first moment matching method
@
text
@d6 1
a6 1
#  $Revision: 1.162 $ $Date: 2014/07/01 01:16:56 $
d1078 2
a1079 1
           adjust=c("Satterthwaite", "firstmoment"),
d1084 1
a1084 1
  adjust <- match.arg(adjust)
d1127 1
a1127 1
                        identical(adjust, info$adjust)))
d1133 2
a1134 2
           switch(test,
                  score = {
d1138 2
a1139 1
                  likelihood = {
d1145 1
a1145 1
                    switch(adjust,
d1168 3
a1170 1
                        test=c("score", "approxlike", "likelihood"),
a1171 1
                        adjust=c("Satterthwaite", "firstmoment"),
d1178 20
a1197 1
  adjust <- match.arg(adjust)
d1210 1
a1210 1
  calcvar <- calc.all || (test != "approxlike")
d1241 1
a1241 1
                  (test=="approxlike"),
d1279 2
a1280 1
                     adjust=adjust)
d1381 1
a1381 1
  # .....  Now calculate test statistic .....................................
d1409 1
d1424 1
a1424 1
                  approxlike = {
a1435 1
           result <- ssf(P, rootstat)
d1437 1
d1447 1
a1447 1
                  approxlike = {
a1455 56
           result <- ssf(P, stat)
         },
         pvalue = {
           # compute local p-value
           switch(test,
                  score = {
                    # compute score test statistic
                    IVmat <- invert.flat.matrix(VUmat, p)
                    stat <- quadform2.flat.matrices(IVmat, Umat,
                                                    c(p,p), c(1,p))
                    # Local p-values using chi^2_p
                    pvals <- pchisq(stat, df=p, lower.tail=FALSE)
                  },
                  likelihood =, 
                  approxlike = {
                    if(test == "likelihood") {
                      ## compute local likelihood ratio test statistic
                      stat <- Lvec
                    } else {
                      ## Taylor approx of local likelihood ratio test statistic
                      IHmat <- invert.flat.matrix(Hmat, p)
                      stat <- quadform2.flat.matrices(IHmat, Umat,
                                                      c(p,p), c(1,p))
                    }
                    ## Null moments
                    if(poolmoments) {
                      Hpool <- matrix(colMeans(Hmat, na.rm=TRUE), p, p)
                      VUpool <- matrix(colMeans(VUmat, na.rm=TRUE), p, p)
                      GinVpool <- solve(Hpool, VUpool)
                      E <- sum(diag(GinVpool))
                      if(adjust == "Satterthwaite")
                        V <- 2 * sum(diag(GinVpool %*% GinVpool))
                    } else {
                      GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                                      c(p,p), c(p,p))
                      E <- trace.flat.matrix(GinVmat, p)
                      if(adjust == "Satterthwaite") {
                        GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat,
                                                            c(p,p), c(p,p))
                        V <- 2 * trace.flat.matrix(GinV2mat, p)
                      }
                    } 
                    # Local p-values using gamma approximation
                    switch(adjust,
                           Satterthwaite = {
                             shape <- E^2/V
                             scale <- V/E
                           },
                           firstmoment = {
                             shape <- ncoef/2  ## i.e. chi^2, df=ncoef
                             scale <- 2 * E/ncoef  ## rescaled so mean =  E
                           })
                    pvals <- pgamma(stat, shape=shape, scale=scale,
                                    lower.tail=FALSE)
                  })
           result <- ssf(P, pvals)
d1457 70
d1555 1
a1555 1
                    test = c("residuals", "score", "approxlike", "likelihood"),
d1596 1
a1596 1
         approxlike = {
d1605 1
a1605 1
             h <- homteststat(fit, test="approxlike",
@


1.162
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.161 $ $Date: 2014/07/01 00:53:39 $
d1078 1
d1083 1
d1125 2
a1126 1
                       identical(poolmoments, info$poolmoments)) 
d1143 11
a1153 1
                    pvals <- pgamma(statvals, shape=E^2/V, scale=V/E,
d1168 1
d1175 1
d1243 2
a1244 1
    if(missed["L"])
d1256 2
a1257 1
                     poolable=is.stationary(as.ppm(object)))
d1462 2
a1463 1
                      V <- 2 * sum(diag(GinVpool %*% GinVpool))
a1466 2
                      GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat,
                                                          c(p,p), c(p,p))
d1468 5
a1472 1
                      V <- 2 * trace.flat.matrix(GinV2mat, p)
d1475 10
a1484 1
                    pvals <- pgamma(stat, shape=E^2/V, scale=V/E,
@


1.161
log
@changed default for use.fft
@
text
@d6 1
a6 1
#  $Revision: 1.160 $ $Date: 2014/07/01 00:51:33 $
d1564 1
@


1.160
log
@homtest has new option 'approxlike'
@
text
@d6 1
a6 1
#  $Revision: 1.159 $ $Date: 2014/06/28 09:47:34 $
d1490 1
a1490 1
                    use.fft = (locations == "fine"),
d1499 2
a1500 1
  force(use.fft)
@


1.159
log
@adapted to new spatstat interface
@
text
@d6 1
a6 1
#  $Revision: 1.158 $ $Date: 2014/06/28 09:14:02 $
d10 1
a10 1
                   vcalc=c("none", "t", "hessian", "hom", "full"),
d26 1
a26 1
    if(vcalc == "hom")  locations <- "coarse"
d64 1
d72 1
d103 9
a111 1
         })
d184 3
a186 1
         gh1="gradient of local score evaluated at homogeneous model")
d203 12
a214 1
               T="tgrad")
a215 9
  ismatrix <- c(c=FALSE,
                v=TRUE,
                f=TRUE,
                s=FALSE,
                g=TRUE,
                t=FALSE,
                V=TRUE,
                T=FALSE)
  
d220 1
a220 1
             ismatrix    = unname(ismatrix[y1]),
d289 1
a289 1
  ismatrix    <- LOT$ismatrix
d331 5
a335 1
  if(need.localfit || any(unlist(opt[tags[!ismatrix]]))) {
d340 1
a340 1
  if(any(unlist(opt[tags[ismatrix]]))) {
d347 9
a355 2
  for(i in seq_along(tags))
    if(opt[[i]]) assign(tags[i], if(ismatrix[i]) v.blank else ct.blank)
d384 1
d466 6
d490 9
d1153 1
a1153 1
                        test=c("likelihood", "score"),
d1166 8
a1173 2
  # Determine whether variance calculation is required
  calcvar <- (what %in% c("pvalue", "all")) || (test == "score")
d1183 1
a1183 1
      warning("Cannot use FFT code when theta0 is given")
d1197 1
a1197 1
  # likelihood ratio requires H
d1200 1
d1203 3
a1205 1
              H = (calcvar && nulltype == "composite") || (test=="likelihood"))
d1210 1
a1210 1
    ftable = c(U="sh1", F="fh1", H="gh1")
d1219 1
a1219 1
                       "refit the model with vcalc=\'hom\'")
d1226 1
a1226 1
    ftable <- c(U="sh", F="fh", H="gh")
d1228 5
d1259 1
d1381 1
d1383 2
a1384 2
                  likelihood = {
                    # local likelihood ratio test
d1390 4
a1394 1
           colnames(rootstat) <- names(hom.coef)
d1406 2
a1407 2
                  likelihood = {
                    # local likelihood ratio test statistic
d1411 3
d1428 12
a1439 6
                  likelihood = {
                    # compute local likelihood ratio test statistic
                    IHmat <- invert.flat.matrix(Hmat, p)
                    stat <- quadform2.flat.matrices(IHmat, Umat,
                                                    c(p,p), c(1,p))
                    # Null moments
d1488 1
a1488 1
                    test = c("likelihood", "score", "residuals"),
d1519 14
d1537 1
a1537 1
             h <- homteststat(fit, test="likelihood",
@


1.158
log
@removed erroneous factor 2 in approximation to likelihood ratio test statistic
@
text
@d6 1
a6 1
#  $Revision: 1.157 $ $Date: 2013/12/19 08:38:35 $
d1599 1
a1599 1
    a <- ppm.influence(homfit, what=c("increments"), precomputed=internals)
@


1.157
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.156 $ $Date: 2013/11/29 01:52:17 $
d1080 6
a1085 2
                  pvalue = return(object)
                  )
d1096 5
a1100 13
                      stop("Cannot compute p-values")
                    if(poolmoments) {
                      edg <- second.moment.calc(as.im(as.owin(P)),
                                                sigma=info$sigma,
                                                what="edge")
                      eP <- edg[P]
                      ebar <- mean(eP, na.rm=TRUE)
                      nm$E <- eP * mean(nm$E, na.rm=TRUE)/ebar
                      nm$V <- eP * mean(nm$V, na.rm=TRUE)/ebar
                    }
                    pvals <- with(nm,
                                  pgamma(statvals, shape=E^2/V, scale=V/E,
                                         lower.tail=FALSE))
d1183 2
a1184 1
                     sigma=sigma, 
d1331 2
a1332 3
                    rootstat <- sqrt(2) *
                      multiply2.flat.matrices(InvsqHmat, Umat,
                                              c(p, p), c(p, 1))
d1349 2
a1350 2
                    stat <- 2 * quadform2.flat.matrices(IHmat, Umat,
                                                        c(p,p), c(1,p))
d1368 2
a1369 2
                    stat <- 2 * quadform2.flat.matrices(IHmat, Umat,
                                                        c(p,p), c(1,p))
a1370 6
                    GinVmat <- solve2.flat.matrices(Hmat, VUmat,
                                                    c(p,p), c(p,p))
                    GinV2mat <- multiply2.flat.matrices(GinVmat, GinVmat,
                                                        c(p,p), c(p,p))
                    E <- 2 * trace.flat.matrix(GinVmat, p)
                    V <- 8 * trace.flat.matrix(GinV2mat, p)
d1372 13
a1384 8
                      edg <- second.moment.calc(as.im(as.owin(P)),
                                                sigma=sigma,
                                                what="edge")
                      eP <- edg[P]
                      ebar <- mean(eP, na.rm=TRUE)
                      E <- eP * mean(E, na.rm=TRUE)/ebar
                      V <- eP * mean(V, na.rm=TRUE)/ebar
                    }
d1395 8
a1402 3
    E <- 2 * trace.flat.matrix(GinVmat, p)
    V <- 8 * trace.flat.matrix(GinV2mat, p)
    attr(result, "nullmoments") <- list(E=E, V=V)
@


1.156
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.155 $ $Date: 2013/11/28 14:49:40 $
d622 1
a622 1
        lamdel <- lamdel * exp(tensor(new.coef - hom.coef, momdel, 1, 1))
d768 3
a770 2
  A <- as.ppp(Y) %mark% as.matrix(Y)
  A <- A[Y$ok]
d823 1
a823 1
  v <- as.matrix(v)
d838 2
a839 2
  co <- as.matrix(coefs)
  P  <- as.ppp(coefs)
d861 1
a861 1
  return(as.matrix(lam))
d875 1
a875 1
    locations <- as.ppp(coefs)
d881 1
a881 1
    coefmat <- as.matrix(coefs)
d983 1
a983 1
  P <- coefs$loc
d1027 2
a1028 2
  Sv <- if(ncol(as.matrix(Tv)) > 1) sqmag(Tv) else Tv
  S <- mean(as.matrix(Sv))
d1036 2
a1037 1
           what=c("components", "statistic", "pvalue", "all")) {
d1045 1
d1082 2
a1083 2
           statvals <- as.vector(as.matrix(stat))
           P <- as.ppp(stat)
d1093 9
d1119 2
a1120 1
                        use.fft=TRUE, verbose=TRUE, simple=FALSE) {
d1128 1
d1186 3
a1188 1
  resultinfo <- list(test=test, what=what, use.fft=use.fft, p=p)
d1194 2
a1195 2
    Umat <- as.matrix(sh1)
    P <- as.ppp(sh1)
d1197 2
a1198 2
    if(needed["F"]) Fmat <- as.matrix(object$fh1)
    if(needed["H"]) Hmat <- as.matrix(object$gh1)
d1202 2
a1203 2
    Umat <- as.matrix(sh)
    P <- as.ppp(sh)
d1205 2
a1206 2
    if(needed["F"]) Fmat <- as.matrix(object$fh)
    if(needed["H"]) Hmat <- as.matrix(object$gh)
d1236 1
a1236 1
      nps <- unlist(lapply(sfs, function(z) npoints(as.ppp(z))))
d1241 1
a1241 1
      P <- as.ppp(best)
d1381 9
d1412 1
a1412 2
  loc <- x$loc
  val <- x$val
d1414 1
a1414 1
  ssf(loc, y)
d1624 1
a1624 1
      lambda <- locppmPredict(homfit, as.matrix(lpe.quad$cg),
d1629 1
a1629 1
      vX <- as.matrix(vX)
d1636 1
a1636 1
      lambda <- locppmPredict(homfit, as.matrix(lpe$cg1),
d1641 1
a1641 1
      hX <- as.matrix(hQ)[Z,,drop=FALSE]
@


1.155
log
@further tweak
@
text
@d6 1
a6 1
#  $Revision: 1.154 $ $Date: 2013/11/28 13:00:44 $
d1411 2
a1412 1
    discard <- clnames %in% c("nsim", "test", "locations", "verbose", "Xname")
@


1.154
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.153 $ $Date: 2013/11/28 10:54:38 $
d1168 1
a1168 1
    use.object <- !any(missed) && (nulltype == "composite")
@


1.153
log
@ramped up option vcalc="full" to do really everything.
@
text
@d6 1
a6 1
#  $Revision: 1.152 $ $Date: 2013/11/28 10:44:15 $
d1264 1
@


1.152
log
@improved
@
text
@d6 1
a6 1
#  $Revision: 1.151 $ $Date: 2013/11/28 10:17:21 $
d62 1
a62 1
    opt.hess <- locppmOptions(Vg=TRUE,Tg=TRUE)
d64 1
a64 1
    opt.full <- locppmOptions(cg=TRUE,vg=TRUE,tg=TRUE,Vg=TRUE,Tg=TRUE,vh=TRUE)
d71 1
a71 1
    opt.full <- locppmOptions(cg1=TRUE, vg1=TRUE, tg1=TRUE, vh1=TRUE) 
@


1.151
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.150 $ $Date: 2013/11/28 05:06:51 $
d1209 1
a1209 6
    # find any variance estimate
    vn <- c("vg", "tg", "Vg", "Tg", "vh", "sh", "fh", "gh", "v0")
    vn <- vn[vn %in% names(object)]
    has.vn <- !unlist(lapply(object[vn], is.null))
    #
    if(ispois || !any(has.vn)) {
d1215 12
a1226 4
      # use points where variance was evaluated
      va <- object[vn[[min(which(has.vn))]]]
      P <- as.ppp(va)
      scopename <- attr(va, "scopename") %orifnull% "grid points"
@


1.150
log
@bug in p-values again
@
text
@d6 1
a6 1
#  $Revision: 1.149 $ $Date: 2013/11/28 05:06:17 $
d1211 1
d1221 1
a1221 1
      va <- object[vn[min(which(has.vn))]]
@


1.149
log
@bug in p-value direction
@
text
@d6 1
a6 1
#  $Revision: 1.148 $ $Date: 2013/11/28 02:15:05 $
d1361 2
a1362 1
                    pvals <- pgamma(stat, shape=E^2/V, scale=V/E)
@


1.148
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.147 $ $Date: 2013/11/28 02:06:36 $
d1090 3
a1092 1
                    pvals <- with(nm, pgamma(statvals, shape=E^2/V, scale=V/E))
@


1.147
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.146 $ $Date: 2013/11/28 02:05:12 $
d1037 1
a1037 1
  if(missing(what) return(object)
d1079 1
d1084 1
a1084 1
                    pvals <- pchisq(stat, df=p, lower.tail=FALSE)
d1090 1
a1090 1
                    pvals <- with(nm, pgamma(stat, shape=E^2/V, scale=V/E))
@


1.146
log
@now has update.homtestmap
@
text
@d6 1
a6 1
#  $Revision: 1.145 $ $Date: 2013/11/27 13:01:17 $
d1022 1
a1022 1
  } else if(inherits(object, "homtestmap"))
@


1.145
log
@fixed (hopefully) the homtest setup
@
text
@d6 1
a6 1
#  $Revision: 1.144 $ $Date: 2013/09/25 07:42:51 $
d599 1
a599 1
      lambda <- lambda * exp(mom %*% (new.coef - hom.coef))
d1020 5
a1024 1
  Tv <- homtestmap(object, ..., verbose=verbose)
d1026 1
a1026 2
  what <- attr(Tv, "info")$what %orifnull% "components"
  Sv <- if(what == "components") sqmag(Tv) else Tv
d1033 3
a1035 5
homtestmap <- function(object, ...,
                       test=c("likelihood", "score"),
                       what=c("components", "statistic", "pvalue"),
                       theta0=NULL, sigma=NULL, 
                       use.fft=TRUE, verbose=TRUE, simple=FALSE) {
d1037 2
a1038 3
  if(inherits(object, "homtestmap"))
    return(object)
  stopifnot(inherits(object, "locppm"))
d1040 66
d1108 2
d1113 1
a1113 1
  calcvar <- (what == "pvalue") || (test == "score")
d1169 1
a1169 1
  resultinfo <- list(test=test, what=what, use.fft=use.fft)
d1210 1
a1210 1
    if(ispois || !any(hasvn)) {
d1293 1
d1362 8
@


1.144
log
@changed formula in bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.143 $ $Date: 2013/09/25 06:57:35 $
d63 1
a63 1
    opt.hom  <- locppmOptions(vh=TRUE)
d163 3
d290 7
d487 1
a487 1
      if(opt$vh) {
d490 4
a493 1
        } else {
d497 12
d510 1
a510 1
        if(!inherits(vhj, "try-error") && !is.null(vhj) &&
d513 9
a577 1

d639 2
a640 6
    A1 <- A1/areaW
    A2 <- A2/areaW
    A3 <- A3/areaW
    Grad <- Grad/areaW
    Sigma <- A1+A2+A3
    U <- try(solve(Grad))
d642 5
a646 1
    mat <- U %*% Sigma %*% U / areaW
d1022 3
a1024 1
  S <- mean(as.matrix(sqmag(Tv)))
d1031 3
a1033 1
                       vcalc=c("hom", "hessian"), theta0=NULL, sigma=NULL, 
d1040 2
a1041 1
  vcalc <- match.arg(vcalc)
d1044 2
d1050 1
a1050 1
  if(nulltype == "simple" && !told.simple && verbose)
d1052 5
a1056 1
  #
d1062 14
d1079 2
a1080 6
    needed <- switch(vcalc,
                     hessian = c("sh1", "gh1"),
                     hom = switch(nulltype,
                       simple = c("sh1", "fh1"),
                       composite = c("sh1", "fh1", "gh1")))
    missed <- unlist(lapply(object[needed], is.null))
d1084 1
a1084 1
        want.tags <- needed[missed]
d1087 2
a1088 1
                       commasep(want.desc))
d1093 11
a1105 1
    # extract local score
d1110 94
a1203 37
    # calculate variance of local score & `standardise' 
    switch(vcalc,
           hom = {
             switch(nulltype,
                    simple = {
                      # theta is fixed.
                      # Extract variance of local score
                      VUmat <- as.matrix(object$fh1)
                    },
                    composite = {
                      # theta has been estimated.
                      # Calculate variance of local score allowing for estim.
                      Fmat <- as.matrix(object$fh1)
                      Hmat <- as.matrix(object$gh1)
                      # Inverse Fisher information of template model
                      invI0 <- vcov(homfit)
                      # Make it a flat matrix stack
                      invI0mat <- matrix(as.vector(invI0), ncol=p^2, nrow=nP,
                                      byrow=TRUE)
                      # Cross-covariance term
                      # C = H_v I^{-1} H_v
                      Cmat <- quadform2.flat.matrices(invI0mat, Hmat,
                                                      c(p,p), c(p,p))
                      # put it together
                      VUmat <- Fmat - Cmat
                    })
             # compute score test statistic
             # inverse square root of variance of local score
             ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
             # premultiply local score
             stat <- multiply2.flat.matrices(ISVmat, Umat, c(p, p), c(p, 1))
             # dress up
             colnames(stat) <- names(hom.coef)
             result <- ssf(P, stat)
             class(result) <- c("homtestmap", class(result))
             result <- timed(result, starttime=starttime)
             return(result)
d1205 17
a1221 18
           hessian = {
             # local score and local Hessian information 
             # under homogeneous model should have already been computed
             # (by FFT)
             gh1 <- object$gh1
             Hmat <- as.matrix(gh1)
             # compute score test statistic
             # inverse square root of variance of local Hessian
             InvsqHmat <- handle.flat.matrix(Hmat, c(p, p), invsqrtmat)
             # premultiply local score
             stat <- multiply2.flat.matrices(InvsqHmat, Umat,
                                             c(p, p), c(p, 1))
             # dress up
             colnames(stat) <- names(hom.coef)
             result <- ssf(P, stat)
             class(result) <- c("homtestmap", class(result))
             result <- timed(result, starttime=starttime)
             return(result)
d1224 40
a1263 4
  # Slower code...
  switch(nulltype,
         simple = {
           lam <- fitted(homfit, drop=TRUE, new.coef=theta0)
d1265 27
a1291 4
         composite = {
           lam <- fitted(homfit, drop=TRUE)
           if(ispois)
             vhom <- vcov(homfit) 
a1292 75
  if(!ispois) {
    va <- switch(vcalc, hom=object$vh, hessian=object$Vg)
    if(is.null(va))
      stop(paste("Object does not contain the required variance information;",
                 "refit the model with vcalc = ", dQuote(vcalc)))
    vest <- as.matrix(va)
  }
  # extract quadrature points used to fit model
  Q    <- quad.ppm(homfit, drop=TRUE)
  w    <- w.quad(Q)
  Z    <- is.data(Q)
  U    <- union.quad(Q)
  nU   <- npoints(U)
  Ux <- U$x
  Uy <- U$y
  ok <- getglmsubset(homfit)
  suf <- model.matrix(homfit)[ok, , drop=FALSE]
  # increments of residual measure of homogeneous fit
  homresid <- Z - lam * w
  #
  # determine points for evaluation
  if(ispois) {
    # use all quadrature points
    P <- U
    scopename <- "quadrature points"
    coarse.to.fine <- seq_len(nU)
  } else {
    # use points where 'va' was evaluated
    P <- as.ppp(va)
    scopename <- attr(va, "scopename") %orifnull% "grid points"
    coarse.to.fine <- object$coarse.to.fine
  }
  nP <- npoints(P)
  Px <- P$x
  Py <- P$y
  # create space
  ncoef <- length(hom.coef)
  stat <- matrix(, nrow=nP, ncol=ncoef)
  colnames(stat) <- names(hom.coef)
  #
  if(verbose)
    cat(paste("Processing", nP, scopename, "\n"))
  for(k in 1:nP) {
    if(verbose) 
      progressreport(k, nP)
    localwt <- dnorm(Ux - Px[k], sd=sigma) * dnorm(Uy - Py[k], sd=sigma)
    # local score at P[k] for homogeneous model
    locscore <- matrix(localwt * homresid, nrow=1) %*% suf
    # evaluate null standard error of local score
    if(ispois) {
      # local Fisher information at P[k] for homogeneous model
      locfish <- sumouter(localwt * suf, w * lam)
      # evaluate null variance of local *score*
      switch(nulltype,
             simple = {
               locinfo <- locfish
             },
             composite = {
               # local Hessian
               locHess <- sumouter(suf, w * lam * localwt)
               locinfo <- locfish - locHess %*% vhom %*% locHess
             })
      # inverse square root of information matrix
      vhalf <- invsqrtmat(locinfo)
    } else {
      # null variance of local *estimates* is given by 'vest'
      nullvcov <- matrix(vest[k,], nrow=ncoef, ncol=ncoef)
      vhalf <- sqrtmat(nullvcov)
    }
    # evaluate (square root of) score test statistic
    stat[k, ] <- locscore %*% vhalf
  }
  if(verbose) cat("\t Done.\n")
  # pack up
  result <- ssf(P, stat)
d1294 1
d1309 1
a1309 2
                    method = c("local", "residuals"),
                    vcalc = c("hom", "hessian"),
d1318 1
a1318 2
  method <- match.arg(method)
  vcalc <- match.arg(vcalc)
d1325 1
a1325 1
    discard <- clnames %in% c("nsim", "method", "locations", "verbose", "Xname")
d1333 17
a1349 6
  switch(method,
         local = {
           methodname <-
             switch(vcalc,
                    hom = "using local variance",
                    hessian = "using Poincare variance")
d1351 1
a1351 1
           doit <- function(Y, ..., vcalc, locations, use.fft) { 
d1353 1
a1353 1
                           vcalc=vcalc,
d1357 2
a1358 1
             h <- homteststat(fit, vcalc=vcalc, use.fft=use.fft, verbose=FALSE)
d1365 1
a1365 1
           doit <- function(Y, ..., vcalc, locations, use.fft) {
d1377 1
a1377 2
  obs <- doit(X, ...,
              vcalc=vcalc, locations=locations, use.fft=use.fft)
d1402 1
a1402 2
    sim[i] <- doit(Xsim[[i]], ...,
                   vcalc=vcalc, locations=locations, use.fft=use.fft)
@


1.143
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.142 $ $Date: 2013/09/25 05:20:37 $
d881 1
a881 1
locppmPredict <- function(homfit, coefs, precomputed=NULL) {
d894 2
d1400 2
a1401 1
                                   precomputed=internals)
d1412 2
a1413 1
                                   precomputed=internals)
d1427 3
d1431 1
d1436 1
a1436 1
        B <- apply(weiU * ddSincrements[ , j, , drop=FALSE], c(2,3), sum)
@


1.142
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.141 $ $Date: 2013/09/25 04:11:39 $
d1314 1
d1368 10
a1377 8
  if(verbose) cat("Leverage... ")
  # pre-compute data for leverage approximation
  internals$coef <- internals$hom.coef
  a <- ppm.influence(homfit, what=c("increments"), precomputed=internals)
  # change in canonical statistic for X[i] when X[j] is deleted
  ddS <- a$increm$ddS[ , Z, , drop=FALSE]
  # change in integral increment at U[i] when X[j] is deleted
  ddSincrements <- wQ * a$increm$ddSintegrand[ , Z, , drop=FALSE]
d1416 16
a1431 7
    dScore <- kernel0 * mmX
    for(j in 1:nX) {
      weighU <- dnorm(xU, mean=xU[j], sd=sigk) * dnorm(yU, mean=yU[j], sd=sigk)
      weighX <- weighU[1:nX]
      A <- apply(weighX * ddS[, j, , drop=FALSE], c(2,3), sum)
      B <- apply(weighU * ddSincrements[ , j, , drop=FALSE], c(2,3), sum)
      dScore[j,] <- dScore[j,] + A + B
a1432 5
    # compute 'leverage' approximation 
    #    log(lambda(x_i)) - log(lambda_{-i}(x_i))
    #    ~ kernel(0) Z(x_i) V(x_i) Z(x_i)^T
#    leve <- quadform2.flat.matrices(vX, mmX, c(p, p), c(1, p))
    leve <- quadform2.flat.matrices(vX, dScore, c(p, p), c(1, p))
@


1.141
log
@bw.locppm corrected
@
text
@d6 1
a6 1
#  $Revision: 1.140 $ $Date: 2013/09/25 04:06:04 $
d1372 1
a1372 1
  ddS <- a$increm$ddS[ , isdata, , drop=FALSE]
d1374 1
a1374 1
  ddSincrements <- wQ * a$increm$ddSintegrand[ , isdata, , drop=FALSE]
@


1.140
log
@accelerated
@
text
@d6 1
a6 1
#  $Revision: 1.139 $ $Date: 2013/09/25 02:47:31 $
a1303 1
                      wpower=1,
d1413 1
a1413 1
    dScore <- mmX
d1428 1
a1428 1
    dof[k]    <- dof.k    <- sum(leve) * kernel0^wpower
@


1.139
log
@accelerated
@
text
@d6 1
a6 1
#  $Revision: 1.138 $ $Date: 2013/09/04 11:53:33 $
d1310 1
d1316 2
d1327 2
d1368 10
d1414 8
d1425 2
a1426 1
    leve <- quadform2.flat.matrices(vX, mmX, c(p, p), c(1, p))
@


1.138
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.137 $ $Date: 2013/08/31 02:27:51 $
d1359 3
a1361 3
    internals <- list(lambda=fitted(homfit),
                      hom.coef=coef(homfit),
                      mom=model.matrix(homfit))
@


1.137
log
@updated to 'Smooth'
@
text
@d6 1
a6 1
#  $Revision: 1.136 $ $Date: 2013/07/28 09:16:42 $
d403 1
a403 1
      lamT <- locppmFitted(model, coTay)
d824 7
a830 1
fitted.locppm <- function(object, ...) {
d835 30
a864 3
  # Extract local coefficients ('co' has priority over 'cg1')
  if(is.null(coefs <- object$cg) && is.null(coefs <- object$cg1))
    stop("Object does not include any fitted coefficients")
d866 2
a867 1
  if(identical(attr(coefs, "scopename"), "quadrature points")) {
d870 2
a871 3
    V <- as.ppp(coefs)
    lambda0 <- predict(homfit, locations=V)
    mom <- sample.imagelist(model.images(object), V)
d877 2
a878 2
  ans <- locppmFitted(homfit, as.matrix(coefs), precomputed=precomputed)
  return(ans)
d881 1
a881 1
locppmFitted <- function(homfit, coefs, precomputed=NULL) {
a896 6
predict.locppm <- function(object, ...) {
  trap.extra.arguments(...)
  U <- union.quad(quad.ppm(as.ppm(object)))
  lam <- fitted(object)
  ssf(U, lam)
}
d1380 1
a1380 1
      lambda <- locppmFitted(homfit, as.matrix(lpe.quad$cg),
d1391 1
a1391 1
      lambda <- locppmFitted(homfit, as.matrix(lpe$cg1),
@


1.136
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.135 $ $Date: 2013/07/27 09:56:12 $
d719 1
a719 1
  Z <- smooth.ssf(Z, ...)
d726 1
a726 1
smooth.locppm <- function(X, ..., what="cg") {
d739 1
a739 1
  out <- do.call("smooth.ppp",
d1223 1
a1223 1
             smr <- smooth.msr(res)
@


1.135
log
@redefined homtest test statistic as mean, in both cases
@
text
@d6 1
a6 1
#  $Revision: 1.134 $ $Date: 2013/07/27 08:42:17 $
d1239 1
a1239 1
    Xsim <- simulate(homfit, nsim=nsim, verbose=verbose)
@


1.134
log
@locppm records time taken for first phase, in split case.
@
text
@d6 1
a6 1
#  $Revision: 1.133 $ $Date: 2013/07/26 02:24:29 $
d1226 1
a1226 1
             h <- integral.im(sumsqr)
@


1.133
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.132 $ $Date: 2013/07/25 07:54:37 $
d10 1
a10 1
                   vcalc=c("none", "full", "hessian", "hom"),
d17 2
a18 1
  
d22 3
a24 1
  if(locations == "split") {
d61 1
d63 1
a63 1
    opt.hom <-  locppmOptions(vh=TRUE)
d68 1
d70 1
a70 1
    opt.hom <-  locppmOptions(sh1=TRUE, fh1=TRUE, gh1=TRUE)
d80 5
d102 2
d129 3
d148 2
a149 1
                        templatecall=templatecall))
d676 11
a686 5
    cat("Values computed:\n")
    explain <- LOT$descrip
    tags    <- LOT$tags
    for(i in which(present))
      cat(paste0("\t$", tags[i], ": ", explain[[i]], "\n"))
d699 2
d960 1
a960 1
  S <- integral.im(smooth.ssf(sqmag(Tv)))
@


1.132
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.131 $ $Date: 2013/07/25 07:53:28 $
a630 1
                        how=c("smoothed", "exact"),
a633 1
  how <- match.arg(how)
a643 10
  switch(how,
         smoothed = {
           Z <- smooth.ssf(Z, ...)
         },
         exact = {
           if(ncol(marx <- as.matrix(Z)) > 1) {
             Z <- lapply(as.data.frame(marx), ssf, loc=as.ppp(Z))
             Z <- as.listof(Z)
           }
         })
@


1.131
log
@corrected and extended ttestmap
@
text
@d6 1
a6 1
#  $Revision: 1.130 $ $Date: 2013/07/23 10:49:38 $
d935 1
a935 1
  tvalues <- z[[tname]])
@


1.130
log
@homtest now accepts 'simul'
@
text
@d6 1
a6 1
#  $Revision: 1.129 $ $Date: 2013/07/23 08:11:54 $
d863 3
a865 2
ttestmap <- function(object, term, ..., 
                     hessian=FALSE, grid = FALSE,
d869 1
d885 2
a886 2
  if(length(relevant) > 1 && !hessian)
    stop(paste("For Gibbs models, the test is not yet implemented",
d894 10
a903 15
  if(!grid) {
    # possibly use results computed in original object
    if(!hessian && !is.null(tg <- object$tg)) {
      # t statistic computed in original object
      result <- tg[,parm]
      result <- timed(result, starttime=starttime)
      return(result)
    }
    if(hessian && !is.null(Tg <- object$Tg)) {
      # t statistic using Hessian instead of Fisher info
      # as computed in original object
      result <- Tg[,parm]
      result <- timed(result, starttime=starttime)
      return(result)
    }
d905 2
a906 2
  # computation required
  coefs <- object$cg
d927 10
a936 25
  if(hessian) {
    # t statistic using Hessian instead of Fisher info
    z <- locppmEngine(homfit, object$sigma, Puse,
                      opt=list(Tg=TRUE, Vg=FALSE, vg=FALSE, vh=FALSE),
                      scopename=scopename, verbose=verbose)
    Tg <- z$Tg
    result <- Tg[,parm]
  } else {
    # t statistic using Fisher information
    coefvals <- as.matrix(coefs)[coarse.to.fine, ]
    outvals <- NULL
    z <- locppmEngine(homfit, sigma, Puse,
                      dropterm=term,
                      opt=list(cg=FALSE,Tg=FALSE,Vg=FALSE,vg=FALSE,vh=FALSE),
                      scopename=scopename, verbose=verbose)
    v0vals <- as.matrix(z$v0)
    # diagonal entry of variance matrix
    iiparm <- (iparm - 1) * length(coef.hom) + iparm
    var.i <- v0vals[,iiparm]
    # t statistic
    outvals <- coefvals[,iparm]/sqrt(var.i)
    outvals <- matrix(outvals, ncol=1)
    colnames(outvals) <- parm
    result <- ssf(Puse, outvals)
  }
@


1.129
log
@tweaked
@
text
@d6 1
a6 1
#  $Revision: 1.128 $ $Date: 2013/07/23 07:35:04 $
d1184 1
d1243 17
d1261 1
a1261 1
  if(verbose) cat(paste("Simulating", nsim, "realizations..."))
d1264 1
a1264 2
    XsimI <- simulate(homfit, verbose=FALSE)[[1]]
    sim[i] <- doit(XsimI, ...,
@


1.128
log
@tweaked
@
text
@d6 1
a6 1
#  $Revision: 1.127 $ $Date: 2013/07/23 06:17:22 $
a11 1
                   quick=FALSE,
d13 2
a14 1
                   verbose=TRUE, algorithm="density") {
d26 2
d56 1
a56 1
  if(!quick) {
d101 1
a101 1
                               algorithm=algorithm)
d110 1
a110 1
                               verbose=verbose, algorithm=algorithm)
d116 1
a116 1
                                   verbose=verbose, algorithm=algorithm)
d123 1
a123 1
                                   verbose=verbose, algorithm=algorithm)
d244 1
a244 1
                         algorithm = "density"
d372 1
a372 1
                      algorithm=algorithm,
d396 1
a396 1
                      algorithm=algorithm, verbose=verbose)
d1183 1
d1187 2
d1192 1
a1193 2
  if(is.null(Xname))
    Xname <- short.deparse(substitute(X))
d1207 8
a1214 5
           methodname <- paste("using",
                               if(vcalc=="hessian") "Poincare" else "local",
                               "variance")
           doit <- function(Y, ..., quick=TRUE, vcalc, locations) { 
             fit <- locppm(Y, ..., vcalc=vcalc,
d1216 3
a1218 2
                           quick=quick, verbose=FALSE)
             h <- homteststat(fit, vcalc=vcalc, verbose=FALSE)
d1224 2
a1225 1
           doit <- function(Y, ..., quick=TRUE, vcalc, locations) {
d1237 2
a1238 1
  obs <- doit(X, ..., vcalc=vcalc, locations=locations)
d1247 2
a1248 1
    sim[i] <- doit(XsimI, ..., vcalc=vcalc, locations=locations)
d1255 1
a1255 1
                 method = c(testname, methodname, testbase),
d1264 1
a1264 1
                      quick=TRUE,
d1311 1
a1311 1
  if(!quick) {
d1332 1
a1332 1
    if(!quick) {
@


1.127
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.126 $ $Date: 2013/07/23 05:41:26 $
d981 2
a982 2
  # determine whether to adjust for variability in homogeneous fit
  # Currently implemented only for Poisson
d984 1
a984 1
  nulltype <- if(told.simple || ispois) "simple" else "homogeneous"
d1000 1
a1000 1
                       homogeneous = c("sh1", "fh1", "gh1")))
d1029 1
a1029 1
                    homogeneous = {
d1083 1
a1083 2
         homogeneous = {
           theta0 <- coef(homfit)
d1124 1
a1124 1
  ncoef <- length(theta0)
d1126 1
a1126 1
  colnames(stat) <- names(theta0)
d1145 1
a1145 1
             homogeneous = {
@


1.126
log
@fixed errors in case nulltype='homogeneous'
@
text
@d6 1
a6 1
#  $Revision: 1.125 $ $Date: 2013/07/23 04:36:43 $
d972 1
a972 1
                       use.fft=TRUE, verbose=TRUE) {
d979 1
a979 1
  nulltype <- if(!is.null(theta0)) "simple" else "homogeneous"
d981 7
a987 1
  ispois <- is.poisson(object)
a1093 2
    if(verbose)
      message("Note: calculation ignores the effect of estimating theta")
@


1.125
log
@bug fix?
@
text
@d6 1
a6 1
#  $Revision: 1.124 $ $Date: 2013/07/23 02:54:40 $
a1036 6
                      # Estimation variance term
                      # D = H_v I^{-1} I_v I^{-1} H_v
                      invI0.Hvmat <- multiply2.flat.matrices(invI0mat, Hmat,
                                                     c(p,p), c(p,p))
                      Dmat <- quadform2.flat.matrices(Fmat, invI0.Hvmat,
                                                      c(p,p), c(p,p))
d1038 1
a1038 1
                      VUmat <- Fmat + Dmat - 2 * Cmat
d1143 3
a1145 3
               covterm <- sumouter(suf, w * lam * localwt)
               locinfo <- locfish +
                 (locfish - 2 * covterm) %*% vhom %*% locfish
d1150 1
a1150 1
      # null variance of local *estimates* is given by 'va'
d1184 1
@


1.124
log
@bug fix in plot.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.123 $ $Date: 2013/07/23 01:26:22 $
d386 3
d393 1
a393 1
                      internals=internals,
@


1.123
log
@removed 'cannot compute var using FFT'
@
text
@d6 1
a6 1
#  $Revision: 1.122 $ $Date: 2013/07/23 01:13:44 $
d641 10
a650 2
  if(how == "smoothed")
    Z <- smooth.ssf(Z, ...)
@


1.122
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.121 $ $Date: 2013/07/23 01:11:49 $
a35 6

  if(quick && !ispois && vcalc == "full") {
    if(verbose)
      cat("Cannot compute variance of Gibbs model using FFT: argument quick=TRUE ignored\n")
    quick <- FALSE
  }
@


1.121
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.120 $ $Date: 2013/07/23 01:10:40 $
d1016 1
a1016 1
                      VUmat <- as.matrix(fh1)
@


1.120
log
@straightened out homtestmap
@
text
@d6 1
a6 1
#  $Revision: 1.119 $ $Date: 2013/07/22 08:15:10 $
a1164 3

  homtestmap
})
@


1.119
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.118 $ $Date: 2013/07/22 08:03:35 $
d69 1
a69 1
    opt.hom <-  locppmOptions(sh1=TRUE, fh1=TRUE, gh1=TRUE, vh1=TRUE)
d965 25
a989 8
homtestmap <- local({

  objectentries <- c(sh1 = "local score",
                     fh1 = "local Fisher information",
                     vh1 = "variance of local parameter estimates",
                     gh1 = "local gradient")
  
  allpresent <- function(object, needed, alternatives=NULL, warn=TRUE) {
d991 9
a999 13
    if(!any(missed)) return(TRUE)
    if(!is.null(alternatives)) {
      missed.alt <- unlist(lapply(object[alternatives], is.null))
      if(!any(missed.alt)) return(TRUE)
    }
    if(warn) {
      gripe <- paste0("Cannot use FFT code; ",
                      "object does not contain ",
                      commasep(objectentries[needed[missed]]),
                      if(is.null(alternatives)) NULL else
                      paste("or alternatively",
                            commasep(objectentries[alternatives[missed.alt]])))
      warning(gripe)
a1000 1
    return(FALSE)
d1002 1
a1002 39

  homtestmap <- function(object, ...,
                         vcalc=c("hom", "hessian"), theta0=NULL, sigma=NULL, 
                         use.fft=TRUE, verbose=TRUE) {
    starttime <- proc.time()
    if(inherits(object, "homtestmap"))
      return(object)
    stopifnot(inherits(object, "locppm"))
    trap.extra.arguments(...)
    vcalc <- match.arg(vcalc)
    nulltype <- if(!is.null(theta0)) "simple" else "homogeneous"
    told.use.fft <- !missing(use.fft) && use.fft
    ispois <- is.poisson(object)
    homfit <- object$homfit
    hom.coef <- coef(homfit)
    p <- ncoef <- length(hom.coef)
    if(is.null(sigma))
      sigma <- object$sigma
    # try to use FFT results
    if(use.fft) {
      # check that required data are available
      switch(vcalc,
             hessian = {
               use.fft <- allpresent(object, c("sh1", "gh1"), warn=told.use.fft)
             },
             hom = {
               switch(nulltype,
                      homogeneous = {
                        use.fft <- allpresent(object, c("sh1", "fh1", "gh1"),
                                              warn=told.use.fft)
                      },
                      simple = {
                        use.fft <- allpresent(object,
                                              c("sh1", "fh1"),
                                              c("sh1", "vh1"),
                                              warn=told.use.fft)
                      })
             })
    }
d1004 48
a1051 79
    if(use.fft) {
      # extract local score
      sh1 <- object$sh1
      Umat <- as.matrix(sh1)
      P <- as.ppp(sh1)
      nP <- npoints(P)
      # calculate variance of local score
      switch(vcalc,
             hom = {
               switch(nulltype,
                      simple = {
                        # theta is fixed. 
                        if(!is.null(vh1 <- object$vh1)) {
                          VUmat <- as.matrix(vh1)
                        } else if(!is.null(fh1 <- object$fh1)) {
                          Fmat <- as.matrix(fh1)
                          VUmat <- handle.flat.matrix(Fmat, c(p, p), sqrtmat)
                        } else {
                          stop("Internal error: fh1 and vh1 missing")
                        }
                      },
                      homogeneous = {
                        # theta has been estimated.
                        Fmat <- as.matrix(object$fh1)
                        Hmat <- as.matrix(object$gh1)
                        # Inverse Fisher information of template model
                        invI0 <- vcov(homfit)
                        # Make it a flat matrix stack
                        invI0mat <- matrix(as.vector(invI0), ncol=p^2, nrow=nP,
                                        byrow=TRUE)
                        # Cross-covariance term
                        # C = H_v I^{-1} H_v
                        Cmat <- quadform2.flat.matrices(invI0mat, Hmat,
                                                        c(p,p), c(p,p))
                        # Estimation variance term
                        # D = H_v I^{-1} I_v I^{-1} H_v
                        invI0.Hvmat <- multiply2.flat.matrices(invI0mat, Hmat,
                                                       c(p,p), c(p,p))
                        Dmat <- quadform2.flat.matrices(Fmat, invI0.Hvmat,
                                                        c(p,p), c(p,p))
                        # put it together
                        VUmat <- Fmat + Dmat - 2 * Cmat
                      })
               # compute score test statistic
               # inverse square root of variance of local score
               ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
               # premultiply local score
               stat <- multiply2.flat.matrices(ISVmat, Umat, c(p, p), c(p, 1))
               # dress up
               colnames(stat) <- names(hom.coef)
               result <- ssf(P, stat)
               class(result) <- c("homtestmap", class(result))
               result <- timed(result, starttime=starttime)
               return(result)
             },
             hessian = {
               # local score and local Hessian information 
               # under homogeneous model should have already been computed
               # (by FFT)
               gh1 <- object$gh1
               Hmat <- as.matrix(gh1)
               # compute score test statistic
               # inverse square root of variance of local Hessian
               InvsqHmat <- handle.flat.matrix(Hmat, c(p, p), invsqrtmat)
               # premultiply local score
               stat <- multiply2.flat.matrices(InvsqHmat, Umat,
                                               c(p, p), c(p, 1))
               # dress up
               colnames(stat) <- names(hom.coef)
               result <- ssf(P, stat)
               class(result) <- c("homtestmap", class(result))
               result <- timed(result, starttime=starttime)
               return(result)
             })
    }
    # Slower code...
    switch(nulltype,
           simple = {
             lam <- fitted(homfit, drop=TRUE, new.coef=theta0)
d1053 18
a1070 5
           homogeneous = {
             theta0 <- coef(homfit)
             lam <- fitted(homfit, drop=TRUE)
             if(ispois)
               vhom <- vcov(homfit) 
d1072 63
a1134 23
    if(!ispois) {
      va <- switch(vcalc, hom=object$vh, hessian=object$Vg)
      if(is.null(va))
        stop(paste("Object does not contain the required variance information;",
                   "refit the model with vcalc = ", dQuote(vcalc)))
      if(verbose)
        message("Note: calculation ignores the effect of estimating theta")
      vest <- as.matrix(va)
    }
    # extract quadrature points used to fit model
    Q    <- quad.ppm(homfit, drop=TRUE)
    w    <- w.quad(Q)
    Z    <- is.data(Q)
    U    <- union.quad(Q)
    nU   <- npoints(U)
    Ux <- U$x
    Uy <- U$y
    ok <- getglmsubset(homfit)
    suf <- model.matrix(homfit)[ok, , drop=FALSE]
    # increments of residual measure of homogeneous fit
    homresid <- Z - lam * w
    #
    # determine points for evaluation
d1136 14
a1149 4
      # use all quadrature points
      P <- U
      scopename <- "quadrature points"
      coarse.to.fine <- seq_len(nU)
d1151 3
a1153 44
      # use points where 'va' was evaluated
      P <- as.ppp(va)
      scopename <- attr(va, "scopename") %orifnull% "grid points"
      coarse.to.fine <- object$coarse.to.fine
    }
    nP <- npoints(P)
    Px <- P$x
    Py <- P$y
    # create space
    ncoef <- length(theta0)
    stat <- matrix(, nrow=nP, ncol=ncoef)
    colnames(stat) <- names(theta0)
    #
    if(verbose)
      cat(paste("Processing", nP, scopename, "\n"))
    for(k in 1:nP) {
      if(verbose) 
        progressreport(k, nP)
      localwt <- dnorm(Ux - Px[k], sd=sigma) * dnorm(Uy - Py[k], sd=sigma)
      # local score at P[k] for homogeneous model
      locscore <- matrix(localwt * homresid, nrow=1) %*% suf
      # evaluate null standard error of local score
      if(ispois) {
        # local Fisher information at P[k] for homogeneous model
        locfish <- sumouter(localwt * suf, w * lam)
        # evaluate null variance of local *score*
        switch(nulltype,
               simple = {
                 locinfo <- locfish
               },
               homogeneous = {
                 covterm <- sumouter(suf, w * lam * localwt)
                 locinfo <- locfish +
                   (locfish - 2 * covterm) %*% vhom %*% locfish
               })
        # inverse square root of information matrix
        vhalf <- invsqrtmat(locinfo)
      } else {
        # null variance of local *estimates* is given by 'va'
        nullvcov <- matrix(vest[k,], nrow=ncoef, ncol=ncoef)
        vhalf <- sqrtmat(nullvcov)
      }
      # evaluate (square root of) score test statistic
      stat[k, ] <- locscore %*% vhalf
d1155 2
a1156 6
    if(verbose) cat("\t Done.\n")
    # pack up
    result <- ssf(P, stat)
    class(result) <- c("homtestmap", class(result))
    result <- timed(result, starttime=starttime)
    return(result)
d1158 7
@


1.118
log
@reorganised homtestmap
@
text
@d6 1
a6 1
#  $Revision: 1.117 $ $Date: 2013/07/20 03:41:43 $
d975 4
a978 2
    missed.alt <- unlist(lapply(object[alternatives], is.null))
    if(!any(missed.alt)) return(TRUE)
d982 1
a982 1
                      commasep(objectentries[missed]),
d984 2
a985 1
                      paste("or", commasep(objectentries[missed.alt])))
@


1.117
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.116 $ $Date: 2013/07/19 09:31:29 $
d14 1
a14 1
                   verbose=TRUE) {
d69 1
a69 1
    opt.hom <-  locppmOptions(sh1=TRUE, fh1=TRUE, gh1=TRUE)
d103 3
a105 1
                               scopename="quadrature points", verbose=verbose)
d113 2
a114 1
                               scopename="grid points", verbose=verbose)
d120 1
a120 1
                                   verbose=verbose)
d127 1
a127 1
                                   verbose=verbose)
d247 2
a248 1
                         internals = NULL
d375 3
a377 1
                      internals=internals)
d396 2
a397 1
                      internals=internals)
d965 71
a1035 37
homtestmap <- function(object, ...,
                       vcalc=c("hom", "hessian"), theta0=NULL, sigma=NULL, 
                       use.fft=TRUE, verbose=TRUE) {
  starttime <- proc.time()
  if(inherits(object, "homtestmap"))
    return(object)
  stopifnot(inherits(object, "locppm"))
  trap.extra.arguments(...)
  vcalc <- match.arg(vcalc)
  nulltype <- if(!is.null(theta0)) "simple" else "homogeneous"
  told.use.fft <- !missing(use.fft) && use.fft
  ispois <- is.poisson(object)
  homfit <- object$homfit
  hom.coef <- coef(homfit)
  p <- ncoef <- length(hom.coef)
  if(is.null(sigma))
    sigma <- object$sigma
  # try to do it quickly
  if(use.fft) {
    switch(vcalc,
           hom = {
             # local score and local Fisher information 
             # under homogeneous model should have already been computed
             # (by FFT)
             needed <- c(sh1 = "local score",
                         fh1 = "local Fisher information",
                         if(nulltype == "homogeneous")
                         c(gh1 = "local gradient") else NULL)
             missed <- unlist(lapply(object[names(needed)], is.null))
             if(!any(missed)) {
               sh1 <- object$sh1
               fh1 <- object$fh1
               Umat <- as.matrix(sh1)
               Fmat <- as.matrix(fh1)
               P <- as.ppp(sh1)
               nP <- npoints(P)
               # compute variance of local score
d1038 9
a1046 3
                        # theta0 is fixed.
                        # Variance of local score is local Fisher info
                        VUmat <- Fmat
d1050 1
d1052 2
a1053 2
                        # Take the template model variance (inverse Fisher info)
                        V0 <- vcov(homfit)
d1055 1
a1055 1
                        V0mat <- matrix(as.vector(V0), ncol=p^2, nrow=nP,
d1059 1
a1059 1
                        Cmat <- quadform2.flat.matrices(V0mat, Hmat,
d1063 1
a1063 1
                        IHv <- multiply2.flat.matrices(V0mat, Hmat,
d1065 1
a1065 1
                        Dmat <- quadform2.flat.matrices(Fmat, IHv,
d1081 5
a1085 14
             } else if(verbose && told.use.fft) {
               warning(paste("Cannot use FFT code; object does not contain",
                             commasep(needed[missed])))
             }
           },
           hessian = {
             # local score and local Hessian information 
             # under homogeneous model should have already been computed
             # (by FFT)
             needed <- c(sh1 = "local score",
                         gh1 = "local gradient")
             missed <- unlist(lapply(object[names(needed)], is.null))
             if(!any(missed)) {
               sh1 <- object$sh1
a1086 1
               Umat <- as.matrix(sh1)
a1087 2
               P <- as.ppp(sh1)
               nP <- npoints(P)
d1100 12
a1111 4
             } else if(verbose && told.use.fft) {
               warning(paste("Cannot use FFT code; object does not contain",
                             commasep(needed[missed])))
             }
d1113 23
a1135 63
  }
  # Slower code...
  switch(nulltype,
         simple = {
           lam <- fitted(homfit, drop=TRUE, new.coef=theta0)
         },
         homogeneous = {
           theta0 <- coef(homfit)
           lam <- fitted(homfit, drop=TRUE)
           if(ispois)
             vhom <- vcov(homfit) 
         })
  if(!ispois) {
    va <- switch(vcalc, hom=object$vh, hessian=object$Vg)
    if(is.null(va))
      stop(paste("Object does not contain the required variance information;",
                 "refit the model with vcalc = ", dQuote(vcalc)))
    if(verbose)
      message("Note: calculation ignores the effect of estimating theta")
    vest <- as.matrix(va)
  }
  # extract quadrature points used to fit model
  Q    <- quad.ppm(homfit, drop=TRUE)
  w    <- w.quad(Q)
  Z    <- is.data(Q)
  U    <- union.quad(Q)
  nU   <- npoints(U)
  Ux <- U$x
  Uy <- U$y
  ok <- getglmsubset(homfit)
  suf <- model.matrix(homfit)[ok, , drop=FALSE]
  # increments of residual measure of homogeneous fit
  homresid <- Z - lam * w
  #
  # determine points for evaluation
  if(ispois) {
    # use all quadrature points
    P <- U
    scopename <- "quadrature points"
    coarse.to.fine <- seq_len(nU)
  } else {
    # use points where 'va' was evaluated
    P <- as.ppp(va)
    scopename <- attr(va, "scopename") %orifnull% "grid points"
    coarse.to.fine <- object$coarse.to.fine
  }
  nP <- npoints(P)
  Px <- P$x
  Py <- P$y
  # create space
  ncoef <- length(theta0)
  stat <- matrix(, nrow=nP, ncol=ncoef)
  colnames(stat) <- names(theta0)
  #
  if(verbose)
    cat(paste("Processing", nP, scopename, "\n"))
  for(k in 1:nP) {
    if(verbose) 
      progressreport(k, nP)
    localwt <- dnorm(Ux - Px[k], sd=sigma) * dnorm(Uy - Py[k], sd=sigma)
    # local score at P[k] for homogeneous model
    locscore <- matrix(localwt * homresid, nrow=1) %*% suf
    # evaluate null standard error of local score
d1137 4
a1140 14
      # local Fisher information at P[k] for homogeneous model
      locfish <- sumouter(localwt * suf, w * lam)
      # evaluate null variance of local *score*
      switch(nulltype,
             simple = {
               locinfo <- locfish
             },
             homogeneous = {
               covterm <- sumouter(suf, w * lam * localwt)
               locinfo <- locfish +
                 (locfish - 2 * covterm) %*% vhom %*% locfish
             })
      # inverse square root of information matrix
      vhalf <- invsqrtmat(locinfo)
d1142 44
a1185 3
      # null variance of local *estimates* is given by 'va'
      nullvcov <- matrix(vest[k,], nrow=ncoef, ncol=ncoef)
      vhalf <- sqrtmat(nullvcov)
d1187 6
a1192 2
    # evaluate (square root of) score test statistic
    stat[k, ] <- locscore %*% vhalf
d1194 3
a1196 7
  if(verbose) cat("\t Done.\n")
  # pack up
  result <- ssf(P, stat)
  class(result) <- c("homtestmap", class(result))
  result <- timed(result, starttime=starttime)
  return(result)
}
@


1.116
log
@homtestmap FFT code works with Gibbs
@
text
@d6 1
a6 1
#  $Revision: 1.115 $ $Date: 2013/07/19 08:56:50 $
d965 1
d1111 2
a1112 2
    P <- va$loc
    scopename <- "grid points"
@


1.115
log
@now handles variance of Gibbs via FFT
@
text
@d6 1
a6 1
#  $Revision: 1.114 $ $Date: 2013/07/19 05:25:51 $
d976 92
a1067 83
    if(ispois && (vcalc == "hom")) {
      # local score and local Fisher information 
      # under homogeneous model should have already been computed (by FFT)
      needed <- c(sh1 = "local score",
                  fh1 = "local Fisher information",
                  if(nulltype == "homogeneous")
                    c(gh1 = "local gradient") else NULL)
      missed <- unlist(lapply(object[needed], is.null))
      if(!any(missed)) {
        sh1 <- object$sh1
        fh1 <- object$fh1
        Umat <- as.matrix(sh1)
        Fmat <- as.matrix(fh1)
        P <- as.ppp(sh1)
        nP <- npoints(P)
        # compute variance of local score
        switch(nulltype,
               simple = {
                 # theta0 is fixed.
                 # Variance of local score is local Fisher info
                 VUmat <- Fmat
               },
               homogeneous = {
                 # theta has been estimated.
                 Hmat <- as.matrix(object$gh1)
                 # Take the template model variance (inverse Fisher info)
                 V0 <- vcov(homfit)
                 # Make it a flat matrix stack
                 V0mat <- matrix(as.vector(V0), ncol=p^2, nrow=nP, byrow=TRUE)
                 # Cross-covariance term
                 # C = H_v I^{-1} H_v
                 Cmat <- quadform2.flat.matrices(V0mat, Hmat, c(p,p), c(p,p))
                 # Estimation variance term
                 # D = H_v I^{-1} I_v I^{-1} H_v
                 IHv <- multiply2.flat.matrices(V0mat, Hmat, c(p,p), c(p,p))
                 Dmat <- quadform2.flat.matrices(Fmat, IHv, c(p,p), c(p,p))
                 # put it together
                 VUmat <- Fmat + Dmat - 2 * Cmat
               })
        # compute score test statistic
        # inverse square root of variance of local score
        ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
        # premultiply local score
        stat <- multiply2.flat.matrices(ISVmat, Umat, c(p, p), c(p, 1))
        # dress up
        colnames(stat) <- names(hom.coef)
        result <- ssf(P, stat)
        class(result) <- c("homtestmap", class(result))
        result <- timed(result, starttime=starttime)
        return(result)
      } else if(verbose && told.use.fft) {
        warning(paste("Cannot use FFT code; object does not contain",
                       commasep(needed[missed])))
      }
    } else if(vcalc == "hessian") {
      # local score and local Hessian information 
      # under homogeneous model should have already been computed (by FFT)
      needed <- c(sh1 = "local score",
                  gh1 = "local gradient")
      missed <- unlist(lapply(object[needed], is.null))
      if(!any(missed)) {
        sh1 <- object$sh1
        gh1 <- object$gh1
        Umat <- as.matrix(sh1)
        Hmat <- as.matrix(gh1)
        P <- as.ppp(sh1)
        nP <- npoints(P)
        # compute score test statistic
        # inverse square root of variance of local Hessian
        InvsqHmat <- handle.flat.matrix(Hmat, c(p, p), invsqrtmat)
        # premultiply local score
        stat <- multiply2.flat.matrices(InvsqHmat, Umat, c(p, p), c(p, 1))
        # dress up
        colnames(stat) <- names(hom.coef)
        result <- ssf(P, stat)
        class(result) <- c("homtestmap", class(result))
        result <- timed(result, starttime=starttime)
        return(result)
      } else if(verbose && told.use.fft) {
        warning(paste("Cannot use FFT code; object does not contain",
                      commasep(needed[missed])))
      }
    }
@


1.114
log
@lamdif, momdif renamed lamdel, momdel
@
text
@d6 1
a6 1
#  $Revision: 1.113 $ $Date: 2013/07/18 06:37:19 $
d243 1
a243 1
                         fastRC = TRUE,
d309 8
a316 4
  
  if(fastRC && any(unlist(opt[c("vg", "vh", "v0")]))) {
    # precompute internal data for Rubak-Coeurjolly estimates
    if(is.null(internals))
d437 1
a437 1
            if(fastRC) {
d456 1
a456 1
        if(fastRC) {
d482 1
a482 1
          if(fastRC) {
@


1.113
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.112 $ $Date: 2013/07/18 06:35:10 $
d558 4
a561 4
      # Require components 'lamdif' and 'momdif'
      #   lamdif[i,j]   = lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)])
      #   momdif[ ,i,j] = h(X[i] | X[-j])      = h(X[i] | X[-c(i,j)])
      # adjust lamdif for new coefficient
d563 5
a567 5
        lamdif <- lamdif * exp(tensor(new.coef - hom.coef, momdif, 1, 1))
      #   pairweight[i,j] = lamdif[i,j]/lambda[i] - 1 
      pairweight <- lamdif / lambda[Z] - 1
      #   momdifL[ , i, j] = localwt[i] * momdif[ , i, j] 
      momdifL <- momdif * rep(localwt[Z], rep(ncoef, nX))
d569 1
a569 1
      # pairweight[i,j] * outer(momdifL[,i,j], momdifL[,j,i])
d571 1
a571 1
      A2 <- sumsymouter(momdifL[, okX, okX], w=pairweight[okX, okX])
d574 2
a575 2
      # deltamomL[ ,i,j] = momLX[j,] - momdifL[,j,i]
      deltamomL <- aperm(rep(t(momLX), nX) - momdifL,
d598 1
a598 1
              if(ispois) NULL else c("lamdif", "momdif"))
d979 2
a980 2
      missed <- needed[!(names(needed) %in% names(object))]
      if(length(missed) == 0) {
d1024 1
a1024 1
                       commasep(missed)))
d1031 2
a1032 2
      missed <- needed[!(names(needed) %in% names(object))]
      if(length(missed) == 0) {
d1052 1
a1052 1
                      commasep(missed)))
d1071 1
a1071 2
                 "refit the model with vcalc = ",
                 sQuote("hom"), "or", sQuote("hessian")))
d1190 1
a1190 1
             h <- homteststat(fit, hessian=(vcalc=="hessian"), verbose=FALSE)
@


1.112
log
@buglet fix in homtestmap
@
text
@d6 1
a6 1
#  $Revision: 1.111 $ $Date: 2013/07/18 01:23:21 $
d981 2
d996 1
a996 1
                 Hmat <- as.matrix(gh1)
d1033 2
@


1.111
log
@bw.locppm (quick=TRUE) works for Gibbs models
@
text
@d6 1
a6 1
#  $Revision: 1.110 $ $Date: 2013/07/16 10:24:16 $
d963 1
d971 79
a1049 56
  if(use.fft && ispois && (vcalc == "hom")) {
    # local score and local Fisher information
    # under homogeneous model should have already been computed (by FFT)
    cando <- TRUE
    if(is.null(sh1 <- object$sh1)) {
      cando <- FALSE
      if(verbose) warning("recomputing local score")
    }
    if(is.null(fh1 <- object$fh1)) {
      cando <- FALSE
      if(verbose) warning("recomputing local Fisher information")
    }
    if(nulltype == "homogeneous" && is.null(gh1 <- object$gh1)) {
      cando <- FALSE
      if(verbose) warning("recomputing local gradient information")
    }
    if(cando) {
      Umat <- as.matrix(sh1)
      Fmat <- as.matrix(fh1)
      P <- as.ppp(sh1)
      nP <- npoints(P)
      # compute variance of local score
      switch(nulltype,
             simple = {
               # theta0 is fixed.
               # Variance of local score is local Fisher info
               VUmat <- Fmat
             },
             homogeneous = {
               # theta has been estimated.
               Hmat <- as.matrix(gh1)
               # Take the template model variance (inverse Fisher info)
               V0 <- vcov(homfit)
               # Make it a flat matrix stack
               V0mat <- matrix(as.vector(V0), ncol=p^2, nrow=nP, byrow=TRUE)
               # Cross-covariance term
               # C = H_v I^{-1} H_v
               Cmat <- quadform2.flat.matrices(V0mat, Hmat, c(p,p), c(p,p))
               # Estimation variance term
               # D = H_v I^{-1} I_v I^{-1} H_v
               IHv <- multiply2.flat.matrices(V0mat, Hmat, c(p,p), c(p,p))
               Dmat <- quadform2.flat.matrices(Fmat, IHv, c(p,p), c(p,p))
               # put it together
               VUmat <- Fmat + Dmat - 2 * Cmat
           })
      # compute score test statistic
      # inverse square root of variance of local score
      ISVmat <- handle.flat.matrix(VUmat, c(p, p), invsqrtmat)
      # premultiply local score
      stat <- multiply2.flat.matrices(ISVmat, Umat, c(p, p), c(p, 1))
      # dress up
      colnames(stat) <- names(hom.coef)
      result <- ssf(P, stat)
      class(result) <- c("homtestmap", class(result))
      result <- timed(result, starttime=starttime)
      return(result)
d1157 1
a1157 1
                    vcalc = c("hom", "hessian"), 
a1166 1

d1176 1
d1221 1
a1221 1
                 method = c(testname, methodname),
@


1.110
log
@coef.locppm extracts cg1 if cg is null.
@
text
@d6 1
a6 1
#  $Revision: 1.109 $ $Date: 2013/07/16 06:47:30 $
d37 1
a37 1
  if(quick && !ispois && (vcalc != "none")) {
d68 1
a68 1
    opt.hess <- locppmOptions(FALSE) # not implemented
a1217 1
  ispois <- is.poisson(homfit)
a1218 6
  # decide whether to use quick-and-dirty code
  if(quick && !ispois) {
    warning("quick=TRUE is unavailable for Gibbs models: ignored")
    quick <- FALSE
  }
  
@


1.109
log
@tweaks
@
text
@d6 1
a6 1
#  $Revision: 1.108 $ $Date: 2013/07/16 06:43:40 $
d719 6
a724 3
  result <- switch(which,
                   local       = object$cg,
                   homogeneous = coef(object$homfit))
d965 2
a966 1
  p <- ncoef <- length(coef(homfit))
d1020 2
@


1.108
log
@gh1 is now computable by FFT
Corrected 'homtestmap'
@
text
@d6 1
a6 1
#  $Revision: 1.107 $ $Date: 2013/07/07 09:35:49 $
d69 1
a69 1
    opt.hom <-  locppmOptions(sh1=TRUE, fh1=TRUE)
@


1.107
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.106 $ $Date: 2013/07/06 09:12:09 $
d155 2
a156 1
         sh1="local score of homogeneous model")
d373 1
d843 1
a843 2
                     hessian=is.poisson(object),
                     grid = !is.poisson(object) && !hessian,
d871 15
a885 6
  if(hessian && !grid && !is.null(Tg <- object$Tg)) {
    # t statistic using Hessian instead of Fisher info
    # as computed in original object
    result <- Tg[,parm]
    result <- timed(result, starttime=starttime)
    return(result)
d954 1
a956 1
  starttime <- proc.time()
d959 1
d962 1
d966 1
a966 2
  if(use.fft && ispois && (vcalc == "hom") && is.null(theta0) &&
     !is.null(sh1 <- object$sh1) && !is.null(fh1 <- object$fh1)){
d968 53
a1020 19
    # under homogeneous model were already computed (by FFT)
    Umat <- as.matrix(sh1)
    Fmat <- as.matrix(fh1)
    P <- as.ppp(sh1)
    # compute score test statistic
    ncoef <- length(coef(homfit))
    stat <- apply(cbind(Umat, Fmat),
                  1,
                  function(z, n) {
                    sco <- matrix(z[1:n], ncol=1)
                    fish <- matrix(z[-(1:n)], n, n)
                    return(invsqrtmat(fish) %*% sco)
                  },
                  n=ncoef)
    stat <- if(ncoef == 1) matrix(stat, ncol=1) else t(stat)
    result <- ssf(P, stat)
    class(result) <- c("homtestmap", class(result))
    result <- timed(result, starttime=starttime)
    return(result)
a1022 1
  nulltype <- if(!is.null(theta0)) "simple" else "homogeneous"
d1202 1
d1211 1
a1211 1
  ncoef <- length(coef(homfit))
d1270 1
a1270 1
  gcv <- dof <- numeric(ns)
d1273 2
d1277 1
a1277 1
      lpe.quad <- locppmEngine(homfit, sigma[k], U, opt=opt.quad,
d1280 1
a1280 1
      lpe.data <- locppmEngine(homfit, sigma[k], X, opt=opt.data,
d1292 1
a1292 1
      lpe <- locppmEngine(homfit, sigma[k], U, opt=opt.taylor,
d1302 1
a1302 1
      vX <- invert.flat.matrices(hX, ncoef)
d1304 1
a1304 1
    # compute 'leverage' approximation of
d1306 3
a1308 7
    leve <- numeric(nX)
    for(i in 1:nX) {
      mmXi <- mmX[i, , drop=FALSE]
      vXi <- matrix(vX[i, ], ncoef, ncoef)
      leve[i] <- mmXi %*% vXi %*% t(mmXi)
    }
    leve <- leve / (2 * pi * sigma[k]^2)
d1310 3
a1312 2
    dof[k] <- sum(leve)
    gcv[k] <- sum(log(lambda[Z])) - sum(lambda * wQ, na.rm=TRUE) - dof[k]
d1314 2
a1315 1
  result <- bw.optim(gcv, sigma, iopt=which.max(gcv), cvname="cv", dof=dof)
@


1.106
log
@safety
@
text
@d6 1
a6 1
#  $Revision: 1.105 $ $Date: 2013/07/06 01:37:10 $
d61 2
a62 2
    opt.coef <- locppmOptions(co=TRUE)
    opt.hess <- locppmOptions(vp=TRUE,tp=TRUE)
d64 1
a64 1
    opt.full <- locppmOptions(co=TRUE,vg=TRUE,tg=TRUE,vp=TRUE,tp=TRUE,vh=TRUE)
d67 1
a67 1
    opt.coef <- locppmOptions(co1=TRUE)
d70 1
a70 1
    opt.full <- locppmOptions(co1=TRUE, vg1=TRUE, tg1=TRUE, vh1=TRUE) 
d142 1
a142 1
    list(co="coefficient estimates",
d145 2
a146 2
         vp="Poincare variance (inverse negative Hessian) of local fit",
         tp="Poincare approximation of t statistics of local fit",
d149 1
a149 1
         co1="Taylor approximation of local coefficient estimates",
d165 17
a181 1
  calcmap <- c(c="coef", v="var", f="fish", s="score", g="grad", t="tstat")
d187 1
a187 1
             ismatrix    = (y1 %in% c("v", "g", "f")),
d239 1
a239 1
                         opt = locppmOptions(co=TRUE, tp=TRUE),
d249 1
a249 1
  nullopt <- locppmOptions(co=TRUE, tp=TRUE, v0=!is.null(dropterm))
d289 1
a289 1
  # i.e.   co <- vg <- tg <- ... <- NULL
d301 1
a301 1
  if(need.localfit) co <- ct.blank
d359 1
a359 1
      opt$co1 <- TRUE
d368 1
a368 1
      if(opt$co1) co1 <- sample.imagelist(HF$coefficients, V)
d416 1
a416 1
          co[j, ] <- coefj <- coef(fitj)
d418 2
a419 2
          if(opt$tp)
            tp[j,] <- coef(summary(fitj))[,3]
d422 1
a422 1
          if(opt$vp) { # Poincare variance of local fit
d425 3
a427 3
            vpj <- try(vcov(fitj, dispersion=1), silent=TRUE)
            if(!inherits(vpj, "try-error") && !is.null(vpj)) 
              vp[j,] <- as.vector(vpj)
d620 1
a620 1
                        what="co",
d627 1
a627 1
    what <- FirstExtantEntry(x, c("co", "co1"), "Please specify argument what")
d673 1
a673 1
                           what="co",
d679 1
a679 1
    what <- FirstExtantEntry(x, c("co", "co1"), "Please specify argument what")
d694 1
a694 1
smooth.locppm <- function(X, ..., what="co") {
d699 1
a699 1
    what <- FirstExtantEntry(X, c("co", "co1"), "Please specify argument what")
d718 1
a718 1
                   local       = object$co,
d747 1
a747 1
    v <- object$vp
d762 1
a762 1
  coefs <- object$co
d794 2
a795 2
  # Extract local coefficients ('co' has priority over 'co1')
  if(is.null(coefs <- object$co) && is.null(coefs <- object$co1))
d870 1
a870 1
  if(hessian && !grid && !is.null(tp <- object$tp)) {
d873 1
a873 1
    result <- tp[,parm]
d878 1
a878 1
  coefs <- object$co
d902 1
a902 1
                      opt=list(tp=TRUE, vp=FALSE, vg=FALSE, vh=FALSE),
d904 2
a905 2
    tp <- z$tp
    result <- tp[,parm]
d912 1
a912 1
                      opt=list(co=FALSE,tp=FALSE,vp=FALSE,vg=FALSE,vh=FALSE),
d990 1
a990 1
    va <- switch(vcalc, hom=object$vh, hessian=object$vp)
d1210 3
a1212 3
    # fit on quadrature points, variance estimation on data points
    opt.quad <- locppmOptions(co=TRUE)
    opt.data <- locppmOptions(vp=TRUE)
d1217 1
a1217 1
    opt.taylor <- locppmOptions(co1=TRUE, gg1=TRUE)
d1238 1
a1238 1
      lambda <- locppmFitted(homfit, as.matrix(lpe.quad$co),
d1241 1
a1241 1
      vX <- lpe.data[[ "vp" ]]
d1249 1
a1249 1
      lambda <- locppmFitted(homfit, as.matrix(lpe$co1),
@


1.105
log
@removed 'rescale.vp'
@
text
@d6 1
a6 1
#  $Revision: 1.104 $ $Date: 2013/07/05 10:49:02 $
d148 1
a148 1
         v0="null variance of local fit under reduced model", 
d363 1
a363 1
      lamT <- fittedlocppmEngine(model, coTay)
a411 1
            }
d481 1
d489 2
d773 1
a773 1
fitted.locppm <- function(object, ..., drop=FALSE) {
d776 2
d781 11
a791 3
  coefs <- as.matrix(coefs)
  # Extract homogeneous/template model
  homfit <- as.ppm(object)
d793 1
a793 6
  ans <- fittedlocppmEngine(homfit, coefs)
  # drop values?
  if(drop) {
    ok <- getglmsubset(homfit)
    ans <- ans[ok]
  }
d797 1
a797 1
fittedlocppmEngine <- function(homfit, coefs, precomputed=NULL) {
d1192 1
a1192 1
  # specify fitting options
d1222 1
a1222 1
      lambda <- fittedlocppmEngine(homfit, as.matrix(lpe.quad$co),
d1228 1
a1228 1
      # fit and variance approximated on quadrature points
d1232 2
a1233 2
      # fitted conditional intensity at each quadrature point
      lambda <- fittedlocppmEngine(homfit, as.matrix(lpe$co1),
d1241 2
a1242 1
    # compute leverage at each data point    
d1249 1
a1249 1
    leve <- leve / (2 * pi * sigma[k]^2)^2
@


1.104
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.103 $ $Date: 2013/07/05 10:34:52 $
d227 1
a227 2
                         internals = NULL,
                         rescale.vp = TRUE
d410 1
a410 2
            if(!inherits(vpj, "try-error") && !is.null(vpj)) {
              if(rescale.vp) vpj <- vpj * mean(localwt^2)/mean(localwt)
@


1.103
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.102 $ $Date: 2013/07/05 09:44:18 $
d373 1
@


1.102
log
@tweaked
@
text
@d6 1
a6 1
#  $Revision: 1.101 $ $Date: 2013/07/05 09:15:28 $
a1138 1
  vcalc <- match.arg(vcalc)
@


1.101
log
@rejigged bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.100 $ $Date: 2013/07/04 07:06:26 $
d1181 1
a1181 1
      srange <- range(bw.diggle(X) * c(1/4, 4),
d1234 1
a1234 9
      vX <- apply(hX,
                  1,
                  function(z, n) {
                    mat <- matrix(z, n, n)
                    s <- try(solve(mat), silent=TRUE)
                    if(!inherits(s, "try-error")) return(s)
                    return(matrix(NA, n, n))
                  },
                  n=ncoef)
@


1.100
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.99 $ $Date: 2013/07/04 06:46:44 $
d70 1
a70 1
    opt.full <- locppmOptions(co1=TRUE, vg1=TRUE, vh1=TRUE) # tg1 not yet implemented
d145 1
a145 1
         vp="Poincare variance (negative Hessian) of local fit",
d152 1
d157 1
a157 1
  not.implemented <- "tg1"
d165 2
d169 3
a171 1
             type        = factor(y1),
d240 2
a241 2
  ismatrix    <- (LOT$type %in% c("v", "f"))
  iscoef      <- (LOT$type == "c")
d244 2
d343 1
a343 1
    if(any(unlist(opt[fftapp]))) 
d346 1
a346 1
    if(any(unlist(opt[ffthom]))) {
d348 3
a350 1
      HF <- locppmFFT(model, sigma=sigma, ..., opt=opt[ffthom],
d358 1
a358 1
    if(any(unlist(opt[fftapp]))) {
d360 1
d366 3
a368 1
      TF <- locppmFFT(model, sigma=sigma, lambda=lamT, ..., opt=opt[fftapp],
d371 2
a372 1
      if(opt$vg1) vg1 <- sample.imagelist(TF$variance,  V)
a1133 1
                      vcalc=c("hessian", "full"),
a1187 1
  hess <- (vcalc == "hessian")
d1191 1
a1191 1
    opt.data <- locppmOptions(vp=hess, vg=!hess)
d1195 2
a1196 2
    # Taylor approximation (fit and variance) on quadrature points
    opt.taylor <- locppmOptions(co1=TRUE, vg1=TRUE)
d1219 2
a1220 2
      # variance at data points
      vX <- lpe.data[[ if(hess) "vp" else "vg" ]]
d1230 13
a1242 3
      # variance at data points
      vQ <- lpe[[ "vg1" ]]
      vX <- as.matrix(vQ)[Z,,drop=FALSE]
@


1.99
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.98 $ $Date: 2013/07/04 06:21:53 $
d268 1
a268 1
  if(any(unlist(opt[tags[!ismatrix]]))) {
@


1.98
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.97 $ $Date: 2013/07/04 06:17:38 $
d1084 1
a1084 1
           doit <- function(Y, ..., quick, vcalc, locations) {
@


1.97
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.96 $ $Date: 2013/07/03 10:17:15 $
d1185 1
a1185 2
    opt.quad <- locppmOptions(co1=TRUE, vg1=TRUE)
    opt.data <- NULL
d1192 1
a1192 1
  if(verbose) cat(paste("Assessing", ns, "values of sigma..."))
d1213 3
a1215 3
      lpe.quad <- locppmEngine(homfit, sigma[k], U, opt=opt.quad,
                               scopename="quadrature points",
                               verbose=FALSE, internals=internals)
d1217 1
a1217 1
      lambda <- fittedlocppmEngine(homfit, as.matrix(lpe.quad$co1),
d1220 1
a1220 1
      vQ <- lpe.quad$vg1
@


1.96
log
@tweaked default srange again in bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.95 $ $Date: 2013/07/03 09:33:17 $
d564 1
a564 1
  internals <- vcov(model, what="internals", saveterms=TRUE, parallel=TRUE)
a575 2
  areaW <- if(model$correction == "border")
           eroded.areas(W, model$rbord) else area.owin(W)
d577 5
a581 2
                      list(wQ=wQ, areaW=areaW, nX=nX,
                           ispois=ispois, hom.coef=coef(model)))
d1074 1
a1074 1
           doit <- function(Y, ..., vcalc, locations) { 
d1077 1
a1077 1
                           quick=TRUE, verbose=FALSE)
d1084 1
a1084 1
           doit <- function(Y, ..., vcalc, locations) {
@


1.95
log
@adjusted srange in bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.94 $ $Date: 2013/07/03 02:58:51 $
d1122 1
a1122 2
                      srange=NULL, ns=9,
                      sigma = seq(srange[1], srange[2], length=ns),
d1168 2
a1169 1
      srange <- bw.diggle(X) * c(1/2, 2)
d1171 1
a1171 1
    sigma <- seq(srange[1], srange[2], length=ns)
@


1.94
log
@minor fixes
@
text
@d6 1
a6 1
#  $Revision: 1.93 $ $Date: 2013/07/03 02:21:44 $
d341 2
a342 1
      HF <- locppmFFT(model, sigma=sigma, ..., opt=opt[ffthom])
d356 2
a357 1
      TF <- locppmFFT(model, sigma=sigma, lambda=lamT, ..., opt=opt[fftapp])
d777 1
a777 1
fittedlocppmEngine <- function(homfit, coefs) {
d780 1
a780 1
  # first compute fitted conditional intensity of homogeneous model
d782 3
a784 3
  lambda0 <- fitted(homfit)
  coef0 <- coef(homfit)
  mom <- model.matrix(homfit)
d1121 1
d1136 6
d1169 1
a1169 3
      smin <- bw.frac(X, f=1/30)
      smax <- bw.frac(X, f=2/3)
      srange <- c(smin, smax)
d1176 15
a1190 6
  opt.fit <- c(co = TRUE,  tp = FALSE, vp = FALSE, vg = FALSE, vh = FALSE)
  opt.var <- c(co = FALSE, tp = FALSE, vp = hess,  vg = !hess, vh = FALSE)

  # precompute internal data for variance estimates
  internals <- getvcinternals(homfit, verbose=verbose)
  
d1196 28
a1223 15
    # fit on quadrature points, variance estimation on data points
    lpe.fit <- locppmEngine(homfit, sigma[k], U, opt=opt.fit,
                            scopename="quadrature points",
                            verbose=FALSE, internals=internals)
    lpe.var <- locppmEngine(homfit, sigma[k], X, opt=opt.var,
                            scopename="data points",
                            scopeindex=Xindex,
                            verbose=FALSE, internals=internals)
    # compute fitted conditional intensity at each quadrature point
    # (see fitted.locppm for explanation)
    coefs <- as.matrix(lpe.fit$co)
    lambda <- lambda0 * exp(rowSums(mm * (coefs - coef0mat)))
    # compute leverage at each data point
    vX <- lpe.var[[ if(hess) "vp" else "vg" ]]
    vX <- as.matrix(vX)
@


1.93
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.92 $ $Date: 2013/07/03 02:18:28 $
d70 1
a70 1
    opt.full <- locppmOptions(co1=TRUE, vh1=TRUE, vg1=TRUE) # tg1 not yet implemented
a616 1
  names(present) <- possible
d620 4
a623 4
    explain <- LOT$descrip[present]
    nama <- names(explain)
    for(i in seq(along=explain))
      cat(paste0("\t$", nama[i], ": ", explain[[i]], "\n"))
@


1.92
log
@tweaked
@
text
@d6 1
a6 1
#  $Revision: 1.91 $ $Date: 2013/07/03 02:15:17 $
d770 1
a770 1
    ok <- getglmsubset(fit0)
@


1.91
log
@implemented vg1
@
text
@d6 1
a6 1
#  $Revision: 1.90 $ $Date: 2013/07/02 10:57:46 $
d70 1
a70 1
    opt.full <- locppmOptions(co1=TRUE, vh1=TRUE) # vg1, tg1 not yet implemented
d151 1
a151 1
         tg1="Taylor approximation of t statistics of local fit",
@


1.90
log
@tweaking tweaking
@
text
@d6 1
a6 1
#  $Revision: 1.89 $ $Date: 2013/07/02 10:45:53 $
d37 1
a37 1
  if(quick && !ispois) {
d39 1
a39 1
      cat("FFT calculations not implemented for Gibbs models: ignored\n")
d149 2
a150 2
         co1="Taylor approximation of coefficient estimates",
         vg1="Taylor approximation of variance of local fit",
d156 1
a156 1
  not.implemented <- c("vg1", "tg1")
d236 1
d328 1
a328 1
  if(any(unlist(uf <- opt[tags[usefft]]))) {
d332 27
a358 12
    FF <- locppmFFT(model, sigma=sigma, ..., opt=uf)
    if(verbose) cat("Sampling...")
    # Extract values at locations V
    sample.listof <- function(X, V) {
      Xvals <- lapply(X, "[", i=V)
      Xmat <- as.matrix(as.data.frame(Xvals))
      return(Xmat)
    }
    if(opt$co1) co1 <- sample.listof(FF$coefficients, V)
    if(opt$vh1) vh1 <- sample.listof(FF$variance,     V)
    if(opt$fh1) fh1 <- sample.listof(FF$fisher,       V)
    if(opt$sh1) sh1 <- sample.listof(FF$score,        V)
d758 21
d781 3
a783 8
  fit0 <- as.ppm(object)
  lambda0 <- fitted(fit0)
  coef0 <- coef(fit0)
  mom <- model.matrix(fit0)
  # now extract local coefficients
  if(is.null(coefs <- object$co))
    stop("Object does not include fitted coefficients")
  coefs <- as.matrix(coefs)
a800 18
# square root of pos def matrix
sqrtmat <- function(M) {
  s <- svd(M)
  d <- s$d
  n <- length(d)
  dsd <- diag(sqrt(d), n, n)
  Y <- s$u %*% dsd %*% t(s$v)
  return(Y)
}
# inverse square root of pos def matrix
invsqrtmat <- function(M) {
  s <- svd(M)
  d <- s$d
  n <- length(d)
  isd <- diag(1/sqrt(d), n, n)
  Y <- s$u %*% isd %*% t(s$v)
  return(Y)
}
@


1.89
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.88 $ $Date: 2013/07/02 09:46:22 $
d891 1
a891 1
                       hessian=FALSE, theta0=NULL, sigma=NULL, 
d897 1
d903 1
a903 1
  if(use.fft && ispois && !hessian && is.null(theta0) &&
d939 1
a939 1
    va <- if(!hessian) object$vh else object$vp
d941 1
a941 1
      stop(paste("Object does not contain variance information;",
d943 1
a943 1
                 sQuote("full"), "or", sQuote("hessian")))
@


1.88
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.87 $ $Date: 2013/07/02 09:44:31 $
d12 1
a12 1
                   taylor=FALSE,
d33 1
d37 4
a40 3
  if(taylor && !ispois) {
    warning("Taylor approximation not yet implemented for Gibbs models")
    taylor <- FALSE
d60 1
a60 1
  if(!taylor) {
d66 1
a66 1
    # Taylor approximations (Poisson only)
d133 2
a134 1
                        ngrid=ngrid, grideps=grideps))
d595 1
a595 1
  cat(paste("\t", x$homfit$callstring, "\n\n"))
d1031 1
a1031 1
                    vcalc = c("full", "hessian"),
a1035 1
  cl <- sys.call()
d1037 1
a1038 3
  vcalc <- match.arg(vcalc)
  if(vcalc == "full")
    vcalc <- "hom"
d1041 3
a1043 1
  #
d1054 3
a1056 3
           methodname <-
             if(vcalc == "hessian") "using Poincare variance" else
                                    "using local variance" 
d1058 3
a1060 2
             fit <- locppm(Y, ..., vcalc=vcalc, locations=locations,
                           verbose=FALSE)
@


1.87
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.86 $ $Date: 2013/07/02 09:38:27 $
d19 1
@


1.86
log
@homtestmap can now access FFT results
@
text
@d6 1
a6 1
#  $Revision: 1.85 $ $Date: 2013/07/02 08:03:43 $
d67 1
a67 1
    opt.full <- locppmOptions(co1=TRUE, vh1=TRUE) # vg1 not yet implemented
@


1.85
log
@'hom' is now a formal option for 'vcalc'
@
text
@d6 1
a6 1
#  $Revision: 1.84 $ $Date: 2013/07/02 07:47:55 $
d66 2
a67 2
    opt.hom <-  locppmOptions(vh1=TRUE, sh1=TRUE, fh1=TRUE)
    opt.full <- locppmOptions(other1=TRUE, vg1=FALSE, tg1=FALSE) 
d87 1
a87 1
           # undocumented option for use by 'homtest'.
d887 2
a888 1
                       hessian=FALSE, theta0=NULL, sigma=NULL, verbose=TRUE) {
d897 25
@


1.84
log
@implemented FFT code for sh1, fh1
@
text
@d6 1
a6 1
#  $Revision: 1.83 $ $Date: 2013/07/02 07:22:27 $
d10 1
a10 1
                   vcalc=c("none", "full", "hessian"),
a18 3

  if(!identical(vcalc, "hom"))
    vcalc <- match.arg(vcalc)
@


1.83
log
@tweaked FFT code
@
text
@d6 1
a6 1
#  $Revision: 1.82 $ $Date: 2013/07/02 06:11:11 $
d69 2
a70 2
    opt.hom <-  locppmOptions(vh1=TRUE)
    opt.full <- locppmOptions(co1=TRUE,vh1=TRUE) # variances not implemented
d326 2
a327 3
  if(any(hf <- unlist(opt[c("co1", "vh1")]))) {
    # Compute first order Taylor approximation to fitted coefficients
    # and/or null variance of local score under homogeneous model
d329 2
a330 5
      cat(paste("Computing",
                commasep(c("Taylor approximation", "null variance")[hf]),
                "..."))
    FF <- locppmFFT(model, sigma=sigma, ...,
                    what=c("coefficients", "variance")[hf])
d333 4
a336 7
    if(opt$co1) {
      Cvals <- lapply(FF$coefficients, "[", i=V)
      co1 <- as.matrix(as.data.frame(Cvals))
    }
    if(opt$vh1) {
      Vvals <- lapply(FF$variance, "[", i=V)
      vh1 <- as.matrix(as.data.frame(Vvals))
d338 4
@


1.82
log
@fixed handling of options
@
text
@d6 1
a6 1
#  $Revision: 1.81 $ $Date: 2013/07/02 06:02:23 $
d151 3
a153 1
         vh1="null variance of local fit under homogeneous model (by FFT)")
d234 1
a234 1
  ismatrix    <- (LOT$type == "v")
d248 1
a248 1
  need.localfit <- any(unlist(opt[tags[modeltype == "l"]]))
d334 1
a334 1
                    give.coef=opt$co1, give.var=opt$vh1)
d599 1
d607 1
a607 1
    explain <- LOT$descrip
@


1.81
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.80 $ $Date: 2013/07/02 06:01:18 $
d202 1
a202 1
    explain <- .locppmOptionTable[y]
d576 1
a576 1
    what <- match.arg(what, names(.locppmOptionTable))
d597 2
a598 1
  possible <- names(.locppmOptionTable)
d604 1
a604 1
    explain <- .locppmOptionTable[present]
d628 1
a628 1
    what <- match.arg(what, names(.locppmOptionTable))
d648 1
a648 1
    what <- match.arg(what, names(.locppmOptionTable))
d650 1
a650 1
    what <- FirstExtantEntry(x, c("co", "co1"), "Please specify argument what")
@


1.80
log
@buglet fix
@
text
@d6 1
a6 1
#  $Revision: 1.79 $ $Date: 2013/07/02 04:32:14 $
d229 1
a229 1
  LOT <- .locppmOptionsTable
@


1.79
log
@reorganised options (again)
implemented 'vh1'
@
text
@d6 1
a6 1
#  $Revision: 1.78 $ $Date: 2013/07/01 09:13:38 $
d173 3
a175 4
  with(.locppmOptionTable, {
    opt <- ifelse(usefft, other1, other)
    names(opt) <- tags
  })
d230 5
a234 7
  with(LOT, {
    tags <- tags
    usefft <- usefft
    ismatrix <- (type == "v")
    implemented <- implemented
    modeltype <- modeltype
  })
@


1.78
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.77 $ $Date: 2013/07/01 08:51:15 $
a59 1
  opt.hom <-  locppmOptions(vh=TRUE)
d63 1
d66 1
a66 1
    # Taylor approximations
d69 2
a70 1
    opt.full <- locppmOptions(co1=TRUE) # variance not implemented
d139 39
a177 17
.locppmOptionTable <-
  list(co="coefficient estimates",
       vg="variance of local fit",
       tg="t statistics of local fit",
       vp="Poincare variance (negative Hessian) of local fit",
       tp="Poincare approximation of t statistics of local fit",
       vh="null variance of local fit under homogeneous model",
       v0="null variance of local fit under reduced model", 
       co1="Taylor approximation of coefficient estimates",
       vg1="Taylor approximation of variance of local fit",
       tg1="Taylor approximation of t statistics of local fit")

locppmOptions <- function(other=FALSE, ..., taylor=other) {
  optnames <- names(.locppmOptionTable)
  if(!is.logical(other)) stop("Logical values expected")
  opt <- ifelse(substr(optnames, 1, 6) == "Taylor", taylor, other)
  names(opt) <- optnames
d179 2
a180 2
  nargh <- names(argh)
  hit <- (nargh %in% optnames)
d184 1
a184 1
    opt[nargh[hit]] <- newvalues
d186 1
d190 2
a191 1
                  commasep(sQuote(nargh[!hit]))))
d229 25
a253 11
  # Things not yet implemented:
  if(opt$vg1) {
    warning("Option vg1 is not yet implemented")
    opt$vg1 <- FALSE
  }
  if(opt$tg1) {
    warning("Option tg1 is not yet implemented")
    opt$tg1 <- FALSE
  }
  # should we fit a GLM at each location?
  do.localfit <- any(unlist(opt[c("co", "vg", "tg", "vp", "tp")]))
d255 1
d264 5
a268 3
  # initialise space for results
  co <- vg <- tg <- vp <- tp <- vh <- v0 <- co1 <- vg1 <- tg1 <- NULL
  if(any(unlist(opt[c("co", "tg", "tp", "co1", "tg1")]))) {
d272 2
a273 1
  if(any(unlist(opt[c("vg", "vp", "vh", "v0", "vg1")]))) {
d277 4
a280 10
  if(do.localfit) co <- ct.blank
  if(opt$tg) tg <- ct.blank
  if(opt$tp) tp <- ct.blank
  if(opt$vg) vg <- v.blank
  if(opt$vp) vp <- v.blank 
  if(opt$vh) vh <- v.blank
  if(opt$v0) v0 <- v.blank
  if(opt$co1) co1 <- ct.blank
  if(opt$tg1) tg1 <- ct.blank
  if(opt$vg1) vg1 <- v.blank
d282 1
d284 1
d297 1
a297 1
  if(do.localfit || opt$v0) {
d327 1
a327 2
  if(opt$co1) {
    if(verbose) cat("Computing Taylor approximation...")
d329 7
a335 1
    CC <- locppmTaylor(model, sigma=sigma, ...)
d338 8
a345 2
    Cvals <- lapply(CC, "[", i=V)
    co1 <- as.matrix(as.data.frame(Cvals))
d349 1
a349 1
  if(any(unlist(opt[c("co", "vg", "tg", "vp", "tp", "vh", "v0")]))) {
d365 1
a365 1
      if(do.localfit) {
d451 14
a464 25
  
  if(!matrices) {
    # convert to ssf objects
    if(!is.null(co)) co <- ssf(V, co)
    if(!is.null(vg)) vg <- ssf(V, vg)
    if(!is.null(tg)) tg <- ssf(V, tg)
    if(!is.null(vp)) vp <- ssf(V, vp)
    if(!is.null(tp)) tp <- ssf(V, tp)
    if(!is.null(vh)) vh <- ssf(V, vh)
    if(!is.null(v0)) v0 <- ssf(V, v0)
    if(!is.null(co1)) co1 <- ssf(V, co1)
    if(!is.null(vg1)) vg1 <- ssf(V, vg1)
    if(!is.null(tg1)) tg1 <- ssf(V, tg1)
  }
  if(!is.null(scopeindex)) {
    if(!is.null(co))  attr(co,  "scopeindex") <- scopeindex
    if(!is.null(vg))  attr(vg,  "scopeindex") <- scopeindex
    if(!is.null(tg))  attr(tg,  "scopeindex") <- scopeindex
    if(!is.null(vp))  attr(vp,  "scopeindex") <- scopeindex
    if(!is.null(tp))  attr(tp,  "scopeindex") <- scopeindex
    if(!is.null(vh))  attr(vh,  "scopeindex") <- scopeindex
    if(!is.null(v0))  attr(v0,  "scopeindex") <- scopeindex
    if(!is.null(co1)) attr(co1, "scopeindex") <- scopeindex
    if(!is.null(vg1)) attr(vg1, "scopeindex") <- scopeindex
    if(!is.null(tg1)) attr(tg1, "scopeindex") <- scopeindex
d466 2
a467 2
  result <- list(co=co, vg=vg, tg=tg, vp=vp, tp=tp, vh=vh, v0=v0,
                 co1=co1, vg1=vg1, tg1=tg1)
@


1.77
log
@better defaults for plot functions
@
text
@d6 1
a6 1
#  $Revision: 1.76 $ $Date: 2013/07/01 08:49:47 $
d432 1
d539 5
a543 5
  if(missing(what)) {
    namx <- names(x)
    what <- if("co" %in% namx) "co" else
            if("co1" %in% namx) "co1" else stop("Please specify argument what")
  } else what <- match.arg(what, names(.locppmOptionTable))
d590 5
a594 5
  if(missing(what)) {
    namx <- names(x)
    what <- if("co" %in% namx) "co" else
            if("co1" %in% namx) "co1" else stop("Please specify argument what")
  } else what <- match.arg(what, names(.locppmOptionTable))
d610 5
a614 5
  if(missing(what)) {
    namx <- names(x)
    what <- if("co" %in% namx) "co" else
            if("co1" %in% namx) "co1" else stop("Please specify argument what")
  } else what <- match.arg(what, names(.locppmOptionTable))
@


1.76
log
@useful default for plot
@
text
@d6 1
a6 1
#  $Revision: 1.75 $ $Date: 2013/07/01 08:47:16 $
d589 5
a593 1
  what <- match.arg(what, names(.locppmOptionTable))
d609 5
a613 1
  what <- match.arg(what, names(.locppmOptionTable))
@


1.75
log
@neatened
@
text
@d6 1
a6 1
#  $Revision: 1.74 $ $Date: 2013/07/01 08:25:22 $
d538 5
a542 1
  what <- match.arg(what, names(.locppmOptionTable))
@


1.74
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.73 $ $Date: 2013/07/01 08:21:13 $
d37 6
d60 1
a61 1
    opt.full <- locppmOptions(co=TRUE, vp=TRUE, vg=TRUE, vh=TRUE)
d63 2
a64 1
    opt.hom <-  locppmOptions(vh = TRUE)
a66 1
    opt.full <- locppmOptions(co1=TRUE, vg1=TRUE, tg1=TRUE)
d68 2
a69 1
    opt.hom <-  locppmOptions(FALSE)
d81 1
a81 1
           opt.var <- opt.hessian & !opt.coef
d289 1
d292 1
d296 1
a297 6
  
  # full pattern of quadrature points 
  U <- union.quad(quad.ppm(model))
  nU <- npoints(U)
  Ux <- U$x
  Uy <- U$y
d299 8
a306 2
  if(verbose)
    cat(paste("Processing", nV, scopename, "...\n"))
a307 1
  for(j in 1:nV) {
d309 43
a351 22
      progressreport(j, nV)
    localwt <- dnorm(Ux - Vx[j], sd=sigma) * dnorm(Uy - Vy[j], sd=sigma)
    if(do.localfit) {
      assign("localwt", localwt, envir=env.update)
      fitj <- update(m, weights = .mpl.W * localwt, start=coef.hom,
                     evaluate=FALSE)
      fitj <- try(eval(fitj, enclos=env.model, envir=env.here), silent=TRUE)
      if(!inherits(fitj, "try-error") && fitj$converged) {
        # fitted coefficients
        co[j, ] <- coefj <- coef(fitj)
        # Poincare t-statistic for each parameter (using Hessian)
        if(opt$tp)
          tp[j,] <- coef(summary(fitj))[,3]
        # variance of local parameter estimates under local model
        # (for confidence intervals)
        if(opt$vp) { # Poincare variance of local fit
          # Note that for a GLM with weights,
          # vcov.glm returns the inverse of the negative Hessian
          vpj <- try(vcov(fitj, dispersion=1), silent=TRUE)
          if(!inherits(vpj, "try-error") && !is.null(vpj)) {
            if(rescale.vp) vpj <- vpj * mean(localwt^2)/mean(localwt)
            vp[j,] <- as.vector(vpj)
d354 30
a383 2
        if(opt$vg || opt$tg) {
          # Rubak-Coeurjolly type estimate of variance of local fit
d385 2
a386 2
            vgj <- vcovlocEngine(internals, localwt,
                                 A1dummy=TRUE, new.coef=coefj)
d388 1
a388 2
            vgj <- try(vcov(model,
                            matwt=localwt, new.coef=coefj,
d392 3
a394 42
          if(!inherits(vgj, "try-error") && !is.null(vgj)) {
            if(opt$vg) vg[j,] <- as.vector(vgj)
            if(opt$tg) tg[j,] <- coefj/sqrt(diag(vgj))
          }
        }
      }
    }
    # variance of local parameter estimates under homogeneous model
    # (for tests of homogeneity)
    if(opt$vh) {
      if(fastRC) {
        vhj <- vcovlocEngine(internals, localwt, A1dummy=TRUE)
      } else {
        vhj <- try(vcov(model, matwt=localwt, A1dummy=TRUE,
                        matrix.action="silent"),
                   silent=TRUE)
      }
      if(!inherits(vhj, "try-error") && !is.null(vhj) && length(as.vector(vhj)) == ncoef2)
        vh[j,] <- as.vector(vhj)
    }
    # variance of local parameter estimates under local NULL model
    # (for local test of H_0: beta_k = 0)
    if(opt$v0) {
        # fit null model
      fit0j <- update(m, dropfmla,
                      weights = .mpl.W * localwt, start=coef.hom0,
                      evaluate=FALSE)
      fit0j <- try(eval(fit0j, enclos=env.model, envir=env.here), silent=TRUE)
      if(!inherits(fit0j, "try-error")) {
        # extract coefficients of null model
        c0j <- coef(fit0j)
        # inject into alternative
        coef0j <- zerocoef
        coef0j[nullmap] <- c0j
        # compute null variance of score
        if(fastRC) {
          v0j <- vcovlocEngine(internals, localwt,
                               A1dummy=TRUE, new.coef=coef0j)
        } else {
          v0j <- try(vcov(model, matwt=localwt, new.coef=coef0j,
                          A1dummy=TRUE, matrix.action="silent"),
                     silent=TRUE)
a395 2
        if(!inherits(v0j, "try-error") && !is.null(v0j) && length(as.vector(v0j)) == ncoef2)
          v0[j,] <- as.vector(v0j)
d398 2
d401 1
a401 1
  if(verbose) cat("Done.\n")
d416 10
a425 10
    if(!is.null(co)) attr(co, "scopeindex") <- scopeindex
    if(!is.null(vg))    attr(vg,    "scopeindex") <- scopeindex
    if(!is.null(tg))    attr(tg,    "scopeindex") <- scopeindex
    if(!is.null(vp))    attr(vp,    "scopeindex") <- scopeindex
    if(!is.null(tp))    attr(tp,    "scopeindex") <- scopeindex
    if(!is.null(vh))    attr(vh,    "scopeindex") <- scopeindex
    if(!is.null(v0))    attr(v0,    "scopeindex") <- scopeindex
    if(!is.null(co1))   attr(co1,    "scopeindex") <- scopeindex
    if(!is.null(vg1))   attr(vg1,    "scopeindex") <- scopeindex
    if(!is.null(tg1))   attr(tg1,    "scopeindex") <- scopeindex
@


1.73
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.72 $ $Date: 2013/06/30 07:00:46 $
d338 1
@


1.72
log
@changed words in output
@
text
@d6 1
a6 1
#  $Revision: 1.71 $ $Date: 2013/06/30 06:53:57 $
d12 1
d53 11
a63 10
  opt.full <-
    c(co = TRUE,  tp = TRUE,  vp = TRUE,  vg = !ispois, vh = TRUE)
  opt.none <-
    c(co = FALSE, tp = FALSE, vp = FALSE, vg = FALSE,   vh = FALSE)
  opt.coef <-
    c(co = TRUE,  tp = FALSE, vp = FALSE, vg = FALSE,   vh = FALSE)
  opt.hessian <-
    c(co = TRUE,  tp = TRUE,  vp = TRUE,  vg = FALSE,   vh = FALSE)
  opt.hom <-
    c(co = FALSE, tp = FALSE, vp = FALSE, vg = FALSE,   vh = TRUE)
d131 48
d184 1
a184 5
                         opt = list(co=TRUE,
                                    tp=TRUE,
                                    vp=FALSE,
                                    vg=FALSE,
                                    vh=FALSE),
d188 2
a189 1
                         internals = NULL
d195 13
a207 8
  opt <- as.list(opt)
  opt <- resolve.defaults(opt, list(co=TRUE,
                                    tp=TRUE,
                                    vp=FALSE,
                                    vg=FALSE,
                                    vh=FALSE,
                                    v0=!is.null(dropterm)))
  do.localfit <- any(unlist(opt[c("co", "tp", "vp", "vg")]))
d218 22
a239 15
  coefs <- tp <- vp <- vg <- vh <- v0 <- NULL
  if(do.localfit) {
    # local fit will be performed; coefficients will be saved
    coefs <- matrix(NA_real_, nrow=nV, ncol=ncoef)
    colnames(coefs) <- nama
    if(opt$tp) tp <- coefs
  }
  if(any(unlist(opt[c("vp", "vg", "vh", "v0")]))) {
    template <-  matrix(NA_real_, nrow=nV, ncol=ncoef2)
    colnames(template) <- as.vector(outer(nama, nama, paste, sep="."))
    if(opt$vp) vp <- template 
    if(opt$vg) vg <- template
    if(opt$vh) vh <- template
    if(opt$v0) v0 <- template
  }
d280 8
d309 2
a310 2
        coefs[j, ] <- coefj <- coef(fitj)
        # t-statistic for each parameter (using Hessian)
d319 2
a320 1
          if(!inherits(vpj, "try-error") && length(as.vector(vpj)) == ncoef2)
d322 1
d324 2
a325 1
        if(opt$vg) { # Rubak-Coeurjolly type estimate of local fit
d335 3
a337 2
          if(!inherits(vgj, "try-error") && !is.null(vgj) && length(as.vector(vgj)) == ncoef2)
            vg[j,] <- as.vector(vgj)
d364 1
a364 1
        coef0j <- coef(fit0j)
d366 2
a367 2
        co <- zerocoef
        co[nullmap] <- coef0j
d371 1
a371 1
                               A1dummy=TRUE, new.coef=co)
d373 1
a373 1
          v0j <- try(vcov(model, matwt=localwt, new.coef=co,
d385 4
a388 1
    if(!is.null(coefs)) coefs <- ssf(V, coefs)
a389 2
    if(!is.null(vp)) vp <- ssf(V, vp)
    if(!is.null(vg)) vg <- ssf(V, vg)
d392 3
d397 4
a400 1
    if(!is.null(coefs)) attr(coefs, "scopeindex") <- scopeindex
a401 2
    if(!is.null(vp))    attr(vp,    "scopeindex") <- scopeindex
    if(!is.null(vg))    attr(vg,    "scopeindex") <- scopeindex
d404 3
d408 2
a409 1
  result <- list(coefs=coefs, tp=tp, vp=vp, vg=vg, vh=vh, v0=v0)
d515 1
a515 1
                        what=c("coefs", "vp", "vg", "vh", "tp"),
d519 1
a519 1
  what <- match.arg(what)
d537 1
a537 3
  cat("Coefficient estimates ($coef):\n")
  print(x$coefs, brief=TRUE)
  possible <- c("vp","vg","vh","tp") 
d542 5
a546 9
    cat("Also computed:\n")
    if(present[["vp"]])
      cat("\t$vp: Poincare variance of local fit\n") 
    if(present[["vg"]])
      cat("\t$vg: variance of local fit (valid for Gibbs/Poisson)\n") 
    if(present[["vh"]])
      cat("\t$vh: variance of local fit under homogeneous model\n") 
    if(present[["tp"]])
      cat("\t$tp: local t statistics using Poincare variance\n")
d563 1
a563 1
                           what=c("coefs", "vp", "vg", "vh", "tp"),
d566 1
a566 1
  what <- match.arg(what)
d580 1
a580 1
smooth.locppm <- function(X, ..., what=c("coefs", "vp", "vg", "vh", "tp")) {
d582 1
a582 1
  what <- match.arg(what)
d600 1
a600 1
                   local       = object$coefs,
d644 1
a644 1
  coefs <- object$coefs
d679 1
a679 1
  if(is.null(coefs <- object$coefs))
d757 1
a757 1
  coefs <- object$coefs
d1080 1
a1080 1
    coefs <- as.matrix(lpe.fit$coefs)
@


1.71
log
@changed default options:
vcalc='full' now always computes Rubak-Coeurjolly estimate,
even for Poisson models
@
text
@d6 1
a6 1
#  $Revision: 1.70 $ $Date: 2013/06/30 03:21:55 $
d466 1
a466 1
      cat("\t$vp: Poincare variance of local estimates\n") 
d468 1
a468 1
      cat("\t$vg: Gibbs variance of local estimates\n") 
d472 1
a472 1
      cat("\t$tp: local t statistics using Poisson/Poincare variance\n")
@


1.70
log
@corrected calculation of vcov in vcovlocEngine
@
text
@d6 1
a6 1
#  $Revision: 1.69 $ $Date: 2013/06/17 08:03:27 $
d248 3
a250 1
        if(opt$vp) { # Poisson or Poincare variance of local fit
d466 1
a466 1
      cat("\t$vp: Poisson/Poincare variance of local estimates\n") 
d553 2
a554 1
  if(ispois) {
d558 2
a559 9
  } else {
    v <- object$vg
    if(is.null(v)) {
      v <- object$vp
      if(is.null(v))
        stop("Fitted model does not contain variances")
      else
        warning("Using Poincare variance (Hessian matrix)")
    }
@


1.69
log
@now uses 'parallel' algorithm in vcov.ppm
@
text
@d6 1
a6 1
#  $Revision: 1.68 $ $Date: 2013/04/22 09:30:34 $
d359 6
d395 1
d397 1
a397 1
    U <- try(solve(A1))
@


1.68
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.67 $ $Date: 2013/04/22 07:39:15 $
d401 1
a401 1
  internals <- vcov(model, what="internals", saveterms=TRUE)
d559 1
a559 1
  v <- v$val
d574 2
a575 2
  co <- coefs$val
  P  <- coefs$loc
d710 1
a710 1
    coefvals <- coefs$val[coarse.to.fine, ]
d716 1
a716 1
    v0vals <- z$v0$val
d772 1
a772 1
    vest <- va$val
d832 1
a832 1
      # null variance of local *estimates* is given by va$val
d851 1
a851 1
  y <- matrix(rowSums(x$val^2), ncol=1)
@


1.67
log
@D'OH!! forgot square root in t statistic
@
text
@d6 1
a6 1
#  $Revision: 1.66 $ $Date: 2013/04/20 10:46:51 $
d717 1
d719 3
a721 1
    outvals <- coefvals[,iparm]/sqrt(v0vals[,iiparm])
@


1.66
log
@accelerated fitted.locppm and bw.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.65 $ $Date: 2013/04/19 09:04:12 $
d718 1
a718 1
    outvals <- coefvals[,iparm]/v0vals[,iiparm]
@


1.65
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.64 $ $Date: 2013/04/19 08:52:36 $
d595 2
d598 12
a609 7
  gfit <- getglmfit(fit0)
  gdat <- getglmdata(fit0, drop=drop)
  coefs <- as.matrix(object$coefs)
  nQ <- n.quad(quad.ppm(fit0, drop=drop))
  ans <- numeric(nQ)
  for(i in 1:nQ) 
    ans[i] <- GLMpredict(gfit, gdat[i,, drop=FALSE], coefs[i,], changecoef=TRUE)
d945 1
a945 1
  Q <- quad.ppm(homfit, drop=TRUE)
d952 1
a952 1

d955 1
a955 1
  gdat <- getglmdata(homfit, drop=TRUE)
d959 4
d999 1
d1001 1
a1001 4
    lambda <- numeric(nU)
    for(j in 1:nU)
      lambda[j] <- GLMpredict(gfit, gdat[j,,drop=FALSE], coefs[j,],
                              changecoef=TRUE)
d1014 1
a1014 1
    gcv[k] <- sum(log(lambda[Z])) - sum(lambda * wQ) - dof[k]
@


1.64
log
@accelerated bw.locppm and homtest
@
text
@d6 1
a6 1
#  $Revision: 1.63 $ $Date: 2013/04/19 08:33:56 $
d18 3
a20 2
  vcalc     <- match.arg(vcalc,
                         c("none", "full", "hessian", "hom"))
@


1.63
log
@locppm has new undocumented option vcalc='hom'
@
text
@d6 1
a6 1
#  $Revision: 1.62 $ $Date: 2013/04/19 07:26:31 $
a16 1
  vcalc <- match.arg(vcalc, c("none", "full", "hessian", "hom"))
d18 2
d140 2
a141 1
                         fastRC = TRUE
d182 2
a183 20
    if(verbose) cat("Computing internal variance data ...")
    ispois <- is.poisson(model)
    internals <- vcov(model, what="internals", saveterms=TRUE)
    needed <- c( c("lambda", "mom", "Z", "ok"),
                 if(ispois) NULL else c("lamdif", "momdif"))
    hit <- needed %in% names(internals)
    if(!all(hit))
      stop(paste(ngettext(sum(!hit), "component", "components"),
                 commasep(sQuote(needed[!hit])),
                 "missing from internals"))
    # add more info
    wQ <- w.quad(quad.ppm(model))
    nX <- npoints(data.ppm(model))
    W <- as.owin(model)
    areaW <- if(model$correction == "border")
             eroded.areas(W, model$rbord) else area.owin(W)
    internals <- append(internals,
                        list(wQ=wQ, areaW=areaW, nX=nX,
                             ispois=ispois, hom.coef=coef.hom))
    if(verbose) cat("Done.\n")
d396 25
d854 1
d856 2
a857 1
  locations <- match.arg(locations)
d872 2
a873 2
             if(vcalc == "hessian") "using local variance" else
                                    "using Poincare variance"
d970 3
d981 1
a981 1
                            verbose=FALSE)
d985 1
a985 1
                            verbose=FALSE)
@


1.62
log
@accelerated
@
text
@d6 1
a6 1
#  $Revision: 1.61 $ $Date: 2013/04/19 07:16:02 $
d17 1
a17 1
  vcalc <- match.arg(vcalc)
d19 5
a23 3
  if(locations == "split" && vcalc == "none")
    locations <- "fine"
  parenv <- sys.parent()
d27 1
d58 2
d76 7
@


1.61
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.60 $ $Date: 2013/04/19 07:14:36 $
d150 19
a168 3
  # ... precompute internal data for Rubak-Coeurjolly estimates
  if(fastRC) {
    if(verbose) cat("Computing internal data ...\n")
d187 1
a187 16
  }
  # initialise space for results
  coefs <- tp <- vp <- vg <- vh <- v0 <- NULL
  if(do.localfit) {
    # local fit will be performed; coefficients will be saved
    coefs <- matrix(NA_real_, nrow=nV, ncol=ncoef)
    colnames(coefs) <- nama
    if(opt$tp) tp <- coefs
  }
  if(any(unlist(opt[c("vp", "vg", "vh", "v0")]))) {
    template <-  matrix(NA_real_, nrow=nV, ncol=ncoef2)
    colnames(template) <- as.vector(outer(nama, nama, paste, sep="."))
    if(opt$vp) vp <- template 
    if(opt$vg) vg <- template
    if(opt$vh) vh <- template
    if(opt$v0) v0 <- template
@


1.60
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.59 $ $Date: 2013/04/19 07:04:50 $
d24 1
d28 1
@


1.59
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.58 $ $Date: 2013/04/19 06:58:04 $
d150 1
@


1.58
log
@added fast computation of local Rubak-Coeurjolly estimate
@
text
@d6 1
a6 1
#  $Revision: 1.57 $ $Date: 2013/04/15 09:00:12 $
a150 6
    W <- as.owin(model)
    correction <- model$correction
    rbord      <- model$rbord
    areaW <- if(correction == "border") eroded.areas(W, rbord) else area.owin(W)
    wQ <- w.quad(quad.ppm(model))
    nX <- npoints(data.ppm(model))
d152 2
a153 2
    needed <-c("lambda", "mom", "Z", "ok")
    if(!ispois) needed <- c(needed, c("lamdif", "momdif"))
d159 9
@


1.57
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.56 $ $Date: 2013/04/12 07:05:30 $
d124 2
a125 1
                         matrices = FALSE
d148 18
a230 1
#    localwt <- localwt / mean(localwt)
d250 9
a258 4
          vgj <- try(vcov(model,
                          matwt=localwt, new.coef=coefj,
                          A1dummy=TRUE, matrix.action="silent"),
                     silent=TRUE)
d267 7
a273 3
      vhj <- try(vcov(model, matwt=localwt, A1dummy=TRUE,
                      matrix.action="silent"),
                 silent=TRUE)
d292 8
a299 3
        v0j <- try(vcov(model, matwt=localwt, new.coef=co,
                        A1dummy=TRUE, matrix.action="silent"),
                   silent=TRUE)
d327 68
a394 1
                         
d973 1
a973 1
  result <- bw.optim(gcv, sigma, iopt=which.max(gcv), xlab="sigma", dof=dof)
a976 1
  
@


1.56
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.55 $ $Date: 2013/04/12 06:57:34 $
d212 1
a212 1
    localwt <- localwt / mean(localwt)
d234 1
a234 1
                          A1dummy=TRUE, matrix.action="fatal"),
d236 1
a236 1
          if(!inherits(vgj, "try-error") && length(as.vector(vgj)) == ncoef2)
d244 4
a247 2
      vhj <- try(vcov(model, matwt=localwt, A1dummy=TRUE), silent=TRUE)
      if(!inherits(vhj, "try-error") && length(as.vector(vhj)) == ncoef2)
d266 1
a266 1
                        A1dummy=TRUE, matrix.action="fatal"),
d268 1
a268 1
        if(!inherits(v0j, "try-error") && length(as.vector(v0j)) == ncoef2)
d790 5
a794 1
bw.locppm <- function(..., srange=NULL, ns=16, verbose=TRUE) {
d797 1
d823 12
a834 7
  # determine range of smoothing parameter
  if(is.null(srange)) {
    smin <- bw.frac(X, f=1/20)
    smax <- bw.frac(X, f=2/3)
    srange <- c(smin, smax)
  } else stopifnot(is.numeric(srange) && length(srange)==2 && diff(srange) > 0)
  sigma <- seq(srange[1], srange[2], length=ns)
d837 1
d839 1
a839 1
  opt.var <- c(co = FALSE, tp = FALSE, vp = FALSE, vg = FALSE, vh = TRUE)
d854 1
a854 1
    # compute fitted intensity at each quadrature point
d861 2
a862 1
    vhX <- as.matrix(lpe.var$vh)
d866 2
a867 2
      vhXi <- matrix(vhX[i, ], ncoef, ncoef)
      leve[i] <- mmXi %*% vhXi %*% t(mmXi)
@


1.55
log
@trying to flameproof variance calculations
@
text
@d6 1
a6 1
#  $Revision: 1.54 $ $Date: 2013/04/11 06:42:57 $
d236 1
a236 1
          if(!inherits(vgj, "try-error") && length(as.vector(vgj) == ncoef2)
a789 1
  
d860 2
a861 1
  bw.optim(gcv, sigma, iopt=which.max(gcv), xlab="sigma", dof=dof)
@


1.54
log
@added bandwidth selection
@
text
@d6 1
a6 1
#  $Revision: 1.53 $ $Date: 2012/12/14 02:48:24 $
d142 1
d156 1
a156 1
    template <-  matrix(NA_real_, nrow=nV, ncol=ncoef^2)
d185 1
a185 1
      m0 <- try(eval(m0, enclos=env.model, envir=env.here))
d217 2
a218 2
      fitj <- try(eval(fitj, enclos=env.model, envir=env.here))
      if(!inherits(fitj, "try-error")) {
d226 13
a238 6
        if(opt$vp) # Poisson or Poincare variance of local fit
          vp[j,] <- as.vector(vcov(fitj, dispersion=1))
        if(opt$vg) # Rubak-Coeurjolly type estimate of local fit
          vg[j,] <- as.vector(vcov(model,
                                   matwt=localwt, new.coef=coefj,
                                   A1dummy=TRUE))
d243 5
a247 2
    if(opt$vh)
      vh[j,] <- as.vector(vcov(model, matwt=localwt, A1dummy=TRUE))
d255 1
a255 1
      fit0j <- try(eval(fit0j, enclos=env.model, envir=env.here))
d262 6
a267 3
        # compute null variance of score 
        v0[j,] <- as.vector(vcov(model, matwt=localwt, new.coef=co,
                                 A1dummy=TRUE))
d859 1
a859 1
    gcv[k] <- sum(log(lambda[Z])) - sum(lambda * wQ) + dof[k]
d861 1
a861 1
  bw.optim(gcv, sigma, xlab="sigma", dof=dof)
@


1.53
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.52 $ $Date: 2012/12/14 02:44:19 $
d774 77
@


1.52
log
@inserted default for ngrid
improved print method
@
text
@d6 1
a6 1
#  $Revision: 1.51 $ $Date: 2012/12/13 02:49:34 $
d40 1
a40 1
  need.grid <- locations %in% c("coarse", "split")
d331 1
@


1.51
log
@bug fixes etc
@
text
@d6 1
a6 1
#  $Revision: 1.50 $ $Date: 2012/12/13 02:33:33 $
d39 5
d105 3
a107 2
                   list(homfit=homfit, ispois=ispois,
                        sigma=sigma, vcalc=vcalc, locations=locations))
d309 1
d321 10
@


1.50
log
@tweaked interface
@
text
@d6 1
a6 1
#  $Revision: 1.49 $ $Date: 2012/12/12 05:12:23 $
d732 1
a732 1
  obs <- doit(X, ..., vcalc=vcalc)
d741 1
a741 1
    sim[i] <- doit(XsimI, ..., vcalc=vcalc)
@


1.49
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.48 $ $Date: 2012/12/12 04:46:00 $
d10 2
a11 1
                   vcalc=c("grid", "none", "hessian", "full"),
d18 3
d22 2
d30 1
a30 1
  P <- union.quad(quad.ppm(homfit, drop=TRUE))
d32 1
d39 10
a48 1
  # Calculation on fine grid
d51 3
a53 8
           # estimate coefficients only, on quadrature points
           opt <- list(co = TRUE,
                       tp = FALSE,
                       vp = FALSE,
                       vg = FALSE,
                       vh = FALSE)
           lpe <- locppmEngine(homfit, sigma, P, opt=opt,
                               scopename="quadrature points", verbose=verbose)
d57 2
a58 9
           # on quadrature points
           opt <- list(co = TRUE,
                       tp = TRUE,
                       vp = TRUE,
                       vg = FALSE,
                       vh = FALSE)
           lpe <- locppmEngine(homfit, sigma, P, opt=opt,
                               scopename="quadrature points",
                               verbose=verbose)
d61 11
a71 7
           # full variance estimation, on quadrature points
           opt <- list(co = TRUE,
                       tp = TRUE,
                       vp = TRUE,
                       vg = !ispois,
                       vh = TRUE)
           lpe <- locppmEngine(homfit, sigma, P, opt=opt,
d74 15
a88 19
         grid = {
           # estimate coefficients on quadrature points;
           # variance estimation on coarse grid
           opt.fine <- list(co = TRUE,
                            tp = TRUE,
                            vp = TRUE,
                            vg = FALSE,
                            vh = FALSE)
           if(verbose) cat("Fitting coefficients..\n")
           lpe.fine <- locppmEngine(homfit, sigma, P, opt=opt.fine,
                                    scopename="quadrature points",
                                    verbose=verbose)
           coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=grideps)
           P.coarse <- P[coarse.to.fine]
           opt.coarse <- list(co = FALSE,
                              tp = FALSE,
                              vp = FALSE,
                              vg = !ispois,
                              vh = TRUE)
d90 5
a94 5
           lpe.coarse <- locppmEngine(homfit, sigma, P.coarse, opt=opt.coarse,
                                      scopename="grid points",
                                      scopeindex=coarse.to.fine,
                                      verbose=verbose)
           lpe <- resolve.defaults(lpe.fine, lpe.coarse,
d101 1
a101 1
                        sigma=sigma, vcalc=vcalc))
d124 1
d522 1
a522 1
    if(is.null(ngrid) && is.null(grideps) && object$vcalc == "grid") {
d597 1
a597 1
                 commasep(sQuote(c("grid", "hessian", "full")), "or")))
d685 3
a687 2
                    method=c("full", "hessian", "residuals"),
                    vcalc = if(method=="hessian") "hessian" else "grid",
d693 2
d699 1
a699 1
    discard <- clnames %in% c("nsim", "method", "vcalc", "verbose", "Xname")
d707 8
a714 13
         full = {
           methodname <- "using local variance"
           doit <- function(Y, ..., vcalc) { 
             fit <- locppm(Y, ..., vcalc=vcalc, verbose=FALSE)
             h <- homteststat(fit, verbose=FALSE)
             return(h)
           }
         },
         hessian = {
           methodname <- "using Poincare variance"
           doit <- function(Y, ..., vcalc) { 
             fit <- locppm(Y, ..., vcalc=vcalc, verbose=FALSE)
             h <- homteststat(fit, hessian=TRUE, verbose=FALSE)
d720 1
a720 1
           doit <- function(Y, ..., vcalc) {
d730 1
a730 1
                   
@


1.48
log
@coef now returns an ssf
@
text
@d6 1
a6 1
#  $Revision: 1.47 $ $Date: 2012/12/12 04:42:57 $
a332 1
  P     <- X$P
d335 2
a336 2
  A <- P %mark% Y
  A <- A[X$ok]
d338 1
a338 1
            NULL else 1.4 * max(nndist(P))
@


1.47
log
@bug fix in confint
@
text
@d6 1
a6 1
#  $Revision: 1.46 $ $Date: 2012/12/12 03:21:28 $
d351 1
a351 1
                   local       = as.matrix(object$coefs),
@


1.46
log
@bug fix in print method
@
text
@d6 1
a6 1
#  $Revision: 1.45 $ $Date: 2012/12/12 03:15:02 $
d46 1
d87 3
a89 1
                                      scopename="grid points", verbose=verbose)
d107 1
d256 8
d379 1
a379 1
    v <- object$vp$val
d383 1
a383 1
    v <- object$vg$val
d385 1
a385 1
      v <- object$vp$val
d392 2
d402 4
a405 2
  coarse.to.fine <- object$coarse.to.fine
  if(!is.null(coarse.to.fine))
d407 1
@


1.45
log
@bug fix in sqrtmat for 1 x 1 matrix
@
text
@d6 1
a6 1
#  $Revision: 1.44 $ $Date: 2012/12/12 01:52:31 $
d283 3
a285 1
  present <- !unlist(lapply(x[c("vp","vg","vh","tp")], is.null))
@


1.44
log
@tweaks to satisfy package checker
@
text
@d6 1
a6 1
#  $Revision: 1.43 $ $Date: 2012/12/12 01:49:33 $
d159 2
d433 4
a436 1
  Y <- s$u %*% diag(sqrt(s$d)) %*% t(s$v)
d442 4
a445 1
  Y <- s$u %*% diag(1/sqrt(s$d)) %*% t(s$v)
d588 1
a588 1
  suf <- model.matrix(homfit)[ok,]
d672 4
a675 2
  discard <- names(cl) %in% c("nsim", "method", "vcalc", "verbose", "Xname")
  cl <- cl[!discard]
@


1.43
log
@removed timed class to util.R
@
text
@d6 1
a6 1
#  $Revision: 1.42 $ $Date: 2012/12/12 01:48:06 $
d384 1
@


1.42
log
@removed ssf code to ssf.R
@
text
@d6 1
a6 1
#  $Revision: 1.41 $ $Date: 2012/12/10 08:54:20 $
a8 2
#require(spatstat)

a723 34
gridproxy <- function(P, ..., dimyx=NULL, eps=NULL, xy=NULL) {
  stopifnot(is.ppp(P))
  W <- as.owin(P)
  if(is.null(dimyx) && is.null(eps) && is.null(xy))
    dimyx <- 10
  M <- as.mask(W, dimyx=dimyx, eps=eps, xy=xy) 
  xy <- raster.xy(M, drop=TRUE)
  G <- as.ppp(xy, W=W)
  id <- nncross(G,P, what="which")
  return(id)
}

timed <- function(object, ..., starttime=NULL, timetaken=NULL) {
  if(is.null(starttime) && is.null(timetaken)) {
    warning("No time information provided!")
  } else {
    if(is.null(timetaken))
      timetaken <- proc.time() - starttime
    class(object) <- c("timed", class(object))
    attr(object, "timetaken") <- timetaken
  }
  return(object)
}

print.timed <- function(x, ...) {
  if(is.numeric(x)) print(as.numeric(x), ...) else NextMethod("print")
  cat("Time taken:\n")
  print(attr(x, "timetaken"))
  return(invisible(NULL))
}

  
    
    
@


1.41
log
@forming into a package
@
text
@d6 1
a6 1
#  $Revision: 1.40 $ $Date: 2012/12/09 10:17:07 $
a725 156
# spatially sampled functions

ssf <- function(loc, val) {
  stopifnot(is.ppp(loc))
  if(is.function(val))
    val <- val(loc$x, loc$y)
  if(is.data.frame(val))
    val <- as.matrix(val)
  if(!is.matrix(val))
    val <- matrix(val, ncol=1, dimnames=list(NULL, "value"))
  if(nrow(val) != npoints(loc))
    stop("Incompatible lengths")
  ok <- complete.cases(val)
  result <- list(loc=loc, val=val, ok = ok)
  class(result) <- c("ssf", class(result))
  return(result)
}

print.ssf <- function(x, ..., brief=FALSE) {
  if(brief) {
    cat(paste("Spatial function sampled at", npoints(x$loc), "locations\n"))
  } else {
    cat("Spatially sampled function\n")
    cat("Locations:\n\t")
    print(x$loc)
  }
  if(!is.matrix(x$val)) {
    d <- 1
    warning("Internal format error: val is not a matrix")
  } else d <- ncol(x$val) 
  if(!brief) {
    type <- if(d == 1) "Scalar" else paste(d, "-vector", sep="")
    cat(paste(type, "valued function\n"))
  }
  if(d > 1 && !is.null(nama <- colnames(x$val)))
    cat(paste("Component names:", commasep(sQuote(nama)), "\n"))
  return(invisible(NULL))
}

image.ssf <- function(x, ...) {
  do.call("plot", resolve.defaults(list(x, how="smoothed"), list(...)))
}

plot.ssf <- function(x, ..., how=c("smoothed", "exact"),
                     style = c("image", "contour", "imagecontour"),
                     sigma=NULL) {
  xname <- short.deparse(substitute(x))
  how <- match.arg(how)
  style <- match.arg(style)
  if(is.null(sigma)) sigma <- 1.4 * max(nndist(x$loc))
  y <- switch(how,
         exact = x$loc %mark% x$val,
         smoothed = smooth.ssf(x, sigma=sigma))
  switch(style,
         image = {
           out <- do.call("plot",
                          resolve.defaults(list(y), list(...),
                                           list(main=xname)))
         },
         contour = {
           do.call("plot",
                   resolve.defaults(list(as.owin(x)),
                                    list(...), list(main=xname)))
           do.call("contour",
                   resolve.defaults(list(y, add=TRUE), list(...)))
           out <- NULL
         },
         imagecontour = {
           out <- do.call("plot",
                          resolve.defaults(list(y), list(...),
                                           list(main=xname)))
           do.call("contour",
                   resolve.defaults(list(y, add=TRUE), list(...)))
         })
  return(invisible(out))
}

contour.ssf <- function(x, ..., main, sigma=NULL) {
  if(missing(main))
    main <- short.deparse(substitute(x))
  y <- smooth.ssf(x, sigma=sigma)
  contour(y, ..., main=main)
}

smooth.ssf <- function(X, ...) {
  stopifnot(inherits(X, "ssf"))
  loc <- X$loc
  val <- X$val
  ok  <- X$ok
  Y   <- (loc %mark% val)[ok]
  argh <- list(...)
  isnul <- as.logical(unlist(lapply(argh, is.null)))
  nonnularg <- argh[!isnul]
  sigma0 <- if(any(c("sigma", "varcov") %in% names(nonnularg)))
            NULL else 1.4 * max(nndist(loc))
  out <- do.call("smooth.ppp",
                 resolve.defaults(list(X = Y),
                                  list(...),
                                  list(sigma=sigma0)))
  return(out)
}

"[.ssf" <- function(x, i, j, ...) {
  loc <- x$loc
  val <- as.matrix(x$val)
  ok  <- x$ok
  #
  if(!missing(j)) 
    val <- val[, j, drop=FALSE]
  if(!missing(i)) {
    # use [.ppp to identify which points are retained
    locn <- loc %mark% seq_len(npoints(loc))
    loci <- locn[i]
    loc  <- unmark(loci)
    id   <- marks(loci)
    # extract
    val  <- val[id, ]
    ok   <- ok[id]
  }
  out <- list(loc=loc,
              val=val,
              ok =ok)
  class(out) <- "ssf"
  return(out)    
}

as.ppp.ssf <- function(X, ...) { X$loc }

as.owin.ssf <- function(X, ...) { as.owin(as.ppp(X)) }

as.matrix.ssf <-  function(x) {
  val <- x$val
  if(!is.matrix(val)) val <- matrix(val, ncol=1)
  return(val)
}

with.ssf <- function(data, ...) {
  loc <- data$loc
  val <- data$val
  newval <- with(as.data.frame(val), ...)
  if(length(newval) == npoints(loc) ||
     (is.matrix(newval) && nrow(newval) == npoints(loc)))
    return(ssf(loc, newval))
  return(newval)
}

apply.ssf <- function(X, ...) {
  loc <- X$loc
  val <- as.matrix(X)
  newval <- apply(val, ...)
  if(length(newval) == npoints(loc) ||
     (is.matrix(newval) && nrow(newval) == npoints(loc)))
    return(ssf(loc, newval))
  return(newval)
}

@


1.40
log
@added option to homtest to use squared magnitude of score residuals
@
text
@d6 1
a6 1
#  $Revision: 1.39 $ $Date: 2012/12/08 02:59:53 $
d9 1
a9 1
require(spatstat)
@


1.39
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.38 $ $Date: 2012/12/07 10:56:23 $
d655 2
a656 2
                    hessian=FALSE,
                    vcalc = if(hessian) "hessian" else "grid",
d659 1
d661 5
a665 1
  discard <- names(cl) %in% c("nsim", "hessian", "vcalc", "verbose", "Xname")
d669 1
d671 30
a700 8
  if(is.null(Xname))
    Xname <- short.deparse(substitute(X))
  starttime <- proc.time()
  doit <- function(Y, ..., hessian, vcalc) { 
    fit <- locppm(Y, ..., vcalc=vcalc, verbose=FALSE)
    h <- homteststat(fit, hessian=hessian, verbose=FALSE)
    return(h)
  }
d702 1
a702 1
  obs <- doit(X, ..., hessian=hessian, vcalc=vcalc)
d711 1
a711 1
    sim[i] <- doit(XsimI, ..., hessian=hessian, vcalc=vcalc)
a714 3
  method <- c("Monte Carlo test of homogeneity for", cl)
  if(hessian && !is.poisson(homfit))
    method <- c(method, "using Poincare variance")
d718 1
a718 1
                 method = method,
@


1.38
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.37 $ $Date: 2012/12/07 10:53:54 $
d679 1
a679 1
  if(verbose) cat("Simulating...")  
@


1.37
log
@tweaking output of homtest
@
text
@d6 1
a6 1
#  $Revision: 1.36 $ $Date: 2012/12/07 10:16:21 $
d662 1
a662 1
  cl[[1]] <- as.name("ppm")
d687 1
a687 2
  method <- c("Monte Carlo test of homogeneity",
              paste("for:", cl))
@


1.36
log
@implemented Monte Carlo test of homogeneity
@
text
@d6 1
a6 1
#  $Revision: 1.35 $ $Date: 2012/12/07 09:36:43 $
d659 6
d675 1
d687 4
d694 3
a696 2
                 method = "Monte Carlo test of homogeneity",
                 data.name = Xname)
@


1.35
log
@more tweaks
@
text
@d6 1
a6 1
#  $Revision: 1.34 $ $Date: 2012/12/07 09:30:53 $
d653 37
a689 1

@


1.34
log
@locppm now has option vcalc="hessian"
homtestmap has argument hessian=FALSE
@
text
@d6 1
a6 1
#  $Revision: 1.33 $ $Date: 2012/12/07 08:37:39 $
d53 3
a55 3
           lpe.fine <- locppmEngine(homfit, sigma, P, opt=opt,
                                    scopename="quadrature points",
                                    verbose=verbose)
d563 1
a563 1
    va <- if(!hessian) object$vh else object$va
@


1.33
log
@tweaks
@
text
@d6 1
a6 1
#  $Revision: 1.32 $ $Date: 2012/12/07 05:05:19 $
d12 1
a12 1
                   vcalc=c("grid", "none", "full"),
d46 11
d542 1
a542 1
                       theta0=NULL, sigma=NULL, verbose=TRUE) {
d563 2
a564 2
    vh <- object$vh$val
    if(is.null(vh))
d567 1
a567 1
                 sQuote("grid"), "or", sQuote("full")))
d570 1
d592 2
a593 2
    # use points where 'vh' was evaluated
    P <- object$vh$loc
d630 2
a631 2
      # null variance of local *estimates* is given by object$vh
      nullvcov <- matrix(vh[k,], nrow=ncoef, ncol=ncoef)
@


1.32
log
@homteststat now handles homtestmap objects
@
text
@d6 1
a6 1
#  $Revision: 1.31 $ $Date: 2012/12/03 06:13:55 $
d702 3
d706 1
a706 1
                   resolve.defaults(list(y), list(...), list(main=xname)))
d823 1
a823 1
  NextMethod("print")
@


1.31
log
@more tweaking
@
text
@d6 1
a6 1
#  $Revision: 1.30 $ $Date: 2012/11/29 05:30:06 $
d521 2
a523 1
  Tv <- homtestmap(object, ..., verbose=verbose)
d525 2
a526 1
  S <- timed(S, starttime=starttime)
d532 2
d628 1
d730 1
a730 1
  isnul <- unlist(lapply(argh, is.null))
@


1.30
log
@d'oh
@
text
@d6 1
a6 1
#  $Revision: 1.29 $ $Date: 2012/11/29 05:25:15 $
d680 3
a682 1
plot.ssf <- function(x, ..., how=c("smoothed", "exact"), sigma=NULL) {
d685 1
d690 19
a708 1
  do.call("plot", resolve.defaults(list(y), list(...), list(main=xname)))
d711 1
a711 1
contour.ssf <- function(x, ..., main) {
d714 1
a714 1
  y <- smooth.ssf(x)
d724 4
a727 1
  sigma0 <- if(any(c("sigma", "varcov") %in% names(list(...))))
@


1.29
log
@added contour method
@
text
@d6 1
a6 1
#  $Revision: 1.28 $ $Date: 2012/11/23 04:54:46 $
d692 1
a692 1
    xname <- short.deparse(substitute(x))
d694 1
a694 1
  contour(y, ..., main=xname)
@


1.28
log
@added class of 'timed' objects
@
text
@d6 1
a6 1
#  $Revision: 1.27 $ $Date: 2012/11/23 04:28:09 $
d287 18
d735 4
@


1.27
log
@now uses A1dummy=TRUE
@
text
@d6 1
a6 1
#  $Revision: 1.26 $ $Date: 2012/11/15 07:04:22 $
d16 2
d84 2
a85 1
                   list(homfit=homfit, ispois=ispois, sigma=sigma, vcalc=vcalc))
d87 1
d419 1
d447 3
a449 1
    return(tp[,parm])
d495 1
d503 1
d506 1
d512 1
d606 1
d755 23
@


1.26
log
@removed collision on name 'eps'
@
text
@d6 1
a6 1
#  $Revision: 1.25 $ $Date: 2012/11/15 04:05:10 $
d36 2
a37 1
           opt <- list(tp = FALSE,
d46 2
a47 1
           opt <- list(tp = TRUE,
d57 3
a59 2
           opt.fine <- list(tp = TRUE,
                            vp = FALSE,
d68 3
a70 2
           opt.coarse <- list(tp = FALSE,
                              vp = TRUE,
d91 3
a93 2
                         opt = list(tp=TRUE,
                                    vp=TRUE,
d95 2
a96 3
                                    vh=FALSE,
                                    v0=!is.null(parm)),
                         parm = NULL,
d102 4
a105 10
  if(!is.null(parm)) {
    # parm must be the name or index of a parameter to be set to 0
    stopifnot(length(parm) == 1)
    if(is.character(parm)) stopifnot(parm %in% names(coef(model))) else 
    if(is.numeric(parm)) stopifnot(parm %in% 1:length(coef(model))) else 
    stop("parm must be the name or index of a parameter in the model")
  }
  # ensure 'opt' contains all required entries
  opt <- resolve.defaults(opt, list(tp=TRUE,
                                    vp=TRUE,
d108 7
a114 6
                                    v0=!is.null(parm)))
  
  coef0 <- coef(model)
  nama <- names(coef0)
  ncoef <- length(coef0)
  
a117 1

d119 5
a123 4
  coefs <- matrix(, nrow=nV, ncol=ncoef)
  colnames(coefs) <- nama
  tp <- vp <- vg <- vh <- v0 <- NULL
  if(any(unlist(opt))) {
d125 3
a127 1
    template <-  matrix(, nrow=nV, ncol=ncoef^2)
a134 1
  # manipulate environments so that the update will work
d140 28
a167 5
  fmla     <- get("fmla",     envir=env.model)
  gcontrol <- get("gcontrol", envir=env.model)
  glmdata  <- get("glmdata", envir=env.model)
  assign("coef0", coef0, envir=env.update)

d182 42
a223 25
    assign("localwt", localwt, envir=env.update)
    fitj <- update(m, weights = .mpl.W * localwt, start=coef0, evaluate=FALSE)
    fitj <- try(eval(fitj, enclos=env.model, envir=env.here))
    if(!inherits(fitj, "try-error")) {
      # fitted coefficients
      coefs[j, ] <- coefj <- coef(fitj)
      # t-statistic for each parameter (using Hessian)
      if(opt$tp)
        tp[j,] <- coef(summary(fitj))[,3]
      # variance of local parameter estimates under local model
      # (for confidence intervals)
      if(opt$vp) # Poisson or Poincare variance of local fit
        vp[j,] <- as.vector(vcov(fitj, dispersion=1))
      if(opt$vg) # Rubak-Coeurjolly type estimate of local fit
        vg[j,] <- as.vector(vcov(model, matwt=localwt, new.coef=coefj))
      # variance of local parameter estimates under homogeneous model
      # (for tests of homogeneity)
      if(opt$vh)
        vh[j,] <- as.vector(vcov(model, matwt=localwt))
      # variance of local parameter estimates under local NULL model
      # (for local test of H_0: parm = 0)
      if(opt$v0) {
        co <- coefj
        co[parm] <- 0
        v0[j,] <- as.vector(vcov(model, matwt=localwt, new.coef=co))
d410 1
a410 1
ttestmap <- function(object, parm, ..., 
d417 21
a437 8
  coef0 <- coef(homfit)
  nama <- names(coef0)
  # validate 'parm'
  if(!is.character(parm))
    parm <- nama[parm]
  iparm <- match(parm, nama)
  if(any(is.na(iparm)))
    stop("Argument parm does not specify valid choice of parameter")
d477 8
a484 15
    nparm <- length(iparm)
    for(k in seq_len(nparm)) {
      parmk <- parm[k]
      iparmk <- iparm[k]
      if(verbose && nparm > 1)
        cat(paste("Calculating t statistic for parameter", sQuote(parmk), "\n"))
      z <- locppmEngine(homfit, sigma, Puse,
                        parm=parmk,
                        opt=list(tp=FALSE,vp=FALSE,vg=FALSE,vh=FALSE,v0=TRUE),
                        scopename=scopename, verbose=verbose)
      v0vals <- z$v0$val
      iiparmk <- (iparmk - 1) * length(coef0) + iparmk
      valk <- coefvals[,iparmk]/v0vals[,iiparmk]
      outvals <- cbind(outvals, valk)
    }
@


1.25
log
@converted homtestmap to new setup
@
text
@d6 1
a6 1
#  $Revision: 1.24 $ $Date: 2012/11/15 02:40:54 $
d13 1
a13 1
                   ngrid=NULL, eps=NULL,
d47 1
a47 1
                       vg = TRUE,
d63 1
a63 1
           coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=eps)
d73 2
a74 1
                                   list(coarse.to.fine=coarse.to.fine))
d373 1
a373 1
                     ngrid=NULL, eps=NULL,
d403 1
a403 1
    if(is.null(ngrid) && is.null(eps) && object$vcalc == "grid") {
d408 1
a408 1
      coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=eps)
d544 1
a544 1
    stat[j, ] <- locscore %*% vhalf
d587 4
a590 1
  d <- ncol(x$val)
d607 1
@


1.24
log
@bug fix
@
text
@d6 1
a6 1
#  $Revision: 1.23 $ $Date: 2012/11/14 11:11:03 $
d59 1
d69 1
d310 8
a318 1
  coefs <- object$coefs$val
d320 1
a320 1
    ci[i,] <- rep(coefs[i,], rep(2, nparm)) +
d323 1
a323 2
  U <- object$coefs$loc
  ssf(U, ci)
d371 2
a372 1
                     grid = TRUE, ngrid=NULL, eps=NULL,
d385 1
a385 1
  if(hessian && !is.null(tp <- object$tp)) {
d394 18
d414 1
a414 1
    z <- locppmEngine(homfit, object$sigma, P,
d416 1
a416 1
                      scopename="quadrature points", verbose=verbose)
d418 1
a418 1
    return(tp[,parm])
d420 17
a436 16
    if(length(iparm) != 1)
      stop("Not implemented for more than one parameter at a time")
    if(grid) {
      if(is.null(ngrid) && is.null(eps) && object$vcalc == "grid") {
        # use existing 'grid'
        coarse.to.fine <- object$coarse.to.fine
      } else {
        # generate new 'grid'
        coarse.to.fine <- gridproxy(P, dimyx=ngrid, eps=eps)
      }
      Puse <- P[coarse.to.fine]
      scopename <- "grid points"
    } else {
      Puse <- P
      scopename <- "quadrature points"
      coarse.to.fine <- seq_len(npoints(P))
d438 2
a439 8
    z <- locppmEngine(homfit, sigma, Puse,
                      parm=parm,
                      opt=list(tp=FALSE, vp=FALSE, vg=FALSE, vh=FALSE, v0=TRUE),
                      scopename=scopename, verbose=verbose)
    v0 <- z$v0
    ncoef <- length(coef0)
    iiparm <- iparm * (ncoef+1) - ncoef
    return(ssf(Puse, coefs$val[coarse.to.fine,iparm]/v0$val[,iiparm]))
d441 1
d463 1
a463 1
           lam <- fitted(homfit, new.coef=theta0)
d467 3
a469 2
           lam <- fitted(homfit)
           vhom <- vcov(homfit) 
d480 2
a481 2
  suf <- model.matrix(homfit)
  Q    <- quad.ppm(homfit)
d489 1
a489 3
  jok <- which(ok)
  nok <- length(jok)
  loctheta <- as.matrix(object$coefs)
d492 16
d510 1
a510 1
  stat <- matrix(NA_real_, nrow=nU, ncol=ncoef)
d514 2
a515 4
    cat(paste("Processing",
              if(nok == nU) paste("all", nok) else paste(nok, "selected"),
              "quadrature points...\n"))
  for(k in 1:nok) {
d517 3
a519 4
      progressreport(k, nok)
    j <- jok[k]
    localwt <- dnorm(Ux - Ux[j], sd=sigma) * dnorm(Uy - Uy[j], sd=sigma)
    # local score at U[j] for homogeneous model
d523 1
a523 1
      # local Fisher information at U[j] for homogeneous model
d547 1
a547 1
  result <- ssf(U, stat)
d600 1
a600 1
plot.ssf <- function(x, ..., how=c("smoothed", "exact")) {
d605 1
a605 1
         smoothed = smooth.ssf(x))
@


1.23
log
@added more control
@
text
@d6 1
a6 1
#  $Revision: 1.22 $ $Date: 2012/11/14 10:49:10 $
d12 2
a13 1
                   vcalc=c("grid", "none", "full"), ngrid=10,
d23 2
a30 3
  
  X <- data.ppm(homfit)
  P <- union.quad(quad.ppm(homfit, drop=TRUE))
d62 2
a63 1
           P.coarse <- neargrid(homfit, dimyx=ngrid)
d70 2
a71 1
           lpe <- resolve.defaults(lpe.fine, lpe.coarse)
d74 2
a75 1
  result <- append(lpe, list(homfit=homfit, ispois=ispois, sigma=sigma))
d363 1
d366 11
a376 1
  if(hessian) {
d378 1
a378 2
    tp <- object$tp
    if(is.null(tp)) stop("Internal error: no tp data")
d381 1
a381 2
  homfit <- object$homfit
  coef0 <- coef(homfit)
d385 34
a418 9
  z <- locppmEngine(homfit, sigma, P,
                    parm=parm,
                    opt=list(vp=FALSE, vg=FALSE, vh=FALSE, v0=TRUE),
                    scopename="quadrature points", verbose=verbose)
  v0 <- z$v0
  iparm <- if(is.numeric(parm)) parm else match(parm, names(coef0))
  nparm <- length(coef0)
  iiparm <- iparm * (nparm+1) - nparm
  return(ssf(P, coefs$val[,parm]/v0[,iiparm]))
d450 3
a452 1
      stop("Object does not contain variance information: refit with slow=TRUE")
d646 6
a651 8
neargrid <- function(model, ...) {
  stopifnot(is.ppm(model))
  Q <- quad.ppm(model)
  W <- as.owin(Q)
  M <- do.call.matched("as.mask",
                       resolve.defaults(list(w=W),
                                        list(...),
                                        list(dimyx=10)))
a653 3
  if(is.expandable(model))
    return(G)
  P <- union.quad(Q)
d655 1
a655 2
  GG <- P[id]
  return(GG)
@


1.22
log
@implemented coarse grid algorithm
@
text
@d6 1
a6 1
#  $Revision: 1.21 $ $Date: 2012/11/14 07:57:39 $
d36 2
a37 1
           opt <- list(vp = FALSE,
d41 1
a41 1
                               "quadrature points", verbose=verbose)
d45 2
a46 1
           opt <- list(vp = TRUE,
d50 1
a50 1
                               "quadrature points", verbose=verbose)
d55 4
a58 3
           opt.fine <- list(vp = FALSE,
                       vg = FALSE,
                       vh = FALSE)
d60 2
a61 1
                                    "quadrature points", verbose=verbose)
d63 2
a64 1
           opt.coarse <- list(vp = TRUE,
d68 1
a68 1
                                      "grid points", verbose=verbose)
d81 2
a82 1
                         opt = list(vp=TRUE,
d100 2
a101 1
  opt <- resolve.defaults(opt, list(vp=TRUE,
d117 1
a117 2
  tp <- coefs
  vp <- vg <- vh <- v0 <- NULL
d119 1
d160 2
a161 1
      tp[j,] <- coef(summary(fitj))[,3]
@


1.21
log
@safety
@
text
@d6 1
a6 1
#  $Revision: 1.20 $ $Date: 2012/11/12 07:11:07 $
d11 3
a13 1
locppm <- function(..., sigma=NULL, f = 1/4, verbose=TRUE, slow = FALSE) {
d15 1
a21 8
  
  opt <- list(vp = TRUE,
              vg = slow && !ispois,
              vh = slow,
              v0 = FALSE)

  X <- data.ppm(homfit)
  
d29 37
a65 12
  P <- union.quad(quad.ppm(homfit))
  nP <- npoints(P)
  # which quadrature points were used in model?
  ok <- getglmsubset(homfit)
  Pok <- P[ok]
  scopename <- if(all(ok)) "quadrature points" else "selected quadrature points"
  # go
  lpe <- locppmEngine(homfit, sigma, Pok,
                      opt=opt, scopename=scopename, verbose=verbose)
  # attach to locations
  isnul <- unlist(lapply(lpe, is.null))
  lpe[!isnul] <- lapply(lpe[!isnul], ssf, loc=Pok)
d80 2
a81 1
                         parm = NULL
d98 1
a98 1

d174 11
a184 1
  return(list(coefs=coefs, tp=tp, vp=vp, vg=vg, vh=vh, v0=v0))
d599 17
@


1.20
log
@safety
@
text
@d6 1
a6 1
#  $Revision: 1.19 $ $Date: 2012/10/29 10:23:35 $
d11 1
a11 3
locppm <- function(...,
                   sigma=NULL, f = 1/4, verbose=TRUE,
                   do.z=NULL, quick=TRUE) {
d18 7
d26 1
d38 2
a39 6

  # create matrix for results
  coef0 <- coef(homfit)
  coefs <- matrix(NA_real_, nrow=nP, ncol=length(coef0))
  colnames(coefs) <- names(coef0)
  
d41 5
a45 14
  if(is.null(do.z)) do.z <- is.poisson(homfit)
  lpe <- locppmEngine(homfit, sigma, P[ok],
                      verbose=verbose,
                      do.z=do.z, quick=quick)

  # unpack
  coefs[ok,] <- lpe$coefs
  if(!is.null(lpe$z)) {
    z <- coefs
    z[ok,] <- lpe$z
  } else z <- NULL

  Cfun <- ssf(P, coefs)
  Zfun <- if(is.null(z)) NULL else ssf(P, z)
d47 1
a47 1
  result <- list(homfit=homfit, coefs=Cfun, z=Zfun, sigma=sigma, quick=quick)
d55 7
a61 3
                         Vname="selected quadrature points",
                         do.z = is.poisson(model),
                         quick = TRUE) {
d65 12
d78 3
a80 1
  ispois <- is.poisson(model)
d85 14
a98 6
  
  # initialise result
  coef0 <- coef(model)
  coefs <- matrix(NA_real_, nrow=nV, ncol=length(coef0))
  colnames(coefs) <- names(coef0)
  z <- if(do.z) coefs else NULL
d118 1
a118 1
    cat(paste("Processing", nV, Vname, "...\n"))
d129 1
d131 18
a148 9
      if(do.z) {
        if(ispois || quick) {
          # use summary.glm to compute standardised residuals
          z[j,] <- coef(summary(fitj, dispersion=1))[, 3]
        } else {
          # use vcov.ppm to compute standardised residuals
          vc <- vcov(model, matwt=localwt, new.coef=coefj)
          z[j, ] <- coefj / sqrt(diag(vc))
        }
d153 1
a153 1
  return(list(coefs=coefs, z=z))
d159 1
a159 1
                        what=c("coefs", "z"),
d181 1
a181 1
  cat("Coefficient estimates:\n")
d183 12
a194 6
  if(!is.null(x$z)) {
    if(x$quick) {
      cat("\nStandardised coefficients (using Poincare pseudovariance):\n")
    } else cat("\nStandardised coefficients:\n")
    print(x$z, brief=TRUE)
  } else cat("\n(Standardised coefficients not computed)\n")
d198 1
a198 1
smooth.locppm <- function(X, ..., what=c("coefs", "z")) {
d224 52
d305 5
a309 57
# standardise the local parameter estimates
# relative to a homogeneous model (either specified by theta0, or fitted)

zvalhom <- function(object, ...,
                       theta0=NULL, sigma=NULL, verbose=TRUE) {
  stopifnot(inherits(object, "locppm"))
  if(!is.poisson(object))
    stop("Only valid for Poisson models")
  homfit <- object$homfit
  if(is.null(sigma))
    sigma <- object$sigma
  #
  if(!is.null(theta0)) {
    lam <- fitted(homfit, new.coef=theta0)
  } else {
    theta0 <- coef(homfit)
    lam <- fitted(homfit)
  }
  #
  suf <- model.matrix(homfit)
  Q    <- quad.ppm(homfit)
  w    <- w.quad(Q)
  U    <- union.quad(Q)
  nU   <- npoints(U)
  Ux <- U$x
  Uy <- U$y
  ok <- getglmsubset(homfit)
  jok <- which(ok)
  nok <- length(jok)
  loctheta <- as.matrix(object$coefs)
  # create space
  resid <- matrix(NA_real_, nrow=nU, ncol=length(theta0))
  colnames(resid) <- names(theta0)
  #
  if(verbose) 
    cat(paste("Processing",
              if(nok == nU) paste("all", nok) else paste(nok, "selected"),
              "quadrature points...\n"))
  for(k in 1:nok) {
    if(verbose) 
      progressreport(k, nok)
    j <- jok[k]
    localwt <- dnorm(Ux - Ux[j], sd=sigma) * dnorm(Uy - Uy[j], sd=sigma)
    locsuf <- localwt * suf
    # local Fisher information
    locfish <- sumouter(locsuf, w * lam)
    # 
    locvcov <- try(solve(locfish))
    if(!inherits(locvcov, "try-error") && all(diag(locvcov) >= 0)) {
      sd <- sqrt(diag(locvcov))
      resid[j, ] <- (loctheta[j,] - theta0)/sd
    }
  }
  if(verbose) cat("\t Done.\n")
  # pack up
  result <- ssf(U, resid)
  return(result)
a310 1

d318 27
d348 8
a355 2
HomScoreTestStat <- function(object, ...,
                        theta0=NULL, sigma=NULL, verbose=TRUE) {
d357 1
a357 2
  if(!is.poisson(object))
    stop("Only valid for Poisson models")
a360 2
  if(!is.null(theta0) && !is.null(effect))
    stop("Only one of the arguments theta0 and effect should be given")
d369 1
a369 1
           vhom <- vcov(homfit)
d371 7
d390 2
d393 2
a394 1
  stat <- matrix(NA_real_, nrow=nU, ncol=length(theta0))
d406 23
a428 15
    # local score at U[j]
    resid <- Z - lam * w
    locscore <- matrix(localwt * resid, nrow=1) %*% suf
    # local Fisher information at U[j]
    locfish <- sumouter(localwt * suf, w * lam)
    # evaluate null variance of local score
    switch(nulltype,
           simple = {
             varlocscore <- locfish
           },
           homogeneous = {
             covterm <- sumouter(suf, w * lam * localwt)
             varlocscore <- locfish +
               (locfish - 2 * covterm) %*% vhom %*% locfish
           })
a429 1
    vhalf <- invsqrtmat(varlocscore)
d446 1
d483 4
d524 1
a524 1
    val <- val[, j]
d542 5
a546 1
as.matrix.ssf <-  function(x) { x$val }
d557 11
@


1.19
log
@moved bw.frac to spatstat
@
text
@d6 1
a6 1
#  $Revision: 1.18 $ $Date: 2012/10/29 01:00:25 $
d373 3
a375 1
  if(inherits(try(loc %mark% val), "try-error"))
d457 10
@


1.18
log
@added contour method
@
text
@d6 1
a6 1
#  $Revision: 1.17 $ $Date: 2012/10/26 07:53:47 $
a196 23
bw.frac <- function(W, f=1/4, plotit=TRUE) {
  W <- as.owin(W)
  stopifnot(is.numeric(f) && length(f) == 1)
  stopifnot(f > 0 && f < 1)
  g <- setcov(W)
  r <- as.im(function(x,y) { sqrt(x^2 + y^2) }, g)
  rvals <- as.vector(as.matrix(r))
  gvals <- as.vector(as.matrix(g))
  rgrid <- seq(0, max(rvals), length=1024)
  h <- whist(rvals, breaks=rgrid, weights=gvals/sum(gvals))
  ch <- cumsum(h)
  i <- min(which(ch >= f))
  ropt <- rgrid[i+1]
  if(plotit) {
    plot(rgrid[-1], ch,
         xlab="Interpoint distance", ylab="Cumulative probability",
         type="l", main="Bandwidth computation (bw.frac)")
    abline(v=ropt, lty=3)
    abline(h=f, lty=3)
  }
  return(ropt)
}

d408 3
a410 7
contour.ssf <- function(x, ..., add=FALSE) {
  xname <- short.deparse(substitute(x))
  if(!add) 
    do.call("plot",
            resolve.defaults(list(as.owin(x$loc)),
                             list(...),
                             list(main=xname)))
d412 1
a412 2
  do.call("contour",
          resolve.defaults(list(y, add=TRUE), list(...)))
@


1.17
log
@locppm can now calculate z using Poincare pseudovariance
@
text
@d6 1
a6 1
#  $Revision: 1.16 $ $Date: 2012/10/10 06:07:11 $
d423 1
d428 13
a440 1
  plot(y, ...)
@


1.16
log
@renamed functions
@
text
@d6 1
a6 1
#  $Revision: 1.15 $ $Date: 2012/10/10 04:48:26 $
d11 3
a13 1
locppm <- function(..., sigma=NULL, f = 1/4, verbose=TRUE, do.z=NULL) {
d42 1
a42 1
                      do.z=do.z)
d54 1
a54 1
  result <- list(homfit=homfit, coefs=Cfun, z=Zfun, sigma=sigma)
d63 2
a64 1
                         do.z = is.poisson(model)) {
d112 1
a112 1
        if(ispois) {
d155 3
a157 1
    cat("\nStandardised coefficients:\n")
@


1.15
log
@rebuilt
@
text
@d6 1
a6 1
#  $Revision: 1.14 $ $Date: 2012/10/10 02:55:33 $
d150 1
a150 1
  print(x$coef, brief=TRUE)
d179 1
a179 1
                   local       = object$coefs$val,
d219 1
a219 1
  coefs <- object$coefs
d236 4
a239 1
standresid <- function(object, ...,
d265 1
a265 1
  loctheta <- object$coefs
d301 6
a306 3
  
ScoreTestStat <- function(object, ...,
                          theta0=NULL, sigma=NULL, verbose=TRUE) {
d336 1
a336 1
  loctheta <- object$coefs
d463 2
@


1.14
log
@safety
@
text
@d6 1
a6 1
#  $Revision: 1.13 $ $Date: 2012/10/03 11:01:30 $
d26 2
a27 2
  U <- union.quad(quad.ppm(homfit))
  nU <- npoints(U)
d33 1
a33 1
  coefs <- matrix(NA_real_, nrow=nU, ncol=length(coef0))
d38 1
a38 1
  lpe <- locppmEngine(homfit, sigma, U[ok],
d49 2
a50 3
  # interpolate
  ok <- complete.cases(coefs)
  smoo <- smooth.ppp(U[ok] %mark% coefs[ok,], sigma=1.4 * max(nndist(U)))
d52 1
a52 2
  result <- list(homfit=homfit, coefs=coefs, smoo=smoo, z=z,
                 sigma=sigma)
d132 7
a138 37
  opt <- paste(how, what, sep="")
  switch(opt,
         smoothedcoefs={
           Z <- x$smoo
           if(!is.null(which)) {
             Z <- as.listof(Z[which])
             if(length(Z) == 1)
               Z <- Z[[1]]
           }
         },
         exactcoefs={
           U <- union.quad(quad.ppm(x$homfit))
           coefs <- x$coefs
           if(!is.null(which))
             coefs <- coefs[,which, drop=FALSE]
           ok <- complete.cases(coefs)
           Z <- U[ok] %mark% coefs[ok,]
         },
         exactz={
           U <- union.quad(quad.ppm(x$homfit))
           z <- x$z
           if(is.null(z)) stop("No standardised coefficients available")
           if(!is.null(which))
             z <- z[,which, drop=FALSE]
           ok <- complete.cases(z)
           Z <- U[ok] %mark% z[ok,]
         },
         smoothedz={
           U <- union.quad(quad.ppm(x$homfit))
           z <- x$z
           if(is.null(z)) stop("No standardised coefficients available")
           if(!is.null(which))
             z <- z[,which, drop=FALSE]
           ok <- complete.cases(z)
           Z <- U[ok] %mark% z[ok,]
           Z <- smooth.ppp(Z, sigma=1.4 * max(nndist(U)))
         })
d146 9
a154 8
  cat("Formula: ")
  print(formula(x$homfit))
  cat("\nSmoothing parameter sigma: ")
  print(x$sigma)
  cat("\nSmoothed coefficient estimates: ")
  print(x$smoo)
  cat(paste("\nStandardised coefficients",
            if(is.null(x$z)) "not available\n" else "available\n"))
d158 17
d176 1
a176 1
                        which=c("smoothed", "unsmoothed", "homogeneous")) {
d179 1
a179 2
                   smoothed = object$smoo,
                   unsmoothed = object$coefs,
d228 1
d231 1
a231 6
  Y <- U %mark% lam
  s0 <- mean(nndist(U))
  do.call("smooth.ppp",
          resolve.defaults(list(X=Y),
                           list(...),
                           list(sigma=s0)))
a286 3
  # interpolate
  ok <- complete.cases(resid)
  smoo <- smooth.ppp(U[ok] %mark% resid[ok,], sigma=1.4 * max(nndist(U)))
d288 1
a288 3
  result <- list(type="standardised residuals",
                 homfit=homfit, resid=resid, smoo=smoo, sigma=sigma)
  class(result) <- c("reslocppm", class(result))
a363 3
  # interpolate
  ok <- complete.cases(stat)
  smoo <- smooth.ppp(U[ok] %mark% stat[ok,], sigma=1.4 * max(nndist(U)))
d365 1
a365 5
  rtype <- paste("components of the score test statistic of",
                 nulltype, "null model")
  result <- list(type=rtype,
                 homfit=homfit, resid=stat, smoo=smoo, sigma=sigma)
  class(result) <- c("reslocppm", class(result))
d369 22
a390 10
print.reslocppm <- function(x, ...) {
  cat("Residuals for local likelihood fit\n")
  cat(paste("Type:", x$type, "\n"))
  cat("Formula: ")
  print(formula(x$homfit))
  cat("\nSmoothing parameter sigma: ")
  print(x$sigma)
  cat("\nSmoothed residuals:\n")
  print(x$smoo)
  return(invisible(NULL))
d393 16
a408 5
plot.reslocppm <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  do.call("plot", resolve.defaults(list(x=x$smoo),
                                   list(...),
                                   list(main=xname)))
d411 45
a455 12
sumsqres <- function(x) {
  stopifnot(inherits(x, "reslocppm"))
  resid2 <- matrix(rowSums(x$resid^2), ncol=1)
  smoo2 <- lapply(x$smoo, function(x) { eval.im(x^2) })
  smoo2 <- Reduce(function(A, B) { eval.im(A+B) }, smoo2)
  result <- list(type=paste("sum of squared", x$type),
                 homfit=x$homfit,
                 resid = resid2,
                 smoo  = listof(t2=smoo2),
                 sigma = x$sigma)
  class(result) <- c("reslocppm", class(result))
  return(result)
a456 1
 
@


1.13
log
@tweaked
@
text
@d6 1
a6 1
#  $Revision: 1.12 $ $Date: 2012/10/03 10:55:01 $
d11 1
a11 1
locppm <- function(..., sigma=NULL, f = 1/4, verbose=TRUE) {
d37 4
a40 1
  lpe <- locppmEngine(homfit, sigma, U[ok], verbose=verbose)
d44 4
a47 4
  if(!is.null(lpe$resids)) {
    resids <- coefs
    resids[ok,] <- lpe$resids
  } else resids <- NULL
d53 1
a53 1
  result <- list(homfit=homfit, coefs=coefs, smoo=smoo, resids=resids,
d62 2
a63 1
                         Vname="selected quadrature points") {
d68 1
a68 1
  do.resids <- is.poisson(model)
d78 1
a78 2
  if(do.resids) 
    resids <- coefs
d109 11
a119 3
      coefs[j, ] <- coef(fitj)
      if(do.resids) 
        resids[j,] <- coef(summary(fitj))[, 3]
d123 1
a123 1
  return(list(coefs=coefs, resids=if(do.resids) resids else NULL))
d129 1
a129 1
                        what=c("coefs", "resids"),
d152 1
a152 1
         exactresids={
d154 2
a155 2
           resids <- x$resids
           if(is.null(resids)) stop("No residuals available")
d157 3
a159 3
             resids <- resids[,which, drop=FALSE]
           ok <- complete.cases(resids)
           Z <- U[ok] %mark% resids[ok,]
d161 1
a161 1
         smoothedresids={
d163 2
a164 2
           resids <- x$resids
           if(is.null(resids)) stop("No residuals available")
d166 3
a168 3
             resids <- resids[,which, drop=FALSE]
           ok <- complete.cases(resids)
           Z <- U[ok] %mark% resids[ok,]
d184 2
d255 2
a256 1
scoresid <- function(object, ..., theta0=NULL, sigma=NULL, verbose=TRUE) {
d263 4
a266 1
  if(is.null(theta0)) {
a268 2
  } else {
    lam <- fitted(homfit, new.coef=theta0)
d270 1
d286 4
a289 2
  if(verbose)
    cat(paste("Processing", nok, "selected quadrature points...\n"))
d298 1
d310 86
a395 1
  result <- list(homfit=homfit, resid=resid, smoo=smoo, sigma=sigma)
d401 2
a402 1
  cat("Score residuals for local likelihood fit\n")
d407 1
a407 1
  cat("\nSmoothed coefficient estimates:\n")
d419 14
a432 1

@


1.12
log
@added predict.locppm
@
text
@d6 1
a6 1
#  $Revision: 1.11 $ $Date: 2012/09/12 02:10:12 $
d233 1
a233 1
  s0 <- 2 * mean(nndist(U))
@


1.11
log
@now computes score residuals of local (Poisson) fits
@
text
@d6 1
a6 1
#  $Revision: 1.10 $ $Date: 2012/09/04 07:16:07 $
d218 1
a218 2
  fit0 <- object$homfit
  coef0 <- coef(fit0)
d227 11
@


1.10
log
@debugged
split off core calculation as 'Engine'
@
text
@d6 1
a6 1
#  $Revision: 1.9 $ $Date: 2012/09/04 06:07:25 $
d12 3
a14 2
  
  homfit <- ppm(..., forcefit=TRUE)
d17 1
a17 1
  
d35 3
d39 6
a44 2
  # go
  coefs[ok,] <- locppmEngine(homfit, sigma, U[ok], verbose=verbose)
d50 2
a51 1
  result <- list(homfit=homfit, coefs=coefs, smoo=smoo, sigma=sigma)
d63 2
d74 2
d105 1
a105 1
    if(!inherits(fitj, "try-error"))
d107 3
d112 1
a112 1
  return(coefs)
d116 4
a119 1
plot.locppm <- function(x, ...) {
d121 40
a160 1
  do.call("plot", resolve.defaults(list(x=x$smoo),
d217 1
a217 1
fitted.locppm <- function(object, ...) {
d221 1
a221 1
  gdat <- getglmdata(fit0)
d223 1
a223 1
  nQ <- n.quad(quad.ppm(fit0))
d229 76
@


1.9
log
@safety
@
text
@d6 1
a6 1
#  $Revision: 1.8 $ $Date: 2012/09/03 06:19:46 $
d13 1
a13 1
  homfit <- ppm(...)
a24 2
  m  <- getglmfit(homfit)
  df <- getglmdata(homfit)
d27 5
a31 5
  Ux <- U$x
  Uy <- U$y
  Uok <- df$.mpl.SUBSET
  
  coef0 <- coef(m)
a33 7
  
  env.here <- sys.frame(sys.nframe())
  env.model <- environment(terms(m))
  env.update <- environment(formula(m))
  fmla     <- get("fmla",     envir=env.model)
  gcontrol <- get("gcontrol", envir=env.model)
  glmdata  <- get("glmdata", envir=env.model)
d35 2
a36 7
  assign("coef0", coef0, envir=env.update)

  jok <- which(Uok)
  nok <- length(jok)
  
  if(verbose)
    cat(paste("Processing", nok, "quadrature points...\n"))
d38 1
a38 13
  for(k in 1:nok) {
    if(verbose)
      progressreport(k, nok)
    j <- jok[k]
    localwt <- dnorm(Ux - Ux[j], sd=sigma) * dnorm(Uy - Uy[j], sd=sigma)
    localwt <- localwt / mean(localwt)
    assign("localwt", localwt, envir=env.update)
    fitj <- update(m, weights = .mpl.W * localwt, start=coef0, evaluate=FALSE)
    fitj <- try(eval(fitj, enclos=env.model, envir=env.here))
    if(!inherits(fitj, "try-error"))
      coefs[j, ] <- coef(fitj)
  }
  if(verbose) cat("Done.\n")
d47 4
a50 1
locppmEngine <- function(model, sigma, U, V, Vname="quadrature points") {
d53 2
d58 1
a58 4
  # quadrature points are given by U
  nU <- npoints(U)
  Ux <- U$x
  Uy <- U$y
d63 2
a64 1
  # environments
d67 1
d73 1
d75 5
a79 1
  assign("coef0", coef0, envir=env.update)
@


1.8
log
@name change
@
text
@d6 1
a6 1
#  $Revision: 1.7 $ $Date: 2012/08/29 02:11:44 $
d73 44
d153 1
a153 1
bw.frac <- function(W, f=1/4) {
d165 9
a173 2
  plot(rgrid[-1], ch, type="l")
  return(rgrid[i+1])
@


1.7
log
@as.ppm moved to spatstat
@
text
@d2 1
a2 1
#  local.R
d6 1
a6 1
#  $Revision: 1.6 $ $Date: 2012/08/28 09:53:10 $
@


1.6
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.5 $ $Date: 2012/08/27 01:48:23 $
a100 4
as.ppm <- function(object) {
  UseMethod("as.ppm")
}

@


1.5
log
@more class/method stuff
@
text
@d6 1
a6 1
#  $Revision: 1.4 $ $Date: 2012/08/27 01:39:39 $
d9 2
d14 3
d45 3
d50 1
a50 1
    cat(paste("Processing", sum(Uok), "quadrature points...\n"))
d52 1
a52 1
  for(j in which(Uok)) {
d54 2
a55 1
      progressreport(j, nU)
d128 13
@


1.4
log
@minor
@
text
@d6 1
a6 1
#  $Revision: 1.3 $ $Date: 2012/08/27 01:30:22 $
d14 1
a14 1
  if(is.null(sigma)) 
d16 3
a18 2
  if(verbose)
    cat(paste("sigma = ", sigma, "\n"))
d59 1
a59 1
  result <- list(homfit=homfit, coefs=coefs, smoo=smoo)
d75 3
d82 22
@


1.3
log
@Changed name to locppm.
Started making class structure.
@
text
@d6 1
a6 1
#  $Revision: 1.2 $ $Date: 2012/08/16 10:17:15 $
d41 1
a41 1
    cat(paste("Processing", nU, "quadrature points...\n"))
@


1.2
log
@developed a bandwidth selection algorithm
@
text
@d6 1
a6 1
#  $Revision: 1.1 $ $Date: 2012/08/16 09:55:05 $
d9 1
a9 1
localppm <- function(..., sigma=NULL, f = 1/4, verbose=TRUE) {
d56 20
a75 2
  smoo <- smooth.ppp(U[ok] %mark% coefs[ok,], sigma=5 * max(nndist(U)))
  return(smoo)
@


1.1
log
@Initial revision
@
text
@d6 1
a6 1
#  $Revision$ $Date$
d9 2
a10 1
localppm <- function(..., sigma=bw.diggle, verbose=TRUE) {
d13 3
a15 5
  if(!is.numeric(sigma)) {
    if(is.function(sigma)) {
      sigma <- sigma(X)
    } else stop("Format of sigma not understood")
  }
d17 1
a17 1
    cat(paste("Sigma =", sigma, "\n"))
d59 16
@
